{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VAE project","text":"<p>Python module for the implementation of a variational autoencoder (VAE) for climate data. The VAE is a generative model that can be used to learn the underlying distribution of a dataset and to generate new samples from it.</p> <p>The present methodology extends on the VAE by adding a second decoder to the model. The second decoder is trained to make predictions about the future evolution of the data from the latent space. The VAE is trained to learn the distribution of the data and the prediction decoder is trained to make predictions about the future distribution of the data.</p>"},{"location":"#implementation","title":"Implementation","text":"<p>The modeling framework is published in Groth and Chavez (2024). For an implementation see the corresponding Jupyter notebooks at:</p> <p>https://github.com/andr-groth/VAE-ENSO-emulator</p>"},{"location":"#simple-examples","title":"Simple examples","text":"<p>To get started, see the following examples:</p> <ul> <li> <p>VAE: Build a variational autoencoder model.</p> </li> <li> <p>VAEp: Build a variational autoencoder model with a prediction decoder.</p> </li> </ul> <p>For more examples, see the collection of examples.</p>"},{"location":"#reference","title":"Reference","text":"<p>Please add a reference to the following paper if you use parts of this code:</p> <pre><code>@Article{Groth.Chavez.2024,\n  author           = {Groth, Andreas and Chavez, Erik},\n  journal          = {Climate Dynamics},\n  title            = {Efficient inference and learning of a generative model for {ENSO} predictions from large multi-model datasets},\n  year             = {2024},\n  doi              = {10.1007/s00382-024-07162-w},\n  publisher        = {Springer Science and Business Media LLC},\n}\n</code></pre>"},{"location":"VAE.callbacks/","title":"Callbacks","text":""},{"location":"VAE.callbacks/#VAE.callbacks","title":"VAE.callbacks","text":"<p>Collection of callbacks for model training.</p>"},{"location":"VAE.callbacks/#VAE.callbacks.ModelCheckpoint","title":"VAE.callbacks.ModelCheckpoint","text":"<pre><code>ModelCheckpoint(filepath, period=1, **kwargs)\n</code></pre> <p>             Bases: <code>ModelCheckpoint</code></p> <p>Callback to save the Keras model or model weights at some frequency.</p> <p>Prevents deprecation warning in super class when period is used.</p> <p>Parameters:</p> <ul> <li> <code>period</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of epochs between checkpoints.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments to be passed to <code>keras.callbacks.ModelCheckpoint</code>.</p> </li> </ul> Source code in <code>VAE/callbacks.py</code> <pre><code>def __init__(self, filepath: str, period: int = 1, **kwargs):\n    super().__init__(filepath, **kwargs)\n    self.period = period\n</code></pre>"},{"location":"VAE.callbacks/#VAE.callbacks.Evaluate","title":"VAE.callbacks.Evaluate","text":"<pre><code>Evaluate(x=None, y=None, batch_size=None, verbose=0, sample_weight=None, prefix='val2_', **kwargs)\n</code></pre> <p>             Bases: <code>Callback</code></p> <p>Callback to evaluate the model.</p> <p>This callbacks evaluates the model on the given data at the end of each epoch. For a detailed description of the input and target data see the Keras documentation for :func:<code>keras.Model.evaluate</code>.</p> <p>With this callback, further validation datasets can be evaluated during training. The prefix is used to identify the metrics in the logs and should be unique for each validation dataset. The prefix cannot be empty of <code>val_</code>. This would cause training metrics to be overwritten.</p> <p>Parameters:</p> <ul> <li> <code>x</code>         \u2013          <p>Input data.</p> </li> <li> <code>y</code>         \u2013          <p>Target data.</p> </li> <li> <code>batch_size</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Number of samples per batch.</p> </li> <li> <code>verbose</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Verbosity mode.</p> </li> <li> <code>sample_weight</code>         \u2013          <p>Sample weights.</p> </li> <li> <code>prefix</code>             (<code>str</code>, default:                 <code>'val2_'</code> )         \u2013          <p>Prefix for the metric names. Defaults to 'val2_'.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments to be passed to <code>keras.callbacks.Callback</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If the prefix is empty or <code>val_</code>.</p> </li> </ul> Source code in <code>VAE/callbacks.py</code> <pre><code>def __init__(self,\n             x=None,\n             y=None,\n             batch_size: int = None,\n             verbose: int = 0,\n             sample_weight=None,\n             prefix: str = 'val2_',\n             **kwargs):\n    self.x = x\n    self.y = y\n    self.batch_size = batch_size\n    self.verbose = verbose\n    self.sample_weight = sample_weight\n    self.prefix = prefix\n    if prefix in {None, '', 'val_'}:\n        raise ValueError('prefix cannot be empty or \"val_\". This will cause the metrics to be overwritten.')\n\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"VAE.generators/","title":"Generators","text":""},{"location":"VAE.generators/#VAE.generators","title":"VAE.generators","text":"<p>Collection of generators for VAE model training.</p> <p>Generator class for data given as a Numpy array(s).</p>"},{"location":"VAE.generators/#VAE.generators.FitGenerator","title":"VAE.generators.FitGenerator","text":"<pre><code>FitGenerator(datasets, input_length, batch_size=32, beta_scheduler=None, condition=None, ensemble_size=None, ensemble_type='random', ensemble_index=None, ensemble_range=None, ensemble_replace=False, ensemble_sync=False, filter_length=None, initial_epoch=0, input_channels=None, latitude=0, longitude=None, prediction_channels=None, prediction_length=None, repeat_samples=1, sample_weights=None, shuffle=True, sph_degree=None, strides=1, time=None, tp_period=None, dtype='float32', **kwargs)\n</code></pre> <p>             Bases: <code>Sequence</code></p> <p>Generator class for model training.</p> <p>Given an Numpy array of shape <code>(set_size, data_length, channels)</code>, the generator prepares the <code>inputs and</code>targets<code>for the model training in :func:</code>keras.Model.fit_generator()`.</p> <p>Parameters:</p> <ul> <li> <code>datasets</code>             (<code>Union[ndarray, list[ndarray]]</code>)         \u2013          <p>Dataset used for training. The dataset can be either a single numpy array of shape <code>(set_size, data_length, channels)</code> or a list of Numpy arrays. In case of a list of Numpy arrays, <code>set_size</code> and <code>channels</code> must be the same, while <code>data_length</code> can vary. Missing (non-finite) values will be excluded from the samples.</p> </li> <li> <code>input_length</code>             (<code>int</code>)         \u2013          <p>Length of input to the encoder.</p> </li> <li> <code>batch_size</code>             (<code>int</code>, default:                 <code>32</code> )         \u2013          <p>Batch size. Note that the effective batch size is <code>batch_size * repeat_samples</code>.</p> </li> <li> <code>beta_scheduler</code>         \u2013          <p>Instance of :class:<code>BetaScheduler</code> that returns the <code>beta</code> parameters for the KL loss in each epoch.</p> </li> <li> <code>condition</code>             (<code>Union[ndarray, list[ndarray], dict]</code>, default:                 <code>None</code> )         \u2013          <p>Additional data used as condition. The Numpy arrays must be of length <code>data_length</code> matching the Numpy array(s)  in <code>dataset</code>. If a list is provided, the length of the list must match the length of <code>datasets</code>. If a dict is provided, the keys must match <code>encoder</code> and <code>decoder</code>. This allows to pass different conditions to the encoder and decoder, provided as the corresponding dict values.</p> </li> <li> <code>ensemble_size</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Size for the one-hot encoded ensemble condition.</p> </li> <li> <code>ensemble_type</code>             (<code>str</code>, default:                 <code>'random'</code> )         \u2013          <p>Whether to use the dataset index (<code>index</code>) or random ensemble condition (<code>random</code>, 'random_full'). If <code>index</code>, the ensemble condition corresponds to the dataset index. If 'random' or <code>random_full</code>, the ensemble condition is sampled from a uniform distribution in the range <code>ensemble_range</code>. The samples are the same for all samples in a batch ('random') or different for each sample in a batch ('random_full'). Defaults to <code>random</code>.</p> </li> <li> <code>ensemble_index</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Array of indices used as ensemble condition if <code>ensemble_type</code> is <code>index</code>. Must match the length of <code>dataset</code> and must be in range <code>(0, ensemble_size)</code>. Defaults to <code>None</code> meaning the dataset index is used.</p> </li> <li> <code>ensemble_range</code>             (<code>tuple[int, int]</code>, default:                 <code>None</code> )         \u2013          <p>Range of the random ensemble condition. Must be a subrange of <code>(0, ensemble_size)</code>. Defaults to <code>None</code> and is set to <code>(0, ensemble_size)</code>.</p> </li> <li> <code>ensemble_replace</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to sample the random ensemble condition with replacement if <code>repeat_samples &gt; 1</code>. Defaults to <code>False</code>.</p> </li> <li> <code>ensemble_sync</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Synchronize random ensemble conditions between encoder and decoder. If <code>True</code> , the random ensemble conditions of the encoder and decoder are the same. Defaults to <code>False</code>, i.e. the random ensemble conditions of the encoder an decoder are different random samples. Note that the ensemble conditions of the decoder and prediction are always the same.</p> </li> <li> <code>filter_length</code>             (<code>Union[int, tuple[int, int]]</code>, default:                 <code>None</code> )         \u2013          <p>Length of the temporal filter for the inputs and targets.  A centered moving average filter of length <code>2 * filter_length + 1</code> is applied to the inputs and targets. If a tuple of two ints is given, the first int is the length of the filter for the input to the encoder and the target to the decoder. The second int is the length of the filter for the target to the prediction. Defaults to <code>None</code>, i.e. no filter.</p> </li> <li> <code>initial_epoch</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Initial epoch at which the generator will start. This will affect the <code>beta</code> parameter.</p> </li> <li> <code>input_channels</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Range of channels used as input. The items in the tuple refer to start, stop and step in slice notation. Defaults to <code>None</code> means all channels are used.</p> </li> <li> <code>latitude</code>             (<code>ndarray</code>, default:                 <code>0</code> )         \u2013          <p>Latitude in degree if the spherical harmonics are used for spatial condition.</p> </li> <li> <code>longitude</code>             (<code>ndarray</code>, default:                 <code>None</code> )         \u2013          <p>Longitude of the data in degree if the spherical harmonics are used for spatial condition. Length of <code>longitude</code> must be equal to <code>set_size</code>. Defaults to <code>None</code> and is set to <code>np.arange(0, 360, 360/set_size)</code>.</p> </li> <li> <code>prediction_channels</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Range of channels used for prediction. The items in the tuple refer to start, stop and step in slice notation. Defaults to <code>None</code> means all channels are used.</p> </li> <li> <code>prediction_length</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Length of prediction. Defaults to <code>None</code> means no prediction.</p> </li> <li> <code>repeat_samples</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of times the same sample is repeated in the batch. This will augment the batch size. This options is useful in combination with the ensemble condition, in which the same samples is presented multiple times with different random samples of the ensemble conditions. Defaults to 1.</p> </li> <li> <code>sample_weights</code>             (<code>ndarray</code>, default:                 <code>None</code> )         \u2013          <p>Sample weights of shape <code>(nr_datasets, set_size)</code>. Defaults to <code>None</code>.</p> </li> <li> <code>shuffle</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Shuffle samples order.</p> </li> <li> <code>sph_degree</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Number of spherical degrees if the spherical harmonics are used for spatial condition.</p> </li> <li> <code>strides</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Sample strides along second dimension of <code>data</code> of size <code>data_length</code>.</p> </li> <li> <code>time</code>             (<code>Union[ndarray, list[ndarray]]</code>, default:                 <code>None</code> )         \u2013          <p>Time of the data if the time-periodic harmonics are used for temporal condition. Must be of length <code>data_length</code>. If a list is provided, the length of the list must match the length of <code>datasets</code>.</p> </li> <li> <code>tp_period</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Maximal period for the temporal harmonics. See :func:<code>get_tp_harmonics</code>.</p> </li> <li> <code>dtype</code>             (<code>str</code>, default:                 <code>'float32'</code> )         \u2013          <p>Dtype of the data that will be returned.</p> </li> </ul> Source code in <code>VAE/generators.py</code> <pre><code>def __init__(self,\n             datasets: Union[np.ndarray, list[np.ndarray]],\n             input_length: int,\n             batch_size: int = 32,\n             beta_scheduler=None,\n             condition: Union[np.ndarray, list[np.ndarray], dict] = None,\n             ensemble_size: int = None,\n             ensemble_type: str = 'random',\n             ensemble_index: int = None,\n             ensemble_range: tuple[int, int] = None,\n             ensemble_replace: bool = False,\n             ensemble_sync: bool = False,\n             filter_length: Union[int, tuple[int, int]] = None,\n             initial_epoch: int = 0,\n             input_channels: list[int] = None,\n             latitude: np.ndarray = 0,\n             longitude: np.ndarray = None,\n             prediction_channels: list[int] = None,\n             prediction_length: int = None,\n             repeat_samples: int = 1,\n             sample_weights: np.ndarray = None,\n             shuffle: bool = True,\n             sph_degree: int = None,\n             strides: int = 1,\n             time: Union[np.ndarray, list[np.ndarray]] = None,\n             tp_period: float = None,\n             dtype: str = 'float32',\n             **kwargs):\n    \"\"\"Instantiate generator.\"\"\"\n    if not isinstance(datasets, (list, tuple)):\n        datasets = [datasets]\n\n    shapes = {dataset[:, 0, :].shape for dataset in datasets}\n    if len(shapes) &gt; 1:\n        raise ValueError('all datasets must have the same set_size and number of channels')\n\n    set_size, channels = shapes.pop()\n    self.channels = channels\n    self.set_size = set_size\n\n    self.batch_size = batch_size\n    self.beta_scheduler = beta_scheduler\n    self.datasets = datasets\n    self.dtype = dtype\n    self.ensemble_replace = ensemble_replace\n    self.ensemble_size = ensemble_size\n    self.ensemble_sync = ensemble_sync\n    self.epoch = initial_epoch\n    self.filter_length = np.broadcast_to(filter_length, (2, ))\n    self.input_length = input_length\n    self.repeat_samples = repeat_samples\n    self.shuffle = shuffle\n    self.strides = strides\n    self.prediction_length = prediction_length if prediction_length is not None else 0\n\n    self.input_channels = slice(*input_channels) if input_channels is not None else slice(None)\n    self.prediction_channels = slice(*prediction_channels) if prediction_channels is not None else slice(None)\n\n    if condition is not None:\n        if not isinstance(condition, dict):\n            # same condition for encoder and decoder\n            condition = {'encoder': condition}\n        else:\n            if 'encoder' not in condition.keys():\n                raise KeyError('Require at least `encoder` item in `condition`.')\n\n        # prepare condition\n        for key, value in condition.items():\n            if isinstance(value, (list, tuple)):\n                condition.update({key: [self._prepare_condition(v) for v in value]})\n            else:\n                condition.update({key: self._prepare_condition(value)})\n\n    self.condition = condition\n\n    if ensemble_size is not None:\n        if ensemble_range is None:\n            ensemble_range = (0, ensemble_size)\n\n        if repeat_samples &gt; len(range(*ensemble_range)) and not ensemble_replace:\n            error_msg = f'{repeat_samples=} must not be larger than {ensemble_range=}' \\\n                f' if sampling without replacement ({ensemble_replace=})'\n            raise ValueError(error_msg)\n\n        val_ensemble_type = {'index', 'random', 'random_full'}\n        if ensemble_type not in val_ensemble_type:\n            raise ValueError(f'{ensemble_type=} must be in {val_ensemble_type}')\n\n    self.ensemble_index = np.array(ensemble_index) if ensemble_index is not None else None\n    self.ensemble_type = ensemble_type\n    self.ensemble_range = ensemble_range\n\n    self._prepare_embedding()\n    if self.shuffle:\n        self._shuffle_data()\n\n    if tp_period is not None:\n        if time is None:\n            raise ValueError('time must be given if tp_period is given')\n\n        if isinstance(time, (list, tuple)):\n            if len(time) == len(datasets):\n                self.tp_harmonics = [self.get_tp_harmonics(t, tp_period) for t in time]\n            else:\n                raise ValueError('Length of `time` must match length of `datasets`')\n        else:\n            self.tp_harmonics = self.get_tp_harmonics(time, tp_period)\n\n    else:\n        self.tp_harmonics = None\n\n    if sph_degree is not None:\n        if longitude is None:\n            longitude = np.arange(0, 360, 360 / set_size)\n\n        self.sph_harmonics = self.get_sph_harmonics(latitude, longitude, sph_degree)\n    else:\n        self.sph_harmonics = None\n\n    if sample_weights is not None:\n        if len(sample_weights) != len(datasets):\n            raise ValueError('`sample_weights` must have the same length as `datasets`')\n\n    self.sample_weights = sample_weights\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.FitGenerator.nr_samples","title":"VAE.generators.FitGenerator.nr_samples  <code>property</code>","text":"<pre><code>nr_samples\n</code></pre> <p>Return number of samples.</p>"},{"location":"VAE.generators/#VAE.generators.FitGenerator.__getitem__","title":"VAE.generators.FitGenerator.__getitem__","text":"<pre><code>__getitem__(idx)\n</code></pre> <p>Return batch of data.</p> <p>Note that the effective batch size is <code>batch_size * repeat_samples</code>.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>             (<code>int</code>)         \u2013          <p>Batch index.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[dict, dict]</code>         \u2013          <p>Two dicts, one for the inputs and one for the targets.</p> </li> </ul> Source code in <code>VAE/generators.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; tuple[dict, dict]:\n    \"\"\"Return batch of data.\n\n    Note that the effective batch size is `batch_size * repeat_samples`.\n\n    Parameters:\n        idx:\n            Batch index.\n\n    Returns:\n        Two dicts, one for the inputs and one for the targets.\n    \"\"\"\n\n    if idx &gt;= self.__len__():\n        raise IndexError('batch index out of range')\n\n    inputs = dict()\n    targets = dict()\n\n    batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size, ..., self.input_channels]\n    batch_size = len(batch_x)\n    batch_x = self._repeat_samples(batch_x)\n    inputs['encoder_input'] = batch_x\n    targets['decoder'] = batch_x\n\n    encoder_cond = []\n    decoder_cond = []\n\n    if self.sph_harmonics is not None:\n        sph_cond = self.sph_harmonics[None, :, :]\n        sph_cond = np.repeat(sph_cond, batch_size * self.repeat_samples, axis=0)\n        encoder_cond.append(sph_cond)\n        decoder_cond.append(sph_cond)\n\n    if self.tp_harmonics is not None:\n        tp_cond = self._get_condition(self.tp_harmonics, idx)\n        encoder_cond.append(tp_cond)\n        decoder_cond.append(tp_cond)\n\n    if self.condition is not None:\n        ex_cond = self._get_condition(self.condition['encoder'], idx)\n        if 'decoder' in self.condition.keys():\n            dx_cond = self._get_condition(self.condition['decoder'], idx)\n        else:\n            dx_cond = ex_cond\n        encoder_cond.append(ex_cond)\n        decoder_cond.append(dx_cond)\n\n    if self.ensemble_size is not None:\n        if self.ensemble_sync:\n            ens_cond = self.get_ensemble_condition(batch_size, idx)\n            encoder_cond.append(ens_cond)\n            decoder_cond.append(ens_cond)\n        else:\n            encoder_cond.append(self.get_ensemble_condition(batch_size, idx))\n            decoder_cond.append(self.get_ensemble_condition(batch_size, idx))\n\n    if encoder_cond:\n        inputs['encoder_cond'] = np.concatenate(encoder_cond, axis=-1)\n        inputs['decoder_cond'] = np.concatenate(decoder_cond, axis=-1)\n\n    if self.y is not None:\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size, ..., self.prediction_channels]\n        batch_y = self._repeat_samples(batch_y)\n        targets['prediction'] = batch_y\n        if 'decoder_cond' in inputs:\n            inputs['prediction_cond'] = inputs['decoder_cond']\n\n    if self.beta_scheduler is not None:\n        inputs['beta'] = self.beta_scheduler(self.epoch, shape=(batch_size * self.repeat_samples, 1))\n\n    if self.sample_weights is not None:\n        indices = self.get_index(idx)[:, 0]\n        sw = [self.sample_weights[i] for i in indices]\n        sw = np.stack(sw, axis=0)\n        samples_weights = {'decoder': sw, 'prediction': sw}\n        return inputs, targets, samples_weights\n\n    else:\n        return inputs, targets\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.FitGenerator.get_ensemble_condition","title":"VAE.generators.FitGenerator.get_ensemble_condition","text":"<pre><code>get_ensemble_condition(batch_size, idx=None)\n</code></pre> <p>Return ensemble condition for given batch.</p> <p>A one-hot encoded ensemble index is return that is the same for all samples in the batch. The code is broadcasted along the second dimension of size <code>set_size</code>.</p> <p>In case of <code>repeat_samples &gt; 1</code>, the actual batch size is <code>batch_size * repeat_samples</code> and a set of <code>repeat_samples</code>random indices is sampled.</p> <p>To alter between sampling with and without replacement, the <code>ensemble_replace</code> flag can be set.</p> <p>Parameters:</p> <ul> <li> <code>batch_size</code>             (<code>int</code>)         \u2013          <p>Batch size.</p> </li> <li> <code>idx</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Required if <code>ensemble_type='index</code>. Returns the ensemble condition corresponding to the batch with index <code>idx</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Array of shape <code>(batch_size * repeat_samples, set_size, ensemble_size)</code></p> </li> </ul> Source code in <code>VAE/generators.py</code> <pre><code>def get_ensemble_condition(self, batch_size: int, idx: int = None) -&gt; np.ndarray:\n    \"\"\"Return ensemble condition for given batch.\n\n    A one-hot encoded ensemble index is return that is the same for all samples in the batch. The code is\n    broadcasted along the second dimension of size `set_size`.\n\n    In case of `repeat_samples &gt; 1`, the actual batch size is `batch_size * repeat_samples` and a set of\n    `repeat_samples`random indices is sampled.\n\n    To alter between sampling with and without replacement, the `ensemble_replace` flag can be set.\n\n    Parameters:\n        batch_size:\n            Batch size.\n        idx:\n            Required if `ensemble_type='index`. Returns the ensemble condition corresponding to the batch with index\n            `idx`.\n\n    Returns:\n        Array of shape `(batch_size * repeat_samples, set_size, ensemble_size)`\n    \"\"\"\n    if self.ensemble_type == 'random':\n        ensemble_idx = np.random.choice(np.arange(*self.ensemble_range),\n                                        size=self.repeat_samples,\n                                        replace=self.ensemble_replace)\n        condition = np.zeros((self.repeat_samples, self.set_size, self.ensemble_size), dtype=self.dtype)\n        condition[np.arange(self.repeat_samples), :, ensemble_idx] = 1\n        condition = np.tile(condition, (batch_size, 1, 1))\n\n    elif self.ensemble_type == 'random_full':\n        ensemble_idx = [\n            np.random.choice(np.arange(*self.ensemble_range),\n                             size=self.repeat_samples,\n                             replace=self.ensemble_replace) for _ in range(batch_size)\n        ]\n        ensemble_idx = np.stack(ensemble_idx, axis=0)\n        condition = np.zeros((batch_size * self.repeat_samples, self.set_size, self.ensemble_size),\n                             dtype=self.dtype)\n        condition[np.arange(batch_size * self.repeat_samples), :, ensemble_idx.flat] = 1\n\n    else:  # `index`\n        if idx &gt;= self.__len__():\n            raise IndexError('batch index out of range')\n        if idx is None:\n            raise ValueError('idx must be given')\n\n        ensemble_idx = self.get_index(idx)[:, 0]\n        if self.ensemble_index is not None:\n            ensemble_idx = self.ensemble_index[ensemble_idx]\n\n        condition = np.zeros((len(ensemble_idx), self.set_size, self.ensemble_size), dtype=self.dtype)\n        condition[np.arange(len(ensemble_idx)), :, ensemble_idx] = 1\n    return condition\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.FitGenerator.get_index","title":"VAE.generators.FitGenerator.get_index","text":"<pre><code>get_index(idx)\n</code></pre> <p>Return array of dataset and time index of samples in batch.</p> <p>The returned array is of shape <code>(batch_size * repeat_samples, 2)</code> with the first column containing the dataset index and the second column the time index of the sample. The time index refers to the first sample of the target sequence for the prediction.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>             (<code>int</code>)         \u2013          <p>Batch index.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Array of shape <code>(batch_size * repeat_samples, 2)</code>.</p> </li> </ul> Source code in <code>VAE/generators.py</code> <pre><code>def get_index(self, idx: int) -&gt; np.ndarray:\n    \"\"\"Return array of dataset and time index of samples in batch.\n\n    The returned array is of shape `(batch_size * repeat_samples, 2)` with the first column containing the dataset\n    index and the second column the time index of the sample. The time index refers to the first sample of the\n    target sequence for the prediction.\n\n    Parameters:\n        idx:\n            Batch index.\n\n    Returns:\n        Array of shape `(batch_size * repeat_samples, 2)`.\n    \"\"\"\n    if idx &gt;= self.__len__():\n        raise IndexError('batch index out of range')\n\n    indices = self.index[idx * self.batch_size:(idx + 1) * self.batch_size, ...]\n    indices = self._repeat_samples(indices)\n    return indices\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.FitGenerator.get_sph_harmonics","title":"VAE.generators.FitGenerator.get_sph_harmonics","text":"<pre><code>get_sph_harmonics(latitude, longitude, sph_degree)\n</code></pre> <p>Get spherical harmonics.</p> <p>The returned array is of shape <code>(set_size, 2 * sph_degree + 1)</code> with the rows containing the spherical harmonics for the given latitude and longitude values.</p> <p>Parameters:</p> <ul> <li> <code>latitude</code>         \u2013          <p>float Latitude value in degree.</p> </li> <li> <code>longitude</code>         \u2013          <p>array_like Array of longitude values in degree of shape <code>(set_size,)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Array of shape <code>(set_size, 2 * sph_degree + 1)</code>.</p> </li> </ul> Source code in <code>VAE/generators.py</code> <pre><code>def get_sph_harmonics(self, latitude: np.ndarray, longitude: np.ndarray, sph_degree: int) -&gt; np.ndarray:\n    \"\"\"Get spherical harmonics.\n\n    The returned array is of shape `(set_size, 2 * sph_degree + 1)` with the rows containing the spherical harmonics\n    for the given latitude and longitude values.\n\n    Parameters:\n        latitude : float\n            Latitude value in degree.\n        longitude : array_like\n            Array of longitude values in degree of shape `(set_size,)`.\n\n    Returns:\n        Array of shape `(set_size, 2 * sph_degree + 1)`.\n    \"\"\"\n    colat = np.pi / 2 - np.deg2rad(latitude)  # [0, pi]\n    lon = np.deg2rad(longitude) % (2 * np.pi)  # [0, 2*pi]\n\n    sph = []\n    for n in range(sph_degree + 1):\n        s = sph_harm(n, n, lon, colat)\n        sph.append(np.real(s))\n        if n &gt; 0:\n            s = sph_harm(-n, n, lon, colat)\n            sph.append(np.imag(s))\n\n    return np.stack(sph, axis=1).astype(self.dtype)\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.FitGenerator.get_tp_harmonics","title":"VAE.generators.FitGenerator.get_tp_harmonics","text":"<pre><code>get_tp_harmonics(time, tp_period)\n</code></pre> <p>Get temporal harmonics.</p> <p>Parameters:</p> <ul> <li> <code>time</code>             (<code>ndarray</code>)         \u2013          <p>Array of time values for which the harmonics are calculated.</p> </li> <li> <code>tp_period</code>             (<code>int</code>)         \u2013          <p>Maximal period for the temporal harmonics in time units.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Array of shape <code>(len(times), tp_period)</code>.</p> </li> </ul> Source code in <code>VAE/generators.py</code> <pre><code>def get_tp_harmonics(self, time: np.ndarray, tp_period: int) -&gt; np.ndarray:\n    \"\"\"Get temporal harmonics.\n\n    Parameters:\n        time:\n            Array of time values for which the harmonics are calculated.\n        tp_period:\n            Maximal period for the temporal harmonics in time units.\n\n    Returns:\n        Array of shape `(len(times), tp_period)`.\n    \"\"\"\n    f = np.fft.rfftfreq(tp_period)[None, 1:]  # omit DC\n    time = np.array(time)[:, None]\n    harmonics = np.concatenate([np.sin(2 * np.pi * f * time), np.cos(2 * np.pi * f * time)], axis=1)\n\n    return harmonics\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.FitGenerator.on_epoch_end","title":"VAE.generators.FitGenerator.on_epoch_end","text":"<pre><code>on_epoch_end()\n</code></pre> <p>Shuffle data after each epoch.</p> <p>This method is called after each epoch and shuffles the data if <code>shuffle=True</code>.</p> Source code in <code>VAE/generators.py</code> <pre><code>def on_epoch_end(self):\n    \"\"\"Shuffle data after each epoch.\n\n    This method is called after each epoch and shuffles the data if `shuffle=True`.\n\n    \"\"\"\n    self.epoch += 1\n    if self.shuffle:\n        self._shuffle_data()\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.FitGenerator.summary","title":"VAE.generators.FitGenerator.summary","text":"<pre><code>summary()\n</code></pre> <p>Print summary.</p> Source code in <code>VAE/generators.py</code> <pre><code>def summary(self):\n    \"\"\"Print summary.\"\"\"\n    total_size = sum([dataset.size for dataset in self.datasets])\n    total_length = sum([dataset.shape[1] for dataset in self.datasets])\n    print(f'Number of datasets : {len(self.datasets):,}')\n    print(f'Total data size    : {total_size:,}')\n    print(f'Total data length  : {total_length:,}')\n    print(f'Strides            : {self.strides:,}')\n    print(f'Number of samples  : {self.nr_samples:,}')\n    print(f'Batch size         : {self.batch_size:,}')\n    print(f'Number of batches  : {len(self):,}')\n\n    act_batch_size = self.batch_size * self.repeat_samples\n    print(f'Sample repetitions : {self.repeat_samples:,}')\n    print(f'Actual batch size  : {self.batch_size:,} * {self.repeat_samples} = {act_batch_size:,}')\n\n    print(f'Shuffle            : {self.shuffle}')\n\n    nx, ny = self.filter_length\n    if (nx is not None) or (ny is not None):\n        print('Filter length')\n        print(f'  input      : {nx}')\n        print(f'  prediction : {ny}')\n\n    if self.ensemble_size is not None:\n        print('Ensemble condition')\n        print(f'  size : {self.ensemble_size}')\n        print(f'  type : {self.ensemble_type}')\n        if self.ensemble_type in ['random', 'random_full']:\n            print(f'  range   : {self.ensemble_range}')\n            print(f'  sync    : {self.ensemble_sync}')\n            print(f'  replace : {self.ensemble_replace}')\n\n    channels = tuple(range(self.channels))[self.input_channels]\n    if len(channels) == self.channels:\n        print('Input channels     : all')\n    else:\n        print(f'Input channels     : {channels}')\n\n    if self.prediction_length:\n        channels = tuple(range(self.channels))[self.prediction_channels]\n        if len(channels) == self.channels:\n            print('Predicted channels : all')\n        else:\n            print(f'Predicted channels : {channels}')\n\n    # get samples\n    items = self.__getitem__(0)\n    # unpack items\n    inputs, targets, sample_weights, *_ = chain(items, [None] * 3)\n\n    print('Output shapes')\n    print('  inputs')\n    for key, value in inputs.items():\n        print(f'    {key:&lt;16.16} : {value.shape}')\n\n    if targets is not None:\n        print('  targets')\n        for key, value in targets.items():\n            print(f'    {key:&lt;16.16} : {value.shape}')\n\n    if sample_weights is not None:\n        print('  sample_weights')\n        for key, value in sample_weights.items():\n            print(f'    {key:&lt;16.16} : {value.shape}')\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.PredictGenerator","title":"VAE.generators.PredictGenerator","text":"<pre><code>PredictGenerator(datasets, input_length, batch_size=32, beta_scheduler=None, condition=None, ensemble_size=None, ensemble_type='random', ensemble_index=None, ensemble_range=None, ensemble_replace=False, ensemble_sync=False, filter_length=None, initial_epoch=0, input_channels=None, latitude=0, longitude=None, prediction_channels=None, prediction_length=None, repeat_samples=1, sample_weights=None, shuffle=True, sph_degree=None, strides=1, time=None, tp_period=None, dtype='float32', **kwargs)\n</code></pre> <p>             Bases: <code>FitGenerator</code></p> <p>Generator class for model prediction.</p> <p>The generator prepares the inputs for the model prediction with :func:<code>ks.Model.predict</code>.</p> <p>Parameters:</p> <ul> <li> <code>**kwargs</code>         \u2013          <p>See :class:<code>FitGenerator</code> for parameters.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Dictionary containing the inputs for the model prediction.</p> </li> </ul> Source code in <code>VAE/generators.py</code> <pre><code>def __init__(self,\n             datasets: Union[np.ndarray, list[np.ndarray]],\n             input_length: int,\n             batch_size: int = 32,\n             beta_scheduler=None,\n             condition: Union[np.ndarray, list[np.ndarray], dict] = None,\n             ensemble_size: int = None,\n             ensemble_type: str = 'random',\n             ensemble_index: int = None,\n             ensemble_range: tuple[int, int] = None,\n             ensemble_replace: bool = False,\n             ensemble_sync: bool = False,\n             filter_length: Union[int, tuple[int, int]] = None,\n             initial_epoch: int = 0,\n             input_channels: list[int] = None,\n             latitude: np.ndarray = 0,\n             longitude: np.ndarray = None,\n             prediction_channels: list[int] = None,\n             prediction_length: int = None,\n             repeat_samples: int = 1,\n             sample_weights: np.ndarray = None,\n             shuffle: bool = True,\n             sph_degree: int = None,\n             strides: int = 1,\n             time: Union[np.ndarray, list[np.ndarray]] = None,\n             tp_period: float = None,\n             dtype: str = 'float32',\n             **kwargs):\n    \"\"\"Instantiate generator.\"\"\"\n    if not isinstance(datasets, (list, tuple)):\n        datasets = [datasets]\n\n    shapes = {dataset[:, 0, :].shape for dataset in datasets}\n    if len(shapes) &gt; 1:\n        raise ValueError('all datasets must have the same set_size and number of channels')\n\n    set_size, channels = shapes.pop()\n    self.channels = channels\n    self.set_size = set_size\n\n    self.batch_size = batch_size\n    self.beta_scheduler = beta_scheduler\n    self.datasets = datasets\n    self.dtype = dtype\n    self.ensemble_replace = ensemble_replace\n    self.ensemble_size = ensemble_size\n    self.ensemble_sync = ensemble_sync\n    self.epoch = initial_epoch\n    self.filter_length = np.broadcast_to(filter_length, (2, ))\n    self.input_length = input_length\n    self.repeat_samples = repeat_samples\n    self.shuffle = shuffle\n    self.strides = strides\n    self.prediction_length = prediction_length if prediction_length is not None else 0\n\n    self.input_channels = slice(*input_channels) if input_channels is not None else slice(None)\n    self.prediction_channels = slice(*prediction_channels) if prediction_channels is not None else slice(None)\n\n    if condition is not None:\n        if not isinstance(condition, dict):\n            # same condition for encoder and decoder\n            condition = {'encoder': condition}\n        else:\n            if 'encoder' not in condition.keys():\n                raise KeyError('Require at least `encoder` item in `condition`.')\n\n        # prepare condition\n        for key, value in condition.items():\n            if isinstance(value, (list, tuple)):\n                condition.update({key: [self._prepare_condition(v) for v in value]})\n            else:\n                condition.update({key: self._prepare_condition(value)})\n\n    self.condition = condition\n\n    if ensemble_size is not None:\n        if ensemble_range is None:\n            ensemble_range = (0, ensemble_size)\n\n        if repeat_samples &gt; len(range(*ensemble_range)) and not ensemble_replace:\n            error_msg = f'{repeat_samples=} must not be larger than {ensemble_range=}' \\\n                f' if sampling without replacement ({ensemble_replace=})'\n            raise ValueError(error_msg)\n\n        val_ensemble_type = {'index', 'random', 'random_full'}\n        if ensemble_type not in val_ensemble_type:\n            raise ValueError(f'{ensemble_type=} must be in {val_ensemble_type}')\n\n    self.ensemble_index = np.array(ensemble_index) if ensemble_index is not None else None\n    self.ensemble_type = ensemble_type\n    self.ensemble_range = ensemble_range\n\n    self._prepare_embedding()\n    if self.shuffle:\n        self._shuffle_data()\n\n    if tp_period is not None:\n        if time is None:\n            raise ValueError('time must be given if tp_period is given')\n\n        if isinstance(time, (list, tuple)):\n            if len(time) == len(datasets):\n                self.tp_harmonics = [self.get_tp_harmonics(t, tp_period) for t in time]\n            else:\n                raise ValueError('Length of `time` must match length of `datasets`')\n        else:\n            self.tp_harmonics = self.get_tp_harmonics(time, tp_period)\n\n    else:\n        self.tp_harmonics = None\n\n    if sph_degree is not None:\n        if longitude is None:\n            longitude = np.arange(0, 360, 360 / set_size)\n\n        self.sph_harmonics = self.get_sph_harmonics(latitude, longitude, sph_degree)\n    else:\n        self.sph_harmonics = None\n\n    if sample_weights is not None:\n        if len(sample_weights) != len(datasets):\n            raise ValueError('`sample_weights` must have the same length as `datasets`')\n\n    self.sample_weights = sample_weights\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.PredictGenerator.__getitem__","title":"VAE.generators.PredictGenerator.__getitem__","text":"<pre><code>__getitem__(idx)\n</code></pre> <p>Return inputs to the model for given batch.</p> Source code in <code>VAE/generators.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; dict:\n    \"\"\"Return inputs to the model for given batch.\"\"\"\n    inputs, _ = super().__getitem__(idx)\n    return inputs\n</code></pre>"},{"location":"VAE.generators/#VAE.generators.example_FitGenerator","title":"VAE.generators.example_FitGenerator","text":"<pre><code>example_FitGenerator()\n</code></pre> <p>Example of :class:<code>FitGenerator</code>.</p> <p>This example shows how to use the :class:<code>FitGenerator</code> class.</p> Source code in <code>VAE/generators.py</code> <pre><code>def example_FitGenerator():\n    \"\"\"Example of :class:`FitGenerator`.\n\n    This example shows how to use the :class:`FitGenerator` class.\n\n    \"\"\"\n\n    # first we create some dummy data\n    shape = (1, 32, 3)  # (set_size, data_length, channels)\n    dataset = np.reshape(np.arange(np.prod(shape)), shape)\n    datasets = [dataset] * 3\n\n    # the corresponding time values\n    time = range(shape[1])\n\n    # and the corresponding conditions\n    # the encoder and decoder conditions are different\n    encoder_cond = np.linspace(-1, 1, 32)\n    decoder_cond = np.linspace(1, -1, 32)\n\n    # then we create the generator\n    fit_gen = FitGenerator(datasets,\n                           condition={\n                               'encoder': encoder_cond,\n                               'decoder': decoder_cond\n                           },\n                           input_length=1,\n                           prediction_length=4,\n                           batch_size=128,\n                           ensemble_size=len(datasets),\n                           ensemble_type='index',\n                           tp_period=12,\n                           time=time,\n                           shuffle=False)\n\n    # we can see the summary of the generator\n    fit_gen.summary()\n\n    # we can now use the generator to get the inputs for the model\n    inputs, *_ = fit_gen[0]\n\n    # we can plot the inputs, to see what the model will get\n    # we show the encoder and decoder conditions\n    fig, (lax, rax) = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(16, 5))\n    lax.pcolormesh(inputs['encoder_cond'][:, 0, :])\n    lax.set_title(\"inputs['encoder_cond']\")\n    mp = rax.pcolormesh(inputs['decoder_cond'][:, 0, :])\n    rax.set_title(\"inputs['decoder_cond']\")\n\n    fig.colorbar(mp, ax=(lax, rax))\n</code></pre>"},{"location":"VAE.layers/","title":"Layers","text":""},{"location":"VAE.layers/#VAE.layers","title":"VAE.layers","text":"<p>Collection of Keras layers.</p>"},{"location":"VAE.layers/#VAE.layers.Attention","title":"VAE.layers.Attention","text":"<pre><code>Attention(activation='softmax', permute=None, **kwargs)\n</code></pre> <p>             Bases: <code>Layer</code></p> <p>Dot-product attention layer.</p> <p>This layers builds on the attention layer :class:<code>keras.layers.Attention</code>. The matrix multiplication in the attention is applied to the two inner dimensions and broadcasted otherwise. Use <code>permute</code> to reorder the input before attention. The output has again the same order of dimenions as the input.</p> <p>Parameters:</p> <ul> <li> <code>activation</code>             (<code>str</code>, default:                 <code>'softmax'</code> )         \u2013          <p>Name of activation function applied to the score. Defaults to 'softmax'.</p> </li> <li> <code>permute</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Permutation applied to the dimensions of the input tensors before attention. The output has the same order of dimenions as the input. Defaults to <code>None</code>, meaning that no permutation is applied.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments passed to the <code>Layer</code> superclass.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def __init__(self, activation: str = 'softmax', permute: list[int] = None, **kwargs):\n    super().__init__(**kwargs)\n\n    self.activation = ks.activations.get(activation)\n    self.permute = permute\n    self.ipermute = None\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.Attention.call","title":"VAE.layers.Attention.call","text":"<pre><code>call(inputs)\n</code></pre> <p>Call the layer.</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>tuple[Tensor, Tensor, Tensor]</code>)         \u2013          <p>Tuple of three tensors representing the query, key, and value, respectively. The shapes of the three tensors is <code>(batch_size, set_size, time_length, channels)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor of shape <code>(batch_size, set_size, time_length, channels)</code>.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def call(self, inputs: tuple[tf.Tensor, tf.Tensor, tf.Tensor]) -&gt; tf.Tensor:\n    \"\"\"Call the layer.\n\n    Parameters:\n        inputs:\n            Tuple of three tensors representing the query, key, and value, respectively. The shapes of the three\n            tensors is `(batch_size, set_size, time_length, channels)`.\n\n    Returns:\n        Tensor of shape `(batch_size, set_size, time_length, channels)`.\n\n    \"\"\"\n    q, k, v = inputs\n\n    if self.permute is not None:\n        q = tf.transpose(q, perm=self.permute)\n        k = tf.transpose(k, perm=self.permute)\n        v = tf.transpose(v, perm=self.permute)\n\n    qk = tf.matmul(q, k, transpose_b=True)\n    qk = self.activation(qk)\n    qkv = tf.matmul(qk, v)\n\n    if self.ipermute is not None:\n        qkv = tf.transpose(qkv, perm=self.ipermute)\n\n    return qkv\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.AttentionMasked","title":"VAE.layers.AttentionMasked","text":"<pre><code>AttentionMasked(activation='softmax', masked=True, permute=None, **kwargs)\n</code></pre> <p>             Bases: <code>Layer</code></p> <p>Dot-product attention layer.</p> <p>This layers builds on the attention layer :class:<code>keras.layers.Attention</code>. Each input tensor of shape <code>(batch_size, set_size, time_length, channels)</code> is first reshaped into a tensor of shape <code>(batch_size, set_size * time_length, channels)</code>. The dot-product attention is applied on the last dimension. If <code>masked=True</code>, score values with a query time index larger than the key time index are masked out.</p> <p>Parameters:</p> <ul> <li> <code>activation</code>             (<code>str</code>, default:                 <code>'softmax'</code> )         \u2013          <p>Activation function applied to the scores. Defaults to 'softmax'.</p> </li> <li> <code>masked</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether a causal masked is applied to the scores. Defaults to <code>True</code>.</p> </li> <li> <code>permute</code>             (<code>tuple[int, int, int]</code>, default:                 <code>None</code> )         \u2013          <p>More general permutation of the dimensions of the input tensors before attention.  Note that the time index of the causal mask always refers to the second dimension of the permuted dimensions. Defaults to <code>None</code>, meaning that no permutation is applied.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments passed to the <code>Layer</code> superclass.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def __init__(self,\n             activation: str = 'softmax',\n             masked: bool = True,\n             permute: tuple[int, int, int] = None,\n             **kwargs):\n    super().__init__(**kwargs)\n    self.activation = ks.activations.get(activation)\n    self.masked = masked\n    self.permute = permute\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.AttentionMasked.call","title":"VAE.layers.AttentionMasked.call","text":"<pre><code>call(inputs)\n</code></pre> <p>Apply the the dot-product attention to the inputs.</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>tuple[Tensor, Tensor, Tensor]</code>)         \u2013          <p>Tuple of three tensors representing the query, key, and value, respectively. The shapes of the three tensors is <code>(batch_size, set_size, time_length, channels)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor of shape <code>(batch_size, set_size, time_length, channels)</code>.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def call(self, inputs: tuple[tf.Tensor, tf.Tensor, tf.Tensor]) -&gt; tf.Tensor:\n    \"\"\"Apply the the dot-product attention to the inputs.\n\n    Parameters:\n        inputs:\n            Tuple of three tensors representing the query, key, and value, respectively. The shapes of the three\n            tensors is `(batch_size, set_size, time_length, channels)`.\n\n    Returns:\n        Tensor of shape `(batch_size, set_size, time_length, channels)`.\n\n    \"\"\"\n    q, k, v = inputs\n\n    # permute dimensions\n    if self.permute is not None:\n        q = tf.transpose(q, perm=self.permute)\n        k = tf.transpose(k, perm=self.permute)\n        v = tf.transpose(v, perm=self.permute)\n\n    q_shape = tf.shape(q)\n    k_shape = tf.shape(k)\n    v_shape = tf.shape(v)\n\n    q = tf.reshape(q, shape=(-1, q_shape[1] * q_shape[2], q_shape[3]))\n    k = tf.reshape(k, shape=(-1, k_shape[1] * k_shape[2], k_shape[3]))\n    v = tf.reshape(v, shape=(-1, v_shape[1] * v_shape[2], v_shape[3]))\n\n    # get dot product of queries and keys\n    qk = tf.matmul(q, k, transpose_b=True)\n    # scale\n    qk /= tf.sqrt(tf.cast(q_shape[-1], dtype=qk.dtype))\n    # apply mask to dot product: set masked positions to large negative values results in near zero activation\n    if self.mask is not None:\n        qk -= 1e9 * self.mask\n    # activation\n    qk = self.activation(qk)\n\n    # get output of attention\n    qkv = tf.matmul(qk, v)\n\n    # reshape output\n    qkv = tf.reshape(qkv, shape=v_shape)\n\n    # restore order of dimensions in output\n    if self.ipermute is not None:\n        qkv = tf.transpose(qkv, perm=self.ipermute)\n\n    return qkv\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.Film","title":"VAE.layers.Film","text":"<pre><code>Film(activation=None, use_scale=True, use_offset=True, use_bias=True, shape=None, kernel_initializer='glorot_uniform', bias_initializer='zeros', **kwargs)\n</code></pre> <p>             Bases: <code>Layer</code></p> <p>Feature-wise linear modulation.</p> <p>Feature-wise linear modulation of the last dimension of the input tensor.</p> <p>A linear layer is applied to the last dimension of the condition tensor and the output gives the scale that is multiplied with the input tensor. The scale can be activated by a non-linearity prior to the multiplication.</p> <p>Another linear layer is applied to the last dimension of the condition tensor and the output gives the offset that is added to the input tensor.</p> <p>The rank of the condition tensor can be smaller than the rank of the input tensor. In this case, the scale is applied according to shape parameter.</p> <p>Note: In this version of the FiLM layer, the shape parameter affects both, the scale and the offset.</p> <p>Parameters:</p> <ul> <li> <code>activation</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Activation function in the linear layer of the scale.</p> </li> <li> <code>use_scale</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use the scale.</p> </li> <li> <code>use_offset</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use the offset.</p> </li> <li> <code>use_bias</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use a bias in the linear layers of the scale and offset.</p> </li> <li> <code>shape</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Shape of the modulation. If None, the modulation is applied to the last dimension of the input. This is the default case from [1]. If shape is a tuple of length <code>n</code> (where <code>n = rank(input) - rank(condition) + 1</code>), the modulation is applied to the last <code>n</code> dimensions of the input according to the specified shape. Setting values to <code>None</code> in the shape tuple results in the modulation being applied to this dimension. Setting values to 1 in the shape results in the modulation being broadcasted to this dimension.Default is None.</p> </li> <li> <code>kernel_initializer</code>             (<code>str</code>, default:                 <code>'glorot_uniform'</code> )         \u2013          <p>Initializer for the kernel of the linear layers.</p> </li> <li> <code>bias_initializer</code>             (<code>str</code>, default:                 <code>'zeros'</code> )         \u2013          <p>Initializer for the bias of the linear layers.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments passed to the <code>Layer</code> superclass.</p> </li> </ul> <p>References:     [1] Perez et al. (2017): https://arxiv.org/abs/1709.07871.</p> Source code in <code>VAE/layers.py</code> <pre><code>def __init__(self,\n             activation: str = None,\n             use_scale: bool = True,\n             use_offset: bool = True,\n             use_bias: bool = True,\n             shape: list[int] = None,\n             kernel_initializer: str = 'glorot_uniform',\n             bias_initializer: str = 'zeros',\n             **kwargs):\n    self.activation = ks.activations.get(activation)\n    self.use_scale = use_scale\n    self.use_offset = use_offset\n    self.use_bias = use_bias\n    self.shape = shape\n    self.kernel_initializer = ks.initializers.get(kernel_initializer)\n    self.bias_initializer = ks.initializers.get(bias_initializer)\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.Film.call","title":"VAE.layers.Film.call","text":"<pre><code>call(inputs)\n</code></pre> <p>Apply FiLM to input tensor.</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>tuple[Tensor, Tensor]</code>)         \u2013          <p>Tuple of two tensors of arbitrary shape. The first tensor is the input. The second tensor is the condition. The <code>k - 1</code> leading dimensions of the condition tensor must be broadcastable to the first <code>k- 1</code> leading dimensions of the input tensor, where <code>k</code> is the rank of the condition tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor of the same shape as input tensor.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def call(self, inputs: tuple[tf.Tensor, tf.Tensor]) -&gt; tf.Tensor:\n    \"\"\"Apply FiLM to input tensor.\n\n    Parameters:\n        inputs:\n            Tuple of two tensors of arbitrary shape. The first tensor is the input. The second tensor is the\n            condition. The `k - 1` leading dimensions of the condition tensor must be broadcastable to the first\n            `k- 1` leading dimensions of the input tensor, where `k` is the rank of the condition tensor.\n\n    Returns:\n        Tensor of the same shape as input tensor.\n\n    \"\"\"\n    x, cond = inputs\n\n    # scale input\n    if self.use_scale:\n        gamma = tf.tensordot(cond, self.gamma_kernel, axes=[[-1], [0]])\n        if self.use_bias:\n            gamma += self.gamma_bias\n\n        if self.activation:\n            gamma = self.activation(gamma)\n\n        x *= gamma\n\n    # add offset\n    if self.use_offset:\n        beta = tf.tensordot(cond, self.beta_kernel, axes=[[-1], [0]])\n        if self.use_bias:\n            beta += self.beta_bias\n\n        x += beta\n\n    return x\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.GumbelSoftmax","title":"VAE.layers.GumbelSoftmax","text":"<pre><code>GumbelSoftmax(axis=-1, temperature=1.0, hard=False, noise_shape=None, **kwargs)\n</code></pre> <p>             Bases: <code>Layer</code></p> <p>Random sampling from Gumbel softmax distribution.</p> <p>This layer is used to sample from a Gumbel softmax distribution.</p> <p>Parameters:</p> <ul> <li> <code>axis</code>             (<code>int</code>, default:                 <code>-1</code> )         \u2013          <p>The axis along which to apply the Gumbel softmax. Default is last axis.</p> </li> <li> <code>temperature</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>The temperature of the Gumbel softmax. Default is 1.</p> </li> <li> <code>hard</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to sample from the hard or soft Gumbel distribution.</p> </li> <li> <code>noise_shape</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>The shape of the random noise. Must be of the same length as the number of dimensions in the input. <code>None</code> values in the tuple can be used to infer the shape from the input shape. If <code>None</code>, the noise shape will be equal to the shape of the input. Default is <code>None</code>.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments passed to the <code>Layer</code> superclass.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def __init__(self,\n             axis: int = -1,\n             temperature: float = 1.,\n             hard: bool = False,\n             noise_shape: list[int] = None,\n             **kwargs):\n    self.axis = axis\n    self.temperature = temperature\n    self.hard = hard\n    self.noise_shape = noise_shape\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.GumbelSoftmax.call","title":"VAE.layers.GumbelSoftmax.call","text":"<pre><code>call(inputs)\n</code></pre> <p>Apply Gumbel softmax to input tensor.</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>Tensor</code>)         \u2013          <p>Tensor of arbitrary shape. The input is expected to be logits.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor of the same shape as input tensor.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Apply Gumbel softmax to input tensor.\n\n    Parameters:\n        inputs:\n            Tensor of arbitrary shape. The input is expected to be logits.\n\n    Returns:\n        Tensor of the same shape as input tensor.\n\n    \"\"\"\n    x = inputs\n    shape = complete_shape(x, self.noise_shape)\n    u = tf.random.uniform(shape, minval=0, maxval=1)\n    eps = K.epsilon()\n    g = -tf.math.log(-tf.math.log(u + eps) + eps)\n    y = x + g\n    y = tf.nn.softmax(y / self.temperature, axis=self.axis)\n    if self.hard:\n        y_hard = tf.one_hot(tf.argmax(y, axis=self.axis), depth=tf.shape(y)[self.axis], axis=self.axis)\n        y_hard = tf.cast(y_hard, x.dtype)\n        y = tf.stop_gradient(y_hard - y) + y\n    return y\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.RandomSampling","title":"VAE.layers.RandomSampling","text":"<pre><code>RandomSampling(noise_shape=None, **kwargs)\n</code></pre> <p>             Bases: <code>Layer</code></p> <p>Random sampling from normal distribution.</p> <p>This layer samples from an isotropic Gaussian with mean <code>z_mean</code> and log variance <code>z_log_var</code>.</p> <p>Parameters:</p> <ul> <li> <code>noise_shape</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>The shape of the random noise. Must be of the same length as the number of dimensions in the input and be broadcastable to the shape of the input. If <code>None</code>, the noise shape will be equal to the shape of the input. Default is <code>None</code>.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments passed to the <code>Layer</code> superclass.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def __init__(self, noise_shape: list[int] = None, **kwargs):\n    self.noise_shape = noise_shape\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.RandomSampling.call","title":"VAE.layers.RandomSampling.call","text":"<pre><code>call(inputs)\n</code></pre> <p>Sample from normal distribution.</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>tuple[Tensor, Tensor]</code>)         \u2013          <p>Tuple of two or three tensors of the same shape. The first tensor is the mean of the normal distribution, the second tensor is the logarithm of the variance of the normal distribution. If a third tensor is given, it is used as the random sample. Otherwise, a random sample is generated.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor of the same shape as input tensors.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def call(self, inputs: tuple[tf.Tensor, tf.Tensor]) -&gt; tf.Tensor:\n    \"\"\"Sample from normal distribution.\n\n    Parameters:\n        inputs:\n            Tuple of two or three tensors of the same shape. The first tensor is the mean of the normal\n            distribution, the second tensor is the logarithm of the variance of the normal distribution. If a third\n            tensor is given, it is used as the random sample. Otherwise, a random sample is generated.\n\n    Returns:\n        Tensor of the same shape as input tensors.\n\n    \"\"\"\n    if len(inputs) == 2:\n        z_mean, z_log_var = inputs\n        shape = complete_shape(z_mean, self.noise_shape)\n        sigma = tf.random.normal(shape=shape)\n    else:\n        z_mean, z_log_var, sigma = inputs\n\n    return z_mean + tf.exp(0.5 * z_log_var) * sigma\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.Split","title":"VAE.layers.Split","text":"<pre><code>Split(size_splits, axis=0, **kwargs)\n</code></pre> <p>             Bases: <code>Layer</code></p> <p>Split input tensor into smaller chunks.</p> <p>Parameters:</p> <ul> <li> <code>size_splits</code>             (<code>list[int]</code>)         \u2013          <p>Containing the sizes of each output tensor along <code>axis</code>.</p> </li> <li> <code>axis</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>The dimension along which to split. Defaults to 0.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments passed to the <code>Layer</code> superclass.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def __init__(self, size_splits: list[int], axis: int = 0, **kwargs):\n    self.size_splits = size_splits\n    self.axis = axis\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.Split.call","title":"VAE.layers.Split.call","text":"<pre><code>call(inputs)\n</code></pre> <p>Split input tensor into smaller chunks.</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>Tensor</code>)         \u2013          <p>A tensor of arbitrary shape.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Tensor]</code>         \u2013          <p>A list of tensors.</p> </li> </ul> Source code in <code>VAE/layers.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; list[tf.Tensor]:\n    \"\"\"Split input tensor into smaller chunks.\n\n    Parameters:\n        inputs:\n            A tensor of arbitrary shape.\n\n    Returns:\n        A list of tensors.\n\n    \"\"\"\n    return tf.split(inputs, self.size_splits, self.axis)\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.example_Film","title":"VAE.layers.example_Film","text":"<pre><code>example_Film()\n</code></pre> <p>Example of Film layer.</p> Source code in <code>VAE/layers.py</code> <pre><code>def example_Film():\n    \"\"\"Example of Film layer.\"\"\"\n    input_shape = (1, 16, 12)\n    cond_shape = (10, )\n    x = tf.constant(1., shape=(32, ) + input_shape)\n    c = tf.constant(1., shape=(32, ) + cond_shape)\n    x_in = ks.layers.Input(shape=input_shape)\n    cond_in = ks.layers.Input(shape=cond_shape)\n    out = Film(\n        use_scale=True,\n        use_offset=True,\n        use_bias=True,\n        shape=(1, None, None),\n    )([x_in, cond_in])\n    model = ks.Model(inputs=[x_in, cond_in], outputs=out)\n    model.summary()\n    _ = model.predict([x, c])\n    for w in model.weights:\n        print(w.name, ':', w.shape)\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.example_GumbelSoftmax","title":"VAE.layers.example_GumbelSoftmax","text":"<pre><code>example_GumbelSoftmax()\n</code></pre> <p>Example of GumbelSoftmax layer.</p> Source code in <code>VAE/layers.py</code> <pre><code>def example_GumbelSoftmax():\n    \"\"\"Example of GumbelSoftmax layer.\"\"\"\n    input_shape = (5, 4)\n    x = tf.zeros((2, ) + input_shape)\n    x_in = ks.layers.Input(shape=input_shape)\n    out = GumbelSoftmax(axis=-1, hard=True, noise_shape=(None, 1, None))(x_in)\n    model = ks.Model(inputs=x_in, outputs=out)\n    y = model.predict(x)\n    print(y)\n</code></pre>"},{"location":"VAE.layers/#VAE.layers.example_RandomSampling","title":"VAE.layers.example_RandomSampling","text":"<pre><code>example_RandomSampling()\n</code></pre> <p>Example of RandomSampling layer.</p> Source code in <code>VAE/layers.py</code> <pre><code>def example_RandomSampling():\n    \"\"\"Example of RandomSampling layer.\"\"\"\n    input_shape = (5, 4)\n    z_mean = tf.zeros((2, ) + input_shape)\n    z_log_var = tf.zeros((2, ) + input_shape)\n    z_mean_in = ks.layers.Input(shape=input_shape)\n    z_log_var_in = ks.layers.Input(shape=input_shape)\n    out = RandomSampling(noise_shape=(None, 1, None))([z_mean_in, z_log_var_in])\n    model = ks.Model(inputs=[z_mean_in, z_log_var_in], outputs=out)\n    z = model.predict([z_mean, z_log_var])\n    print(z)\n</code></pre>"},{"location":"VAE.logs/","title":"Logs","text":""},{"location":"VAE.logs/#VAE.logs","title":"VAE.logs","text":"<p>Collection of log functions for model training.</p>"},{"location":"VAE.logs/#VAE.logs.ActiveUnits","title":"VAE.logs.ActiveUnits","text":"<pre><code>ActiveUnits(z_mean, z_log_var, kl_threshold=0.1)\n</code></pre> <p>Number of active units.</p> <p>Return metric for number of active units that are above the threshold specified in <code>kl_threshold</code>.</p> <p>Parameters:</p> <ul> <li> <code>z_mean</code>             (<code>Tensor</code>)         \u2013          <p>Output node of encoder, specifying <code>z_mean</code>.</p> </li> <li> <code>z_log_var</code>             (<code>Tensor</code>)         \u2013          <p>Output node of encoder, specifying <code>z_log_var</code>.</p> </li> <li> <code>kl_threshold</code>             (<code>float</code>, default:                 <code>0.1</code> )         \u2013          <p>Lower bound for the KL divergence above which a latent dimension is assumed to be active.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Metrics that returns the number of active units.</p> </li> </ul> Source code in <code>VAE/logs.py</code> <pre><code>def ActiveUnits(z_mean: tf.Tensor, z_log_var: tf.Tensor, kl_threshold: float = 0.1) -&gt; callable:\n    \"\"\"Number of active units.\n\n    Return metric for number of active units that are above the threshold specified in `kl_threshold`.\n\n    Parameters:\n        z_mean:\n            Output node of encoder, specifying `z_mean`.\n        z_log_var:\n            Output node of encoder, specifying `z_log_var`.\n        kl_threshold:\n            Lower bound for the KL divergence above which a latent dimension is assumed to be active.\n\n    Returns:\n        Metrics that returns the number of active units.\n\n    \"\"\"\n    def active_units(y_true, y_pred):\n        \"\"\"Prepare function that takes y_true and y_pred as input\"\"\"\n        kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n        kl_loss *= -0.5\n        kl_loss = tf.reduce_mean(kl_loss, axis=0)\n        is_active = tf.greater(kl_loss, kl_threshold)\n        is_active = tf.cast(is_active, kl_loss.dtype)\n\n        return tf.reduce_sum(is_active)\n\n    return active_units\n</code></pre>"},{"location":"VAE.logs/#VAE.logs.Beta","title":"VAE.logs.Beta","text":"<pre><code>Beta(beta)\n</code></pre> <p>Beta value.</p> <p>Returns metrics for beta value, which can be added to the model metrics for logging purposes.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>             (<code>Tensor</code>)         \u2013          <p>Beta multiplier of the KL divergence.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Metric function that reduces the beta tensor to a scalar.</p> </li> </ul> Source code in <code>VAE/logs.py</code> <pre><code>def Beta(beta: tf.Tensor) -&gt; callable:\n    \"\"\"Beta value.\n\n    Returns metrics for beta value, which can be added to the model metrics for logging purposes.\n\n    Parameters:\n        beta:\n            Beta multiplier of the KL divergence.\n\n    Returns:\n        Metric function that reduces the beta tensor to a scalar.\n    \"\"\"\n    def beta_value(y_true, y_pred):\n        return tf.reduce_mean(beta)\n\n    return beta_value\n</code></pre>"},{"location":"VAE.losses/","title":"Losses","text":""},{"location":"VAE.losses/#VAE.losses","title":"VAE.losses","text":"<p>Collection of loss functions.</p>"},{"location":"VAE.losses/#VAE.losses.KLDivergence","title":"VAE.losses.KLDivergence","text":"<pre><code>KLDivergence(z_mean, z_log_var, kl_threshold=None, free_bits=None)\n</code></pre> <p>Kullback-Leibler divergence.</p> <p>This is the KL divergence between N(<code>z_mean</code>, <code>z_log_var</code>) and the prior N(0, 1).</p> <p>Parameters:</p> <ul> <li> <code>z_mean</code>             (<code>Tensor</code>)         \u2013          <p>Tensor of shape <code>(batch_size, latent_dim)</code> specifying mean.</p> </li> <li> <code>z_log_var</code>             (<code>Tensor</code>)         \u2013          <p>Tensor of shape <code>(batch_size, latent_dim)</code> specifying log of variance.</p> </li> <li> <code>kl_threshold</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Lower bound for the KL divergence. Default is <code>None</code>.</p> </li> <li> <code>free_bits</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Number of bits to keep free for the KL divergence per latent dimension; cf. Appendix C8 in [1]. Default is <code>None</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Loss function that returns a tensor of shape <code>(batch_size, 1, 1)</code>.</p> </li> </ul> References <p>[1] Kingma et al. (2016): Improved Variational Inference with Inverse Autoregressive Flow. NIPS 2016.</p> Source code in <code>VAE/losses.py</code> <pre><code>def KLDivergence(z_mean: tf.Tensor,\n                 z_log_var: tf.Tensor,\n                 kl_threshold: float = None,\n                 free_bits: float = None) -&gt; callable:\n    \"\"\"Kullback-Leibler divergence.\n\n    This is the KL divergence between N(`z_mean`, `z_log_var`) and the prior N(0, 1).\n\n    Parameters:\n        z_mean:\n            Tensor of shape `(batch_size, latent_dim)` specifying mean.\n        z_log_var:\n            Tensor of shape `(batch_size, latent_dim)` specifying log of variance.\n        kl_threshold:\n            Lower bound for the KL divergence. Default is `None`.\n        free_bits:\n            Number of bits to keep free for the KL divergence per latent dimension; cf. Appendix C8 in [1]. Default is\n            `None`.\n\n    Returns:\n        Loss function that returns a tensor of shape `(batch_size, 1, 1)`.\n\n    References:\n        [1] Kingma et al. (2016): Improved Variational Inference with Inverse Autoregressive Flow. NIPS 2016.\n\n    \"\"\"\n    def kl_divergence(y_true, y_pred):\n        # KL divergence to N(0, 1) of shape (batch_size, latent_dim)\n        kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n        kl_loss *= -0.5\n\n        # apply threshold per latent dimension\n        if free_bits is not None:\n            kl_loss = tf.maximum(kl_loss, free_bits)\n\n        # reduce to shape (batch_size, 1)\n        kl_loss = tf.reduce_sum(kl_loss, axis=-1, keepdims=True)\n\n        # apply global threshold\n        if kl_threshold is not None:\n            kl_loss = tf.maximum(kl_loss, kl_threshold)\n\n        # expand to shape (batch_size, 1, 1)\n        kl_loss = tf.expand_dims(kl_loss, axis=-1)\n\n        return kl_loss\n\n    return kl_divergence\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.SquaredError","title":"VAE.losses.SquaredError","text":"<pre><code>SquaredError(size=1, taper=None)\n</code></pre> <p>Squared error loss.</p> <p>This is the reconstruction loss of the model, without the KL divergence.</p> <p>Parameters:</p> <ul> <li> <code>size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Size of the model output of shape <code>(set_size, output_length, channels)</code>.</p> </li> <li> <code>taper</code>             (<code>array_like</code>, default:                 <code>None</code> )         \u2013          <p>Array of length <code>output_length</code> to taper the squared error.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Loss function that returns a tensor of shape <code>(batch_size, set_size, 1)</code>.</p> </li> </ul> Source code in <code>VAE/losses.py</code> <pre><code>def SquaredError(size: int = 1, taper=None) -&gt; callable:\n    \"\"\"Squared error loss.\n\n    This is the reconstruction loss of the model, without the KL divergence.\n\n    Parameters:\n        size:\n            Size of the model output of shape `(set_size, output_length, channels)`.\n        taper (array_like):\n            Array of length `output_length` to taper the squared error.\n\n    Returns:\n        Loss function that returns a tensor of shape `(batch_size, set_size, 1)`.\n\n    \"\"\"\n    def squared_error(y_true, y_pred):\n        # losses reduce last channel dimension to shape (batch_size, set_size, output_length)\n        reconstruction_loss = ks.losses.mse(y_true, y_pred)\n        if taper is not None:\n            reconstruction_loss *= taper\n        # further reduce to shape (batch_size, set_size, 1)\n        reconstruction_loss = tf.reduce_mean(reconstruction_loss, axis=-1, keepdims=True)\n        # scale back to sum of squared errors\n        reconstruction_loss *= size\n\n        return reconstruction_loss\n\n    return squared_error\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.Similarity","title":"VAE.losses.Similarity","text":"<pre><code>Similarity(temperature=1.0)\n</code></pre> <p>Similarity loss.</p> <p>This loss flattens all but the leading batch dimension of <code>y_pred</code> to the shape <code>(batch_size, -1)</code>. The similarity is then calculated of the reshaped input.</p> <p>Parameters:</p> <ul> <li> <code>temperature</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Temperature for the softmax.</p> </li> </ul> <p>Returns:     Loss function.</p> Source code in <code>VAE/losses.py</code> <pre><code>def Similarity(temperature: float = 1.) -&gt; callable:\n    \"\"\"Similarity loss.\n\n    This loss flattens all but the leading batch dimension of `y_pred` to the shape `(batch_size, -1)`. The similarity\n    is then calculated of the reshaped input.\n\n    Parameters:\n        temperature:\n            Temperature for the softmax.\n    Returns:\n        Loss function.\n\n    \"\"\"\n    def sim(y_true, y_pred):\n        batch_size = tf.shape(y_pred)[0]\n        # flatten input to shape (batch_size, -1)\n        x = tf.reshape(y_pred, (batch_size, -1))\n        # compute similarity loss\n        loss = vaemath.similarity(x, temperature=temperature)\n        # broadcast loss to shape (batch_size, 1, 1)\n        loss = tf.reshape(loss, (-1, 1, 1))\n\n        return loss\n\n    return sim\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.SimilarityBetween","title":"VAE.losses.SimilarityBetween","text":"<pre><code>SimilarityBetween(repeat_samples=1, temperature=1.0)\n</code></pre> <p>Similarity between repeated samples (fast implementation).</p> <p>This function returns the similarity between repeated samples. The input <code>y_pred</code> is first reshaped to the shape <code>(batch_size // repeat_samples, repeat_samples, ...)</code> and the similarity is calculated for each slice along the first dimension.</p> <p>Note: This is an implementation with einsum that avoids calling :func:<code>math.similarity</code> with :func:<code>tf.map_fn</code>.</p> <p>Parameters:</p> <ul> <li> <code>repeat_samples</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of repeated samples.</p> </li> <li> <code>temperature</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Temperature for the softmax.</p> </li> </ul> <p>Returns:     Loss function.</p> Source code in <code>VAE/losses.py</code> <pre><code>def SimilarityBetween(repeat_samples: int = 1, temperature: float = 1.) -&gt; callable:\n    \"\"\"Similarity between repeated samples (fast implementation).\n\n    This function returns the similarity between repeated samples. The input `y_pred` is first reshaped to the shape\n    `(batch_size // repeat_samples, repeat_samples, ...)` and the similarity is calculated for each slice along the\n    first dimension.\n\n    Note: This is an implementation with einsum that avoids calling :func:`math.similarity` with :func:`tf.map_fn`.\n\n    Parameters:\n        repeat_samples:\n            Number of repeated samples.\n        temperature:\n            Temperature for the softmax.\n    Returns:\n        Loss function.\n\n    \"\"\"\n    def sim_between(y_true, y_pred):\n        batch_size = tf.shape(y_pred)[0]\n        # reshape to (batch_size // repreat_samples, repeat_samples, -1)\n        inputs = tf.reshape(y_pred, (batch_size // repeat_samples, repeat_samples, -1))\n        # normalize input\n        l2 = tf.math.l2_normalize(inputs, axis=-1)\n        # correlation matrices of slices along first axis, each of shape (repeat_samples, -1)\n        # shape (batch_size // repreat_samples, repeat_samples, repeat_samples)\n        similarity = tf.einsum('ijk, ilk -&gt; ijl', l2, l2)\n        # reshape to (batch_size, repeat_samples)\n        similarity = tf.reshape(similarity, (-1, repeat_samples))\n        # apply temperature\n        similarity /= temperature\n        # target labels = diagonal elements\n        labels = tf.tile(tf.range(repeat_samples), (batch_size // repeat_samples, ))\n        # cross entropy loss between target labels and similarity matrices\n        loss = ks.losses.sparse_categorical_crossentropy(labels, similarity, from_logits=True, axis=-1)\n\n        # broadcast to shape (batch_size, 1, 1)\n        loss = tf.reshape(loss, (-1, 1, 1))\n\n        return loss\n\n    return sim_between\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.TotalCorrelation","title":"VAE.losses.TotalCorrelation","text":"<pre><code>TotalCorrelation(z, z_mean, z_log_var)\n</code></pre> <p>Total correlation.</p> <p>The total correlation is already part of the KL divergence, see KL decomposition in [1]. This function only returns the batch-wise sampled total correlation loss that will be added on top of the KL divergence. The total correlation is computed separately for each step along the axis of length <code>set_size</code> of the input tensor <code>z</code>.</p> <p>Parameters:     z:         Sample from latent space of shape <code>(batch_size, set_size, latent_dim)</code>.     z_mean:         Mean of latent space of shape <code>(batch_size, latent_dim)</code>.     z_log_var:         Log of variance of latent space of shape <code>(batch_size, latent_dim)</code>.</p> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Loss function that returns a tensor of shape <code>(batch_size, set_size, 1)</code>.</p> </li> </ul> References <p>[1] Chen et al. (2018): Isolating sources of disentanglement in Variational Autoencoders.</p> Source code in <code>VAE/losses.py</code> <pre><code>def TotalCorrelation(z: tf.Tensor, z_mean: tf.Tensor, z_log_var: tf.Tensor) -&gt; callable:\n    \"\"\"Total correlation.\n\n    The total correlation is already part of the KL divergence, see KL decomposition in [1]. This function only returns\n    the batch-wise sampled total correlation loss that will be added on top of the KL divergence. The total correlation\n    is computed separately for each step along the axis of length `set_size` of the input tensor `z`.\n\n     Parameters:\n        z:\n            Sample from latent space of shape `(batch_size, set_size, latent_dim)`.\n        z_mean:\n            Mean of latent space of shape `(batch_size, latent_dim)`.\n        z_log_var:\n            Log of variance of latent space of shape `(batch_size, latent_dim)`.\n\n    Returns:\n        Loss function that returns a tensor of shape `(batch_size, set_size, 1)`.\n\n    References:\n        [1] Chen et al. (2018): Isolating sources of disentanglement in Variational Autoencoders.\n\n    \"\"\"\n    # expand to shape (batch_size, 1, latent_dim) for broadcasting with z of shape (batch_size, set_size, latent_dim)\n    z_mean = tf.expand_dims(z_mean, axis=1)\n    z_log_var = tf.expand_dims(z_log_var, axis=1)\n\n    def tc(y_true, y_pred) -&gt; tf.Tensor:\n        # log prob of all combinations along first axis of length batch_size\n        # shape (batch_size, batch_size, set_size, latent_dim)\n        mat_log_qz = vaemath.log_density_gaussian(z, z_mean, z_log_var, all_combinations=True, axis=0)\n\n        # log prob of joint distribution of shape (batch_size, set_size, 1)\n        log_qz = vaemath.reduce_logmeanexp(tf.reduce_sum(mat_log_qz, axis=-1, keepdims=True), axis=1)\n\n        # log prob of product of marginal distributions of shape (batch_size, set_size, 1)\n        log_prod_qz = tf.reduce_sum(vaemath.reduce_logmeanexp(mat_log_qz, axis=1), axis=-1, keepdims=True)\n\n        # total correlation loss of shape (batch_size, set_size, 1)\n        tc_loss = log_qz - log_prod_qz\n\n        return tc_loss\n\n    return tc\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.TotalCorrelationBetween","title":"VAE.losses.TotalCorrelationBetween","text":"<pre><code>TotalCorrelationBetween(z, z_mean, z_log_var, repeat_samples=1)\n</code></pre> <p>Total correlation between repeated samples.</p> <p>Returns the total correlation loss between repeated samples. This is the same as the total correlation but restricted to the same repeated samples. This means that <code>z_mean</code> and <code>z_log_var</code> are split into segments of length <code>repeat_samples</code> along the first axis and the total correlation is computed within each segment.</p> <p>This version of the total correlation is useful for the case where the model is trained with repeated input samples. It helps increase the diversity of the latent distribution between repeated samples.</p> <p>Parameters:</p> <ul> <li> <code>z</code>             (<code>Tensor</code>)         \u2013          <p>Sample from latent space of shape <code>(batch_size, set_size, latent_dim)</code>.</p> </li> <li> <code>z_mean</code>             (<code>Tensor</code>)         \u2013          <p>Mean of latent space of shape <code>(batch_size, latent_dim)</code>.</p> </li> <li> <code>z_log_var</code>             (<code>Tensor</code>)         \u2013          <p>Log of variance of latent space of shape <code>(batch_size, latent_dim)</code>.</p> </li> <li> <code>repeat_samples</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of repeated samples.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Loss function that returns a tensor of shape <code>(batch_size, set_size, 1)</code>.</p> </li> </ul> Source code in <code>VAE/losses.py</code> <pre><code>def TotalCorrelationBetween(z: tf.Tensor, z_mean: tf.Tensor, z_log_var: tf.Tensor, repeat_samples: int = 1) -&gt; callable:\n    \"\"\"Total correlation between repeated samples.\n\n    Returns the total correlation loss between repeated samples. This is the same as the total correlation but\n    restricted to the same repeated samples. This means that `z_mean` and `z_log_var` are split into segments of length\n    `repeat_samples` along the first axis and the total correlation is computed within each segment.\n\n    This version of the total correlation is useful for the case where the model is trained with repeated input samples.\n    It helps increase the diversity of the latent distribution between repeated samples.\n\n    Parameters:\n        z:\n            Sample from latent space of shape `(batch_size, set_size, latent_dim)`.\n        z_mean:\n            Mean of latent space of shape `(batch_size, latent_dim)`.\n        z_log_var:\n            Log of variance of latent space of shape `(batch_size, latent_dim)`.\n        repeat_samples:\n            Number of repeated samples.\n\n    Returns:\n        Loss function that returns a tensor of shape `(batch_size, set_size, 1)`.\n\n    \"\"\"\n    # reshape z_mean and z_log_var to shape (batch_size // repeat_samples, repeat_samples, 1, latent_dim)\n    z_mean = tf.reshape(z_mean, (-1, repeat_samples, 1, z_mean.shape[-1]))\n    z_log_var = tf.reshape(z_log_var, (-1, repeat_samples, 1, z_log_var.shape[-1]))\n\n    # reshape z to shape (batch_size // repeat_samples, repeat_samples, set_size, latent_dim)\n    z = tf.reshape(z, (-1, repeat_samples, z.shape[-2], z.shape[-1]))\n\n    def tc_between(y_true, y_pred):\n        # log prob of all combinations along second axis of size repeat_samples\n        # shape (batch_size // repeat_samples, repeat_samples, repeat_samples, set_size, latent_dim)\n        mat_log_qz = vaemath.log_density_gaussian(z, z_mean, z_log_var, all_combinations=True, axis=1)\n\n        # log prob of joint distribution, shape (batch_size // repeat_samples, repeat_samples, set_size, 1)\n        log_qz = vaemath.reduce_logmeanexp(tf.reduce_sum(mat_log_qz, axis=-1, keepdims=True), axis=2)\n\n        # log prob of product of marg. distribution, shape (batch_size // repeat_samples, repeat_samples, set_size, 1)\n        log_prod_qz = tf.reduce_sum(vaemath.reduce_logmeanexp(mat_log_qz, axis=2), axis=-1, keepdims=True)\n\n        # total correlation loss, shape (batch_size // repeat_samples, repeat_samples, set_size, 1)\n        tc_loss = log_qz - log_prod_qz\n\n        # reshape to shape (batch_size, set_size, 1)\n        tc_loss = tf.reshape(tc_loss, (-1, tc_loss.shape[-2], 1))\n\n        return tc_loss\n\n    return tc_between\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.TotalCorrelationWithin","title":"VAE.losses.TotalCorrelationWithin","text":"<pre><code>TotalCorrelationWithin(z, z_mean, z_log_var, repeat_samples=1)\n</code></pre> <p>Total correlation within repeated samples.</p> <p>Returns the total correlation loss within all samples of same repetition. This is the same as the total correlation but restricted to samples of the same repetition. This means that <code>z_mean</code> and <code>z_log_var</code> are split into strided views with stride <code>repeat_samples</code> along the first axis and the total correlation is computed within each view.</p> <p>Parameters:</p> <ul> <li> <code>z</code>             (<code>Tensor</code>)         \u2013          <p>Sample from latent space of shape <code>(batch_size, set_size, latent_dim)</code>.</p> </li> <li> <code>z_mean</code>             (<code>Tensor</code>)         \u2013          <p>Mean of latent space of shape <code>(batch_size, latent_dim)</code>.</p> </li> <li> <code>z_log_var</code>             (<code>Tensor</code>)         \u2013          <p>Log of variance of latent space of shape <code>(batch_size, latent_dim)</code>.</p> </li> <li> <code>repeat_samples</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of repeated samples.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Loss function that returns a tensor of shape <code>(batch_size, set_size, 1)</code>.</p> </li> </ul> Source code in <code>VAE/losses.py</code> <pre><code>def TotalCorrelationWithin(z: tf.Tensor, z_mean: tf.Tensor, z_log_var: tf.Tensor, repeat_samples: int = 1) -&gt; callable:\n    \"\"\"Total correlation within repeated samples.\n\n    Returns the total correlation loss within all samples of same repetition. This is the same as the total correlation\n    but restricted to samples of the same repetition. This means that `z_mean` and `z_log_var` are split into strided\n    views with stride `repeat_samples` along the first axis and the total correlation is computed within each view.\n\n    Parameters:\n        z:\n            Sample from latent space of shape `(batch_size, set_size, latent_dim)`.\n        z_mean:\n            Mean of latent space of shape `(batch_size, latent_dim)`.\n        z_log_var:\n            Log of variance of latent space of shape `(batch_size, latent_dim)`.\n        repeat_samples:\n            Number of repeated samples.\n\n    Returns:\n        Loss function that returns a tensor of shape `(batch_size, set_size, 1)`.\n\n    \"\"\"\n    # reshape z_mean and z_log_var to shape (batch_size // repeat_samples, repeat_samples, 1, latent_dim)\n    z_mean = tf.reshape(z_mean, (-1, repeat_samples, 1, z_mean.shape[-1]))\n    z_log_var = tf.reshape(z_log_var, (-1, repeat_samples, 1, z_log_var.shape[-1]))\n\n    # reshape z to shape (batch_size // repeat_samples, repeat_samples, set_size, latent_dim)\n    z = tf.reshape(z, (-1, repeat_samples, z.shape[-2], z.shape[-1]))\n\n    def tc_within(y_true, y_pred):\n        # log prob of all combinations along first axis of size batch_size // repeat_samples\n        # shape (batch_size // repeat_samples, batch_size // repeat_samples, repeat_samples, set_size, latent_dim)\n        mat_log_qz = vaemath.log_density_gaussian(z, z_mean, z_log_var, all_combinations=True, axis=0)\n\n        # log prob of joint distribution, shape (batch_size // repeat_samples, repeat_samples, set_size, 1)\n        log_qz = vaemath.reduce_logmeanexp(tf.reduce_sum(mat_log_qz, axis=-1, keepdims=True), axis=1)\n\n        # log prob of product of marg. distribution, shape (batch_size // repeat_samples, repeat_samples, set_size, 1)\n        log_prod_qz = tf.reduce_sum(vaemath.reduce_logmeanexp(mat_log_qz, axis=1), axis=-1, keepdims=True)\n\n        # total correlation loss, shape (batch_size // repeat_samples, repeat_samples, set_size, 1)\n        tc_loss = log_qz - log_prod_qz\n\n        # revert shape to (batch_size, set_size, 1)\n        tc_loss = tf.reshape(tc_loss, (-1, tc_loss.shape[-2], 1))\n\n        return tc_loss\n\n    return tc_within\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.VAEloss","title":"VAE.losses.VAEloss","text":"<pre><code>VAEloss(z, z_mean, z_log_var, beta=1.0, size=1, gamma=0.0, gamma_between=0.0, gamma_within=0.0, delta=0.0, delta_between=0.0, kl_threshold=None, free_bits=None, repeat_samples=1, taper=None)\n</code></pre> <p>Variational auto-encoder loss function.</p> <p>Loss function of variational auto-encoder, for use in :func:<code>models.VAE</code>. The input to the loss function has shape <code>(batch_size, set_size, output_length, channels)</code>. The output of the loss function has shape <code>(batch_size, set_size, 1)</code>. The sample weights from the generator must have shape <code>(batch_size, set_size)</code>. This will make the sample weights sample-dependent; see also <code>sample_weight_mode='temporal'</code> in model compile.</p> <p>Parameters:</p> <ul> <li> <code>z</code>             (<code>Tensor</code>)         \u2013          <p>Sample from latent space of shape <code>(batch_size, set_size, latent_dim)</code>.</p> </li> <li> <code>z_mean</code>             (<code>Tensor</code>)         \u2013          <p>Mean of latent space of shape <code>(batch_size, latent_dim)</code>.</p> </li> <li> <code>z_log_var</code>             (<code>Tensor</code>)         \u2013          <p>Log of variance of latent space of shape <code>(batch_size, latent_dim)</code>.</p> </li> <li> <code>size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Size of decoder output, i.e. total number of elements.</p> </li> <li> <code>beta</code>             (<code>Union[float, Tensor]</code>, default:                 <code>1.0</code> )         \u2013          <p>Loss weight of the KL divergence. If <code>beta</code> is a float, the loss weight is constant. If <code>beta</code> is a tensor, it should have shape <code>(batch_size, 1)</code>.</p> </li> <li> <code>gamma</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss. See :func:<code>losses.TotalCorrelation</code>.</p> </li> <li> <code>gamma_between</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss between repeated samples. See :func:<code>losses.TotalCorrelationBetween</code>.</p> </li> <li> <code>gamma_within</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss within repeated samples. See :func:<code>losses.TotalCorrelationWithin</code>.</p> </li> <li> <code>delta</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of similarity loss. See :func:<code>losses.Similarity</code>.</p> </li> <li> <code>delta_between</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of similarity loss between repeated samples. See :func:<code>losses.SimilarityBetween</code>.</p> </li> <li> <code>kl_threshold</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Lower bound for the KL divergence. See :func:<code>losses.KLDivergence</code>.</p> </li> <li> <code>free_bits</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Number of bits to keep free for the KL divergence per latent dimension. See :func:<code>losses.KLDivergence</code>.</p> </li> <li> <code>repeat_samples</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of repetitions of input samples present in the batch.</p> </li> <li> <code>taper</code>             (<code>array_like</code>, default:                 <code>None</code> )         \u2013          <p>Numpy array of length <code>output_length</code> to taper the squared error. See :func:<code>losses.SquaredError</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Loss function that returns a tensor of shape <code>(batch_size, set_size, 1)</code>.</p> </li> </ul> Source code in <code>VAE/losses.py</code> <pre><code>def VAEloss(z: tf.Tensor,\n            z_mean: tf.Tensor,\n            z_log_var: tf.Tensor,\n            beta: Union[float, tf.Tensor] = 1.,\n            size: int = 1,\n            gamma: float = 0.,\n            gamma_between: float = 0.,\n            gamma_within: float = 0.,\n            delta: float = 0.,\n            delta_between: float = 0.,\n            kl_threshold: float = None,\n            free_bits: float = None,\n            repeat_samples: int = 1,\n            taper=None) -&gt; callable:\n    \"\"\"Variational auto-encoder loss function.\n\n    Loss function of variational auto-encoder, for use in :func:`models.VAE`. The input to the loss function has shape\n    `(batch_size, set_size, output_length, channels)`. The output of the loss function has shape `(batch_size, set_size,\n    1)`. The sample weights from the generator must have shape `(batch_size, set_size)`. This will make the sample\n    weights sample-dependent; see also `sample_weight_mode='temporal'` in model compile.\n\n    Parameters:\n        z:\n            Sample from latent space of shape `(batch_size, set_size, latent_dim)`.\n        z_mean:\n            Mean of latent space of shape `(batch_size, latent_dim)`.\n        z_log_var:\n            Log of variance of latent space of shape `(batch_size, latent_dim)`.\n        size:\n            Size of decoder output, i.e. total number of elements.\n        beta:\n            Loss weight of the KL divergence. If `beta` is a float, the loss weight is constant. If `beta` is a\n            tensor, it should have shape `(batch_size, 1)`.\n        gamma:\n            Scale of total correlation loss. See :func:`losses.TotalCorrelation`.\n        gamma_between:\n            Scale of total correlation loss between repeated samples. See :func:`losses.TotalCorrelationBetween`.\n        gamma_within:\n            Scale of total correlation loss within repeated samples. See :func:`losses.TotalCorrelationWithin`.\n        delta:\n            Scale of similarity loss. See :func:`losses.Similarity`.\n        delta_between:\n            Scale of similarity loss between repeated samples. See :func:`losses.SimilarityBetween`.\n        kl_threshold:\n            Lower bound for the KL divergence. See :func:`losses.KLDivergence`.\n        free_bits:\n            Number of bits to keep free for the KL divergence per latent dimension. See :func:`losses.KLDivergence`.\n        repeat_samples:\n            Number of repetitions of input samples present in the batch.\n        taper (array_like):\n            Numpy array of length `output_length` to taper the squared error. See :func:`losses.SquaredError`.\n\n    Returns:\n        Loss function that returns a tensor of shape `(batch_size, set_size, 1)`.\n\n    \"\"\"\n    if isinstance(beta, tf.Tensor):\n        # add singleton dimension to beta to shape (batch_size, 1, 1)\n        beta = tf.expand_dims(beta, axis=-1)\n\n    def vae_loss(y_true, y_pred):\n        squared_error_fcn = SquaredError(size=size, taper=taper)\n        squared_error = squared_error_fcn(y_true, y_pred)\n\n        kl_loss_fcn = KLDivergence(z_mean, z_log_var, kl_threshold=kl_threshold, free_bits=free_bits)\n        entropy = kl_loss_fcn(y_true, y_pred)\n\n        if gamma:\n            tc_loss_fcn = TotalCorrelation(z, z_mean, z_log_var)\n            entropy += gamma * tc_loss_fcn(y_true, y_pred)\n\n        if gamma_between:\n            tc_between_loss_fcn = TotalCorrelationBetween(z, z_mean, z_log_var, repeat_samples=repeat_samples)\n            entropy += gamma_between * tc_between_loss_fcn(y_true, y_pred)\n\n        if gamma_within:\n            tc_within_loss_fcn = TotalCorrelationWithin(z, z_mean, z_log_var, repeat_samples=repeat_samples)\n            entropy += gamma_within * tc_within_loss_fcn(y_true, y_pred)\n\n        if delta:\n            sim_loss_fcn = Similarity()\n            entropy += delta * sim_loss_fcn(y_true, y_pred)\n\n        if delta_between:\n            sim_between_loss_fcn = SimilarityBetween(repeat_samples=repeat_samples)\n            entropy += delta * sim_between_loss_fcn(y_true, y_pred)\n\n        return squared_error + beta * entropy\n\n    return vae_loss\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.VAEploss","title":"VAE.losses.VAEploss","text":"<pre><code>VAEploss(beta=1.0, delta=0.0, delta_between=0.0, repeat_samples=1, size=1, taper=None)\n</code></pre> <p>VAE prediction loss function.</p> <p>Parameters:</p> <ul> <li> <code>beta</code>             (<code>Union[float, Tensor]</code>, default:                 <code>1.0</code> )         \u2013          <p>Loss weight of the KL divergence. If <code>beta</code> is a float, the loss weight is constant. If <code>beta</code> is a tensor, it should have shape <code>(batch_size, 1)</code>.</p> </li> <li> <code>delta</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of similarity loss. See :func:<code>losses.Similarity</code>.</p> </li> <li> <code>delta_between</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of similarity loss between repeated samples. See :func:<code>losses.SimilarityBetween</code>.</p> </li> <li> <code>size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Size of prediction output, i.e. total number of elements.</p> </li> <li> <code>repeat_samples</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of repetitions of input samples present in the batch.</p> </li> <li> <code>taper</code>             (<code>array_like</code>, default:                 <code>None</code> )         \u2013          <p>Array of length <code>output_length</code> to taper the squared error. See :func:<code>losses.SquaredError</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>         \u2013          <p>Loss function that returns a tensor of shape <code>(batch_size, set_size, 1)</code>.</p> </li> </ul> Source code in <code>VAE/losses.py</code> <pre><code>def VAEploss(beta: Union[float, tf.Tensor] = 1.,\n             delta: float = 0.,\n             delta_between: float = 0.,\n             repeat_samples: int = 1,\n             size: int = 1,\n             taper=None) -&gt; callable:\n    \"\"\"VAE prediction loss function.\n\n    Parameters:\n        beta:\n            Loss weight of the KL divergence. If `beta` is a float, the loss weight is constant. If `beta` is a\n            tensor, it should have shape `(batch_size, 1)`.\n        delta:\n            Scale of similarity loss. See :func:`losses.Similarity`.\n        delta_between:\n            Scale of similarity loss between repeated samples. See :func:`losses.SimilarityBetween`.\n        size:\n            Size of prediction output, i.e. total number of elements.\n        repeat_samples:\n            Number of repetitions of input samples present in the batch.\n        taper (array_like):\n            Array of length `output_length` to taper the squared error. See :func:`losses.SquaredError`.\n\n    Returns:\n        Loss function that returns a tensor of shape `(batch_size, set_size, 1)`.\n\n    \"\"\"\n    if isinstance(beta, tf.Tensor):\n        # add singleton dimension to beta to shape (batch_size, 1, 1)\n        beta = tf.expand_dims(beta, axis=-1)\n\n    def vaep_loss(y_true, y_pred):\n        squared_error_fcn = SquaredError(size=size, taper=taper)\n        squared_error = squared_error_fcn(y_true, y_pred)\n\n        entropy = tf.zeros_like(squared_error)\n\n        if delta:\n            sim_loss_fcn = Similarity()\n            entropy += delta * sim_loss_fcn(y_true, y_pred)\n\n        if delta_between:\n            sim_between_loss_fcn = SimilarityBetween(repeat_samples=repeat_samples)\n            entropy += delta_between * sim_between_loss_fcn(y_true, y_pred)\n\n        return squared_error + beta * entropy\n\n    return vaep_loss\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.example_total_correlation_losses","title":"VAE.losses.example_total_correlation_losses","text":"<pre><code>example_total_correlation_losses()\n</code></pre> <p>Example of total correlation loss functions.</p> Source code in <code>VAE/losses.py</code> <pre><code>def example_total_correlation_losses():\n    \"\"\"Example of total correlation loss functions.\"\"\"\n    batch_size = 32\n    repeat_samples = 20\n    shape = (batch_size * repeat_samples, 8)\n    set_size = 7\n\n    z_mean = tf.random.normal(shape)\n    z_log_var = tf.random.normal(shape) * 0.1 - 1.\n    z = z_mean + tf.exp(z_log_var * 0.5) * tf.random.normal(shape)\n    z = tf.expand_dims(z, axis=1)\n    z = tf.repeat(z, repeats=set_size, axis=1)\n\n    fcns = {\n        'TC loss': TotalCorrelation(z, z_mean, z_log_var),\n        'TC loss between': TotalCorrelationBetween(z, z_mean, z_log_var, repeat_samples=repeat_samples),\n        'TC loss within': TotalCorrelationWithin(z, z_mean, z_log_var, repeat_samples=repeat_samples),\n    }\n\n    print(f'{\"Batch size\":&lt;20} {batch_size} * {repeat_samples} = {batch_size * repeat_samples}')\n\n    for name, fcn in fcns.items():\n        tc_loss = fcn(None, None)\n        tc_mean = tf.reduce_mean(tc_loss)\n        tc_std = tf.math.reduce_std(tc_loss)\n        print(f'{name:&lt;20} mean={tc_mean:.2f}  std={tc_std:.2f}  shape={tc_loss.shape}')\n</code></pre>"},{"location":"VAE.losses/#VAE.losses.example_similarity_losses","title":"VAE.losses.example_similarity_losses","text":"<pre><code>example_similarity_losses()\n</code></pre> <p>Example of similarity loss functions.</p> Source code in <code>VAE/losses.py</code> <pre><code>def example_similarity_losses():\n    \"\"\"Example of similarity loss functions.\"\"\"\n    batch_size = 32\n    repeat_samples = 5\n    shape = (batch_size * repeat_samples, 1, 160, 3)\n\n    inputs = tf.random.normal(shape)\n\n    fcns = {\n        'Sim loss': Similarity(),\n        'Sim loss between': _SimilarityBetween(repeat_samples=repeat_samples),\n        'Sim loss between (fast)': SimilarityBetween(repeat_samples=repeat_samples),\n    }\n\n    print(f'{\"Batch size\":&lt;25} {batch_size} * {repeat_samples} = {batch_size * repeat_samples}')\n\n    losses = []\n    for name, fcn in fcns.items():\n        loss = fcn(None, inputs)\n        losses.append(loss)\n        mean_loss = tf.reduce_mean(loss)\n        std_loss = tf.math.reduce_std(loss)\n        print(f'{name:&lt;25} mean={mean_loss:.2f}  std={std_loss:.2f}  shape={loss.shape}')\n\n    return losses\n</code></pre>"},{"location":"VAE.models/","title":"Models","text":""},{"location":"VAE.models/#VAE.models","title":"VAE.models","text":"<p>Many-to-many version of variational auto-encoder.</p> Model specifications <ul> <li>Multiple set members (<code>set_size</code>) as time distributed layers, the leading dimension after the batch dimension.</li> <li>Input shape to encoder <code>(set_size, input_length, channels)</code>.</li> <li>Output shape of encoder <code>(latent_dim,)</code>: mean and log-variance of latent space, common to all members in set.</li> <li>Output shape of latent_sampling <code>(set_size, latent_dim)</code>: independent random samples for each member in set.</li> <li>Input shape to decoder <code>(set_size, latent_dim)</code>.</li> <li>Output shape of decoder <code>(set_size, input_length, channels)</code>.</li> <li>Masked multihead attention over filters x set_size. Temporal mask along dimension of size input_length.</li> <li>Residual blocks with causal convolution with pre-activation and pixel-shuffling for downsampling and upsampling</li> <li>Decoder with internal padding blocks</li> <li>3 FiLM blocks:     encoder: after input expansion, after encoder blocks, and after attention,     decoder: after input expansion, after sttention blocks, and decoder blocks</li> </ul>"},{"location":"VAE.models/#VAE.models.Encoder","title":"VAE.models.Encoder","text":"<pre><code>Encoder(input_shape, latent_dim, set_size=1, set_noise=True, encoder_blocks=0, residual_units=1, activation=None, depth_wise=False, filters=1, kernel_size=2, ratio=1, attn_activation='softmax', attn_blocks=0, attn_filters='full', attn_heads=1, attn_masked=True, attn_transposed=False, cond_activation=None, cond_size=None, cond_units=16, cond_use_bias=True, cond_use_scale=True, cond_use_offset=True, cond_ens_size=None, cond_temperature=1.0, fc_activation=None, fc_units=None, film_activation=None, film_temporal=False, film_use_bias=True, film_use_scale=True, film_use_offset=True, pooling='reduce_sum', name='encoder', **kwargs)\n</code></pre> <p>Encoder model.</p> <p>This function creates an encoder model, for use in :func:<code>VAEp</code>, for example. This model takes multiple set members as input and returns a single <code>z_mean</code> and <code>z_log_var</code> via pooling.</p> <p>Parameters:</p> <ul> <li> <code>input_shape</code>             (<code>tuple[int, int]</code>)         \u2013          <p>Input shape of the encoder. A tuple of two integers <code>(input_length, channels)</code>, with <code>input_length</code> being the length of the input sequence and <code>channels</code> being the number of input channels. If the input length is not a power of 2, the input will be zero-padded to the next power of 2.</p> </li> <li> <code>latent_dim</code>             (<code>int</code>)         \u2013          <p>Size of the latent space.</p> </li> <li> <code>set_size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of samples in a set. This is the leading dimension, after the batch dimension.</p> </li> <li> <code>encoder_blocks</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Number of encoder blocks. Defaults to 0.</p> </li> <li> <code>residual_units</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of residual units in each of the encoder blocks.</p> </li> <li> <code>filters</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of filters that the input is expanded to.</p> </li> <li> <code>activation</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Activation function for convolutions in residual units.</p> </li> <li> <code>kernel_size</code>             (<code>Union[int, list[int]]</code>, default:                 <code>2</code> )         \u2013          <p>Kernel size of convolutions in residual units. If a tuple is given, the kernel size can be different for the different encoder blocks. In this case, the length of the tuple must be equal to <code>encoder_blocks</code>.</p> </li> <li> <code>ratio</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Compression ratio of filters in the residual units. Defaults to 1.</p> </li> <li> <code>fc_units</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Number of units in last dense layer, i.e. before sampling of <code>z_mean</code> and <code>z_log_var</code>. Set to <code>None</code> to disable the dense layer.</p> </li> <li> <code>fc_activation</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Activation function of last dense layer.</p> </li> <li> <code>pooling</code>             (<code>str</code>, default:                 <code>'reduce_sum'</code> )         \u2013          <p>Pooling function. Set to <code>None</code> to disable pooling.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'encoder'</code> )         \u2013          <p>Name of the encoder model. Must be one of the following: <code>encoder</code>.</p> </li> </ul> <p>Attention parameters:</p> <ul> <li> <code>attn_activation</code>             (<code>str</code>, default:                 <code>'softmax'</code> )         \u2013          <p>Name of activation function for the scores in the attention.</p> </li> <li> <code>attn_blocks</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Number of attention blocks. Defaults to 0.</p> </li> <li> <code>attn_filters</code>             (<code>Union[int, str]</code>, default:                 <code>'full'</code> )         \u2013          <p>Number of attention filters.</p> </li> <li> <code>attn_heads</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of attention heads.</p> </li> <li> <code>attn_masked</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether apply a causal mask to the scores in the attention layer. Defaults to <code>True</code>.</p> </li> <li> <code>attn_transposed</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether the attention is applied to the spatial dimension (<code>False</code>) or the channel dimension (<code>True</code>).</p> </li> </ul> <p>Conditional parameters:</p> <ul> <li> <code>cond_size</code>             (<code>Union[int, tuple[int, int]]</code>, default:                 <code>None</code> )         \u2013          <p>int or tuple of two ints Size of conditional input. If <code>cond_size</code> is an integer, the conditional input is passed to a regular dense layer. If <code>cond_size</code> is a tuple of two integers, the conditional input of size <code>sum(cond_size)</code> is split along the channel axis into two tensors of size <code>cond_size[0]</code> and <code>cond_size[1]</code>, providing the condition and the ensemble id. The condition is passed to a (set) of dense layer(s), while the ensemble id is passed to a GumbelSoftmax layer, which is then used to FiLM the output of the dense layer(s) along the channel axis.</p> </li> <li> <code>cond_activation</code>             (<code>Union[str, list[str]]</code>, default:                 <code>None</code> )         \u2013          <p>Name of the activation function for dense layer(s).</p> </li> <li> <code>cond_units</code>             (<code>Union[int, list[int]]</code>, default:                 <code>16</code> )         \u2013          <p>Number of units for dense layer(s) applied to the input condition.  Set to <code>None</code> to disable dense layer.</p> </li> <li> <code>cond_use_bias</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use bias in the input condition. Defaults to <code>True</code>.</p> </li> <li> <code>cond_use_scale</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use scale in FiLM. Defaults to <code>True</code>.</p> </li> <li> <code>cond_use_offset</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use offset in FiLM. Defaults to <code>True</code>.</p> </li> <li> <code>cond_ens_size</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Size of the ensemble of GumbelSoftmax. Defaults to <code>None</code>.</p> </li> <li> <code>cond_temperature</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Temperature of the GumbelSoftmax. Defaults to 1.</p> </li> </ul> <p>FiLM parameters:</p> <ul> <li> <code>film_activation</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Name of the activation function for the scale in the Film layers. Defaults to <code>None</code>.</p> </li> <li> <code>film_temporal</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether the Film layers are time-dependent (apply to the second last dimension). Defaults to <code>False</code>.</p> </li> <li> <code>film_use_offset</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use offset in the Film layers. Defaults to <code>True</code>.</p> </li> <li> <code>film_use_scale</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use scale in the Film layers. Defaults to <code>True</code>.</p> </li> <li> <code>film_use_bias</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use bias in the Film layers. Defaults to <code>True</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>ks.Model</code>.</p> </li> </ul> Model inputs <p>If <code>cond_size</code> is None:     Tensor of shape <code>(set_size, input_length, channels)</code>. If <code>cond_size</code> is not None:     Tuple of two tensors of shape <code>(set_size, input_length, channels)</code> and <code>(set_size, cond_size)</code>.</p> Model outputs <p>Tensor of shape <code>(latent_dim, )</code></p> Source code in <code>VAE/models.py</code> <pre><code>def Encoder(input_shape: tuple[int, int],\n            latent_dim: int,\n            set_size: int = 1,\n            set_noise: bool = True,\n            encoder_blocks: int = 0,\n            residual_units: int = 1,\n            activation: str = None,\n            depth_wise: bool = False,\n            filters: int = 1,\n            kernel_size: Union[int, list[int]] = 2,\n            ratio: int = 1,\n            attn_activation: str = 'softmax',\n            attn_blocks: int = 0,\n            attn_filters: Union[int, str] = 'full',\n            attn_heads: int = 1,\n            attn_masked: bool = True,\n            attn_transposed: bool = False,\n            cond_activation: Union[str, list[str]] = None,\n            cond_size: Union[int, tuple[int, int]] = None,\n            cond_units: Union[int, list[int]] = 16,\n            cond_use_bias: bool = True,\n            cond_use_scale: bool = True,\n            cond_use_offset: bool = True,\n            cond_ens_size: int = None,\n            cond_temperature: float = 1.,\n            fc_activation: str = None,\n            fc_units: int = None,\n            film_activation: str = None,\n            film_temporal: bool = False,\n            film_use_bias: bool = True,\n            film_use_scale: bool = True,\n            film_use_offset: bool = True,\n            pooling: str = 'reduce_sum',\n            name: str = 'encoder',\n            **kwargs) -&gt; ks.Model:\n    \"\"\"Encoder model.\n\n    This function creates an encoder model, for use in :func:`VAEp`, for example. This model takes multiple set members\n    as input and returns a single `z_mean` and `z_log_var` via pooling.\n\n    Parameters:\n        input_shape:\n            Input shape of the encoder. A tuple of two integers `(input_length, channels)`, with `input_length` being\n            the length of the input sequence and `channels` being the number of input channels. If the input length is\n            not a power of 2, the input will be zero-padded to the next power of 2.\n        latent_dim:\n            Size of the latent space.\n        set_size:\n            Number of samples in a set. This is the leading dimension, after the batch dimension.\n        encoder_blocks:\n            Number of encoder blocks. Defaults to 0.\n        residual_units:\n            Number of residual units in each of the encoder blocks.\n        filters:\n            Number of filters that the input is expanded to.\n        activation:\n            Activation function for convolutions in residual units.\n        kernel_size:\n            Kernel size of convolutions in residual units. If a tuple is given, the kernel size can be different for the\n            different encoder blocks. In this case, the length of the tuple must be equal to `encoder_blocks`.\n        ratio:\n            Compression ratio of filters in the residual units. Defaults to 1.\n        fc_units:\n            Number of units in last dense layer, i.e. before sampling of `z_mean` and `z_log_var`. Set to `None` to\n            disable the dense layer.\n        fc_activation:\n            Activation function of last dense layer.\n        pooling:\n            Pooling function. Set to `None` to disable pooling.\n        name:\n            Name of the encoder model. Must be one of the following: `encoder`.\n\n    Parameters: Attention parameters:\n        attn_activation:\n            Name of activation function for the scores in the attention.\n        attn_blocks:\n            Number of attention blocks. Defaults to 0.\n        attn_filters:\n            Number of attention filters.\n        attn_heads:\n            Number of attention heads.\n        attn_masked:\n            Whether apply a causal mask to the scores in the attention layer. Defaults to `True`.\n        attn_transposed:\n            Whether the attention is applied to the spatial dimension (`False`) or the channel dimension (`True`).\n\n    Parameters: Conditional parameters:\n        cond_size: int or tuple of two ints\n            Size of conditional input. If `cond_size` is an integer, the conditional input is passed to a regular dense\n            layer. If `cond_size` is a tuple of two integers, the conditional input of size `sum(cond_size)` is split\n            along the channel axis into two tensors of size `cond_size[0]` and `cond_size[1]`, providing the condition\n            and the ensemble id. The condition is passed to a (set) of dense layer(s), while the ensemble id is passed\n            to a GumbelSoftmax layer, which is then used to FiLM the output of the dense layer(s) along the channel\n            axis.\n        cond_activation:\n            Name of the activation function for dense layer(s).\n        cond_units:\n            Number of units for dense layer(s) applied to the input condition.  Set to `None` to disable dense layer.\n        cond_use_bias:\n            Whether to use bias in the input condition. Defaults to `True`.\n        cond_use_scale:\n            Whether to use scale in FiLM. Defaults to `True`.\n        cond_use_offset:\n            Whether to use offset in FiLM. Defaults to `True`.\n        cond_ens_size:\n            Size of the ensemble of GumbelSoftmax. Defaults to `None`.\n        cond_temperature:\n            Temperature of the GumbelSoftmax. Defaults to 1.\n\n    Parameters: FiLM parameters:\n        film_activation:\n            Name of the activation function for the scale in the Film layers. Defaults to `None`.\n        film_temporal:\n            Whether the Film layers are time-dependent (apply to the second last dimension). Defaults to `False`.\n        film_use_offset:\n            Whether to use offset in the Film layers. Defaults to `True`.\n        film_use_scale:\n            Whether to use scale in the Film layers. Defaults to `True`.\n        film_use_bias:\n            Whether to use bias in the Film layers. Defaults to `True`.\n\n    Returns:\n        Instance of :class:`ks.Model`.\n\n    Model inputs:\n        If `cond_size` is None:\n            Tensor of shape `(set_size, input_length, channels)`.\n        If `cond_size` is not None:\n            Tuple of two tensors of shape `(set_size, input_length, channels)` and `(set_size, cond_size)`.\n\n    Model outputs:\n        Tensor of shape `(latent_dim, )`\n\n    \"\"\"\n    valid_names = {'encoder'}\n    if name not in valid_names:\n        raise ValueError(f\"Name must be one of {valid_names}.\")\n\n    kernel_size = (kernel_size, ) * encoder_blocks if isinstance(kernel_size, int) else kernel_size\n    if len(kernel_size) != encoder_blocks:\n        raise ValueError(f\"{len(kernel_size)=} must be equal to {encoder_blocks=}.\")\n\n    # Input of x\n    x_in = ks.layers.Input(shape=(set_size, ) + tuple(input_shape), name=name + '_input')\n\n    # Left zero-padding\n    scale = 2**encoder_blocks\n    input_length, _ = input_shape\n    padded_length = int(np.ceil(input_length / scale)) * scale\n    if padded_length &gt; input_length:\n        y = ks.layers.ZeroPadding2D(padding=((0, 0), (padded_length - input_length, 0)), name=name + '_input_pad')(x_in)\n    else:\n        y = x_in\n\n    # Input BatchNormalization\n    y = ks.layers.BatchNormalization(name=name + '_input_bn')(y)\n\n    # Input expansion\n    y = ks.layers.Dense(units=filters, name=name + '_input_expand')(y)\n\n    shape = [set_size, padded_length, filters]\n\n    # Input of condition\n    if cond_size is not None:\n        if isinstance(cond_size, int):\n            cond_size = [cond_size]\n        cond_in = ks.layers.Input(shape=(set_size, sum(cond_size)), name=name + '_cond')\n\n        # optionally split the condition into two tensors\n        if len(cond_size) == 1:\n            y_cond, y_id = cond_in, None\n        elif len(cond_size) == 2:\n            y_cond, y_id = vaelayers.Split(size_splits=cond_size, axis=-1, name=name + '_cond_split')(cond_in)\n        else:\n            raise ValueError('cond_size must be either an integer or a list of two integers.')\n\n        # apply dense layer(s) to the condition\n        y_cond = MLP(units=cond_units, activation=cond_activation, use_bias=cond_use_bias,\n                     name=name + '_cond_dense')(y_cond)\n\n        # film condition\n        if y_id is not None:\n            if cond_ens_size is not None:\n                y_id = ks.layers.Dense(units=cond_ens_size, name=name + '_cond_id')(y_id)\n                noise_shape = None if set_noise else (None, 1, None)\n                y_id = vaelayers.GumbelSoftmax(noise_shape=noise_shape,\n                                               temperature=cond_temperature,\n                                               name=name + '_cond_id_gumbel')(y_id)\n\n            y_cond = vaelayers.Film(use_scale=cond_use_scale,\n                                    use_offset=cond_use_offset,\n                                    use_bias=False,\n                                    name=name + '_cond_film')([y_cond, y_id])\n\n    else:\n        cond_in = None\n        y_cond = None\n\n    if film_temporal:\n        # apply Film to last and second last dimension\n        film_shape = (None, None)\n    else:\n        # apply Film to last dimension only\n        film_shape = (1, None)\n\n    film_kw = {\n        'activation': film_activation,\n        'use_bias': film_use_bias,\n        'use_offset': film_use_offset,\n        'use_scale': film_use_scale,\n    }\n\n    # Conditional input FiLM, always applied to the last dimension\n    if y_cond is not None:\n        y = vaelayers.Film(shape=(1, None), name=name + '_input_film', **film_kw)([y, y_cond])\n\n    # Encoder blocks\n    for n, k_size in enumerate(kernel_size):\n        y = EncoderBlock(shape,\n                         residual_units=residual_units,\n                         activation=activation,\n                         depth_wise=depth_wise,\n                         kernel_size=k_size,\n                         ratio=ratio,\n                         name=name + '_block_{}'.format(n + 1))(y)\n        shape[1] //= 2\n        shape[2] *= 2\n\n    # Conditional FiLM of conv output\n    if (y_cond is not None) and (encoder_blocks &gt; 0):\n        y = vaelayers.Film(shape=film_shape, name=name + '_conv_film', **film_kw)([y, y_cond])\n\n    # Attention blocks\n    for n in range(attn_blocks):\n        y = MultiheadAttentionBlock(shape,\n                                    filters=attn_filters,\n                                    heads=attn_heads,\n                                    masked=attn_masked,\n                                    transposed=attn_transposed,\n                                    attn_activation=attn_activation,\n                                    res_activation=activation,\n                                    name=name + '_MAB_{}'.format(n + 1))(y)\n\n    # Conditional FiLM of attn output\n    if (y_cond is not None) and (attn_blocks &gt; 0):\n        y = vaelayers.Film(shape=film_shape, name=name + '_attn_film', **film_kw)([y, y_cond])\n\n    # Pooling over set_size\n    if set_size &gt; 1 and pooling is not None:\n        pooling_fcn = getattr(tf, pooling)\n        y = ks.layers.Lambda(lambda x: pooling_fcn(x, axis=1, keepdims=True), name=name + '_pooling_set')(y)\n\n    # Flatten\n    y = ks.layers.Flatten(name=name + '_flatten')(y)\n\n    # Final nonlinearity\n    if fc_units:\n        y = ks.layers.Dense(fc_units, activation=fc_activation, name=name + '_z_dense')(y)\n\n    # Compress to latent dimensions\n    z_mean = ks.layers.Dense(latent_dim, name=name + '_z_mean')(y)\n    z_log_var = ks.layers.Dense(latent_dim, name=name + '_z_log_var')(y)\n\n    # Build encoder model\n    if cond_in is not None:\n        inputs = [x_in, cond_in]\n    else:\n        inputs = [x_in]\n\n    model = ks.Model(inputs=inputs, outputs=[z_mean, z_log_var], name=name)\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.Decoder","title":"VAE.models.Decoder","text":"<pre><code>Decoder(output_shape, latent_dim, set_size=1, set_noise=True, decoder_blocks=0, residual_units=1, activation=None, depth_wise=False, filters=1, kernel_size=2, ratio=1, attn_activation='softmax', attn_blocks=0, attn_filters='full', attn_heads=1, attn_masked=True, attn_transposed=False, cond_activation=None, cond_size=None, cond_units=16, cond_use_bias=True, cond_use_scale=True, cond_use_offset=True, cond_ens_size=None, cond_temperature=1.0, film_activation=None, film_temporal=False, film_use_bias=True, film_use_scale=True, film_use_offset=True, fc_units=None, fc_activation=None, padding_blocks=0, output_reverse=True, name='decoder', **kwargs)\n</code></pre> <p>Decoder model.</p> <p>This function creates a decoder model, for use in :func:<code>VAE</code>, for example. This model takes multiple realizations <code>z</code> from the latent space and returns multiple samples.</p> <p>Parameters:</p> <ul> <li> <code>output_shape</code>             (<code>tuple[int, int]</code>)         \u2013          <p>Output shape of the decoder. A tuple of two integers <code>(output_length, channels)</code>, with <code>output_length</code> being the length of the output sequence and <code>channels</code> being the number of output channels. If <code>output_length</code> is not a power of 2, the decoder will internally work with a sequence length to the next power of 2 and crop the sequence to the desired length.</p> </li> <li> <code>latent_dim</code>             (<code>int</code>)         \u2013          <p>Size of the latent space.</p> </li> <li> <code>set_size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of output samples in a set. This is the leading dimension, after the batch dimension.</p> </li> <li> <code>decoder_blocks</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Number of decoder blocks. Defaults to 0.</p> </li> <li> <code>output_reverse</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Reverse temporal order of output.</p> </li> <li> <code>padding_blocks</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Number of internal padding blocks. Instead of zero-padding, further padding blocks are drawn from <code>z</code>. Defaults to 0.</p> </li> <li> <code>kernel_size</code>             (<code>Union[int, list[int]]</code>, default:                 <code>2</code> )         \u2013          <p>Size of the convolutional kernel. If a list, the kernel size can be different for each decoder block. In this case, the length of the list must be equal to <code>decoder_blocks</code> and the order is reversed.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'decoder'</code> )         \u2013          <p>Name of the decoder model. Must be one of the following: <code>decoder</code>, <code>prediction</code>.</p> </li> </ul> <p>For the rest of the parameters, see :func:<code>Encoder</code>.</p> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>keras.Model</code>.</p> </li> </ul> Model inputs <p>If <code>cond_size</code> is None:     Tensor of shape <code>(set_size, latent_dim)</code>. If <code>cond_size</code> is not None:     Tuple of two tensors of shape <code>(set_size, latent_dim)</code> and <code>(set_size, cond_size)</code>.</p> Model outputs <p>Tensor of shape <code>(set_size, output_length, channels)</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def Decoder(output_shape: tuple[int, int],\n            latent_dim: int,\n            set_size: int = 1,\n            set_noise: bool = True,\n            decoder_blocks: int = 0,\n            residual_units: int = 1,\n            activation: str = None,\n            depth_wise: bool = False,\n            filters: int = 1,\n            kernel_size: Union[int, list[int]] = 2,\n            ratio: int = 1,\n            attn_activation: str = 'softmax',\n            attn_blocks: int = 0,\n            attn_filters: Union[int, str] = 'full',\n            attn_heads: int = 1,\n            attn_masked: bool = True,\n            attn_transposed: bool = False,\n            cond_activation: Union[str, list[str]] = None,\n            cond_size: Union[int, tuple[int, int]] = None,\n            cond_units: Union[int, list[int]] = 16,\n            cond_use_bias: bool = True,\n            cond_use_scale: bool = True,\n            cond_use_offset: bool = True,\n            cond_ens_size: int = None,\n            cond_temperature: float = 1.,\n            film_activation: str = None,\n            film_temporal: bool = False,\n            film_use_bias: bool = True,\n            film_use_scale: bool = True,\n            film_use_offset: bool = True,\n            fc_units: int = None,\n            fc_activation: str = None,\n            padding_blocks: int = 0,\n            output_reverse: bool = True,\n            name: str = 'decoder',\n            **kwargs) -&gt; ks.Model:\n    \"\"\"Decoder model.\n\n    This function creates a decoder model, for use in :func:`VAE`, for example. This model\n    takes multiple realizations `z` from the latent space and returns multiple samples.\n\n    Parameters:\n        output_shape:\n            Output shape of the decoder. A tuple of two integers `(output_length, channels)`, with `output_length` being\n            the length of the output sequence and `channels` being the number of output channels. If `output_length` is\n            not a power of 2, the decoder will internally work with a sequence length to the next power of 2 and\n            crop the sequence to the desired length.\n        latent_dim:\n            Size of the latent space.\n        set_size:\n            Number of output samples in a set. This is the leading dimension, after the batch dimension.\n        decoder_blocks:\n            Number of decoder blocks. Defaults to 0.\n        output_reverse:\n            Reverse temporal order of output.\n        padding_blocks:\n            Number of internal padding blocks. Instead of zero-padding, further padding blocks are drawn from `z`.\n            Defaults to 0.\n        kernel_size:\n            Size of the convolutional kernel. If a list, the kernel size can be different for each decoder block. In\n            this case, the length of the list must be equal to `decoder_blocks` and the order is reversed.\n        name:\n            Name of the decoder model. Must be one of the following: `decoder`, `prediction`.\n\n    For the rest of the parameters, see :func:`Encoder`.\n\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    Model inputs:\n        If `cond_size` is None:\n            Tensor of shape `(set_size, latent_dim)`.\n        If `cond_size` is not None:\n            Tuple of two tensors of shape `(set_size, latent_dim)` and `(set_size, cond_size)`.\n\n    Model outputs:\n        Tensor of shape `(set_size, output_length, channels)`.\n\n    \"\"\"\n    valid_names = {'decoder', 'prediction'}\n    if name not in valid_names:\n        raise ValueError(f\"Name must be one of {valid_names}.\")\n\n    kernel_size = (kernel_size, ) * decoder_blocks if isinstance(kernel_size, int) else kernel_size\n    if len(kernel_size) != decoder_blocks:\n        raise ValueError(f\"{len(kernel_size)=} must be equal to {decoder_blocks=}.\")\n\n    # Input of z\n    z_in = ks.layers.Input(shape=(set_size, latent_dim), name=name + '_input')\n\n    # optional first layer\n    if fc_units:\n        y = ks.layers.Dense(fc_units, activation=fc_activation, name=name + '_input_dense')(z_in)\n    else:\n        y = z_in\n\n    # Right pad\n    # note: if the decoder output is reversed, the padding is on the left such as in the encoder\n    scale = 2**decoder_blocks\n    output_length, _ = output_shape\n    padded_length = int(np.ceil(output_length / scale)) * scale\n    right_pad = padded_length - output_length\n\n    # Left pad with internal padding blocks\n    left_pad = padding_blocks * scale\n    full_length = left_pad + padded_length\n\n    # Expand\n    y = ks.layers.Dense(full_length * filters, name=name + '_input_expand')(y)\n\n    # Reshape\n    shape = [set_size, full_length // scale, filters * scale]\n    y = ks.layers.Reshape(shape, name=name + '_input_reshape')(y)\n\n    # Input of condition\n    if cond_size is not None:\n        if isinstance(cond_size, int):\n            cond_size = [cond_size]\n        cond_in = ks.layers.Input(shape=(set_size, sum(cond_size)), name=name + '_cond')\n\n        # optionally split the condition into two tensors\n        if len(cond_size) == 1:\n            y_cond, y_id = cond_in, None\n        elif len(cond_size) == 2:\n            y_cond, y_id = vaelayers.Split(size_splits=cond_size, axis=-1, name=name + '_cond_split')(cond_in)\n        else:\n            raise ValueError('cond_size must be either an integer or a list of two integers.')\n\n        # apply dense layer(s) to the condition\n        y_cond = MLP(units=cond_units, activation=cond_activation, use_bias=cond_use_bias,\n                     name=name + '_cond_dense')(y_cond)\n\n        # film condition\n        if y_id is not None:\n            if cond_ens_size is not None:\n                y_id = ks.layers.Dense(units=cond_ens_size, name=name + '_cond_id')(y_id)\n                noise_shape = None if set_noise else (None, 1, None)\n                y_id = vaelayers.GumbelSoftmax(noise_shape=noise_shape,\n                                               temperature=cond_temperature,\n                                               name=name + '_cond_id_gumbel')(y_id)\n\n            y_cond = vaelayers.Film(use_scale=cond_use_scale,\n                                    use_offset=cond_use_offset,\n                                    use_bias=False,\n                                    name=name + '_cond_film')([y_cond, y_id])\n\n    else:\n        cond_in = None\n        y_cond = None\n\n    if film_temporal:\n        # apply Film to last and second last dimension\n        film_shape = (None, None)\n    else:\n        # apply Film to last dimension only\n        film_shape = (1, None)\n\n    film_kw = {\n        'activation': film_activation,\n        'use_bias': film_use_bias,\n        'use_offset': film_use_offset,\n        'use_scale': film_use_scale,\n    }\n\n    # Conditional input FiLM\n    if y_cond is not None:\n        y = vaelayers.Film(shape=film_shape, name=name + '_input_film', **film_kw)([y, y_cond])\n\n    # Attention blocks\n    for n in range(attn_blocks):\n        y = MultiheadAttentionBlock(shape,\n                                    filters=attn_filters,\n                                    heads=attn_heads,\n                                    masked=attn_masked,\n                                    transposed=attn_transposed,\n                                    attn_activation=attn_activation,\n                                    res_activation=activation,\n                                    name=name + '_MAB_{}'.format(n + 1))(y)\n\n    # Conditional FiLM of attention output\n    if (y_cond is not None) and (attn_blocks &gt; 0):\n        y = vaelayers.Film(shape=film_shape, name=name + '_attn_film', **film_kw)([y, y_cond])\n\n    # Decoder blocks\n    for n, k_size in enumerate(reversed(kernel_size)):\n        y = DecoderBlock(shape,\n                         residual_units=residual_units,\n                         activation=activation,\n                         depth_wise=depth_wise,\n                         kernel_size=k_size,\n                         ratio=ratio,\n                         name=name + '_block_{}'.format(n + 1))(y)\n        shape[1] *= 2\n        shape[2] //= 2\n\n    # Conditional FiLM of conv output, always applied to the last dimension\n    if (y_cond is not None) and (decoder_blocks &gt; 0):\n        y = vaelayers.Film(shape=(1, None), name=name + '_conv_film', **film_kw)([y, y_cond])\n\n    # Output aggregation\n    y = ks.layers.Dense(units=output_shape[-1], name=name + '_output_aggregation')(y)\n\n    # Output BatchNormalization\n    y = ks.layers.BatchNormalization(name=name + '_output_bn')(y)\n\n    # Output crop. Remove internal padding blocks\n    y = ks.layers.Cropping2D(cropping=((0, 0), (left_pad, right_pad)), name=name + '_output_crop')(y)\n\n    # Time reverse output\n    if output_reverse:\n        y = ks.layers.Lambda(lambda x: tf.reverse(x, axis=[2]), name=name + '_output_reverse')(y)\n\n    outputs = ks.layers.Lambda(lambda x: x, name=name)(y)\n\n    # Build decoder model\n    if cond_in is not None:\n        inputs = [z_in, cond_in]\n    else:\n        inputs = [z_in]\n\n    model = ks.Model(inputs=inputs, outputs=outputs, name=name)\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.LatentSampling","title":"VAE.models.LatentSampling","text":"<pre><code>LatentSampling(latent_dim, set_size=1, set_noise=True, input_sigma=False, name='latent', **kwargs)\n</code></pre> <p>Latent-sampling model.</p> <p>This function creates a model for latent sampling, for use in :func:<code>VAE</code>. The  model has input <code>z_mean</code> and <code>z_log_var</code> from the encoder and returns <code>set_size</code> random samples <code>z</code>.</p> <p>Parameters:</p> <ul> <li> <code>latent_dim</code>             (<code>int</code>)         \u2013          <p>Size of the latent space.</p> </li> <li> <code>set_size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of output samples in a set. This is the leading dimension, after the batch dimension.</p> </li> <li> <code>set_noise</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether the noise varies between members in a set.</p> </li> <li> <code>input_sigma</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Specify, whether random samples are provided as input to the model.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>keras.Model</code>.</p> </li> </ul> Model inputs <p>Tensor of shape <code>(latent_dim,)</code>.</p> Model outputs <p>Tensor of shape <code>(set_size, latent_dim)</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def LatentSampling(latent_dim: int,\n                   set_size: int = 1,\n                   set_noise: bool = True,\n                   input_sigma: bool = False,\n                   name: str = 'latent',\n                   **kwargs) -&gt; ks.Model:\n    \"\"\"Latent-sampling model.\n\n    This function creates a model for latent sampling, for use in :func:`VAE`. The  model has input `z_mean`\n    and `z_log_var` from the encoder and returns `set_size` random samples `z`.\n\n    Parameters:\n        latent_dim:\n            Size of the latent space.\n        set_size:\n            Number of output samples in a set. This is the leading dimension, after the batch dimension.\n        set_noise:\n            Whether the noise varies between members in a set.\n        input_sigma:\n            Specify, whether random samples are provided as input to the model.\n\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    Model inputs:\n        Tensor of shape `(latent_dim,)`.\n\n    Model outputs:\n        Tensor of shape `(set_size, latent_dim)`.\n\n    \"\"\"\n    # Input layer\n    input_shape = (latent_dim, )\n    z_mean_in = ks.layers.Input(shape=input_shape, name=name + '_input_z_mean')\n    z_log_var_in = ks.layers.Input(shape=input_shape, name=name + '_input_z_log_var')\n\n    # broadcast the input to set_size\n    z_mean = ks.layers.RepeatVector(set_size, name=name + '_z_mean_repeat')(z_mean_in)\n    z_log_var = ks.layers.RepeatVector(set_size, name=name + '_z_log_var_repeat')(z_log_var_in)\n\n    # Optional input layer\n    if input_sigma:\n        sigma = ks.layers.Input(shape=(set_size, ) + input_shape, name=name + '_sigma')\n        inputs = [z_mean_in, z_log_var_in, sigma]\n        sample_args = [z_mean, z_log_var, sigma]\n    else:\n        inputs = [z_mean_in, z_log_var_in]\n        sample_args = [z_mean, z_log_var]\n\n    # Random sampling\n    noise_shape = None if set_noise else (None, 1, None)\n    z = vaelayers.RandomSampling(noise_shape=noise_shape, name=name + '_z_sampling')(sample_args)\n\n    # Build model\n    model = ks.Model(inputs=inputs, outputs=z, name=name)\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.EncoderBlock","title":"VAE.models.EncoderBlock","text":"<pre><code>EncoderBlock(shape, residual_units=1, activation=None, depth_wise=False, kernel_size=1, ratio=1, name='encoder_block')\n</code></pre> <p>Encoder-block model.</p> <p>This function creates an encoder-block model for the use in  :func:<code>Encoder</code>.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>             (<code>tuple[int, int, int]</code>)         \u2013          <p>Input shape of the block <code>(set_size, input_length, filters)</code>.</p> </li> <li> <code>residuals_units</code>         \u2013          <p>Number of residual units.</p> </li> <li> <code>activation</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Activation function.</p> </li> <li> <code>kernel_size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Size of the convolutional kernel.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'encoder_block'</code> )         \u2013          <p>Name of encoder-block model.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>keras.Model</code>.</p> </li> </ul> Model inputs <p>Tensor of shape <code>(set_size, input_length, filters)</code>.</p> Model outputs <p>Tensor of shape <code>(set_size, input_length // 2, 2 * filters)</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def EncoderBlock(shape: tuple[int, int, int],\n                 residual_units: int = 1,\n                 activation: str = None,\n                 depth_wise: bool = False,\n                 kernel_size: int = 1,\n                 ratio: int = 1,\n                 name: str = 'encoder_block') -&gt; ks.Model:\n    \"\"\"Encoder-block model.\n\n    This function creates an encoder-block model for the use in  :func:`Encoder`.\n\n    Parameters:\n        shape:\n            Input shape of the block `(set_size, input_length, filters)`.\n        residuals_units:\n            Number of residual units.\n        activation:\n            Activation function.\n        kernel_size:\n            Size of the convolutional kernel.\n        name:\n            Name of encoder-block model.\n\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    Model inputs:\n        Tensor of shape `(set_size, input_length, filters)`.\n\n    Model outputs:\n        Tensor of shape `(set_size, input_length // 2, 2 * filters)`.\n\n    \"\"\"\n    y_in = ks.layers.Input(shape, name=name + '_in')\n    y = y_in\n\n    # residual unit(s)\n    for n in range(residual_units):\n        y = ResidualUnit(filters=y.shape.as_list()[-1],\n                         activation=activation,\n                         depth_wise=depth_wise,\n                         kernel_size=kernel_size,\n                         ratio=ratio,\n                         name=name + '_R{}'.format(n + 1))(y)\n\n    # downsampling by pixel shuffling\n    set_size, input_length, filters = shape\n    input_length //= 2\n    filters *= 2\n    y = ks.layers.Reshape((set_size, input_length, filters), name=name + '_down_shuffle')(y)\n\n    model = ks.Model(inputs=y_in, outputs=y, name=name)\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.DecoderBlock","title":"VAE.models.DecoderBlock","text":"<pre><code>DecoderBlock(shape, residual_units=1, activation=None, depth_wise=False, kernel_size=1, ratio=1, name='decoder_block')\n</code></pre> <p>Decoder-block model.</p> <p>This function creates a decoder-block model for the use in  :func:<code>Decoder</code>.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>             (<code>tuple[int, int, int]</code>)         \u2013          <p>Input shape of the block <code>(set_size, input_length, filters)</code>.</p> </li> <li> <code>residuals_units</code>         \u2013          <p>Number of residual units.</p> </li> <li> <code>activation</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Activation function.</p> </li> <li> <code>kernel_size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Size of the convolutional kernel.</p> </li> <li> <code>name</code>             (<code>int</code>, default:                 <code>'decoder_block'</code> )         \u2013          <p>Name of decoder-block model.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>keras.Model</code>.</p> </li> </ul> Model inputs <p>Tensor of shape <code>(set_size, input_length, filters)</code>.</p> Model outputs <p>Tensor of shape <code>(set_size, 2 * input_length, filters // 2)</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def DecoderBlock(shape: tuple[int, int, int],\n                 residual_units: int = 1,\n                 activation: str = None,\n                 depth_wise: bool = False,\n                 kernel_size: int = 1,\n                 ratio: int = 1,\n                 name: int = 'decoder_block') -&gt; ks.Model:\n    \"\"\"Decoder-block model.\n\n    This function creates a decoder-block model for the use in  :func:`Decoder`.\n\n    Parameters:\n        shape:\n            Input shape of the block `(set_size, input_length, filters)`.\n        residuals_units:\n            Number of residual units.\n        activation:\n            Activation function.\n        kernel_size:\n            Size of the convolutional kernel.\n        name:\n            Name of decoder-block model.\n\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    Model inputs:\n        Tensor of shape `(set_size, input_length, filters)`.\n\n    Model outputs:\n        Tensor of shape `(set_size, 2 * input_length, filters // 2)`.\n\n    \"\"\"\n    y_in = ks.layers.Input(shape, name=name + '_in')\n\n    # upsampling by pixel shuffling\n    set_size, input_length, filters = shape\n    input_length *= 2\n    filters //= 2\n    y = ks.layers.Reshape((set_size, input_length, filters), name=name + '_up_shuffle')(y_in)\n\n    # residual units\n    for n in range(residual_units):\n        y = ResidualUnit(filters=y.shape.as_list()[-1],\n                         activation=activation,\n                         depth_wise=depth_wise,\n                         kernel_size=kernel_size,\n                         ratio=ratio,\n                         name=name + '_R{}'.format(n + 1))(y)\n\n    model = ks.Model(inputs=y_in, outputs=y, name=name)\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.MLP","title":"VAE.models.MLP","text":"<pre><code>MLP(units, activation=None, use_bias=None, **kwargs)\n</code></pre> <p>Multi-layer perceptron.</p> <p>This is a convenience function to create a multi-layer perceptron. The parameters can be either single values or lists of values. If a list is given, the length of the list determines the number of layers. Otherwise, a single dense layer is created.</p> <p>Parameters:</p> <ul> <li> <code>units</code>             (<code>Union[int, list[int]]</code>)         \u2013          <p>Number of units in each layer.</p> </li> <li> <code>activation</code>             (<code>Union[str, list[str]]</code>, default:                 <code>None</code> )         \u2013          <p>Activation function for each layer.</p> </li> <li> <code>use_bias</code>             (<code>Union[bool, list[bool]]</code>, default:                 <code>None</code> )         \u2013          <p>Whether to use bias in each layer.</p> </li> <li> <code>kwargs</code>         \u2013          <p>Additional keyword arguments are passed to the dense layers.</p> </li> </ul> Model inputs <p>Tensor of arbitrary shape.</p> Model outputs <p>Tensor of same shape as input, except for the last dimension which is specified by the last value in <code>units</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def MLP(units: Union[int, list[int]],\n        activation: Union[str, list[str]] = None,\n        use_bias: Union[bool, list[bool]] = None,\n        **kwargs):\n    \"\"\"Multi-layer perceptron.\n\n    This is a convenience function to create a multi-layer perceptron. The parameters can be either single values or\n    lists of values. If a list is given, the length of the list determines the number of layers. Otherwise, a single\n    dense layer is created.\n\n    Parameters:\n        units:\n            Number of units in each layer.\n        activation:\n            Activation function for each layer.\n        use_bias:\n            Whether to use bias in each layer.\n        kwargs:\n            Additional keyword arguments are passed to the dense layers.\n\n    Model inputs:\n        Tensor of arbitrary shape.\n\n    Model outputs:\n        Tensor of same shape as input, except for the last dimension which is specified by the last value in `units`.\n    \"\"\"\n    if not isinstance(units, list):\n        units = [units]\n    if not isinstance(activation, list):\n        activation = [activation] * len(units)\n    if not isinstance(use_bias, list):\n        use_bias = [use_bias] * len(units)\n\n    name = kwargs.pop('name', '')\n\n    def mlp(inputs):\n        x = inputs\n        for n, (_units, _activation, _use_bias) in enumerate(zip(units, activation, use_bias), start=1):\n            x = ks.layers.Dense(units=_units, activation=_activation, use_bias=_use_bias, name=name + f'_{n}',\n                                **kwargs)(x)\n        return x\n\n    return mlp\n</code></pre>"},{"location":"VAE.models/#VAE.models.MultiheadAttentionBlock","title":"VAE.models.MultiheadAttentionBlock","text":"<pre><code>MultiheadAttentionBlock(shape, filters='full', heads=4, masked=True, transposed=False, attn_activation='softmax', res_activation=None, name='mab')\n</code></pre> <p>Multihead-attention model.</p> <p>This function creates a model for multihead attention for use in :func:<code>Decoder</code> and :func:<code>Encoder</code>. The input shape of the model is <code>(set_size, input_length, filters)</code>. The dot-product attention is applied over reshaped matrices of shape <code>(set_size * input_length, filters)</code> . The score has a shape of <code>(set_size * input_length, set_size * input_length)</code>. Optional causal masking is applied to the scores and no temporal information is merged.</p> <p>Parameters:</p> <ul> <li> <code>shape</code>             (<code>tuple[int, int, int]</code>)         \u2013          <p>Input shape of the model.</p> </li> <li> <code>filters</code>             (<code>Union[int, str]</code>, default:                 <code>'full'</code> )         \u2013          <p>Number of filters in each of the heads. If <code>full</code>, the number of filters will be the same as in the input. If <code>reduced</code>, the number of filters will be divided by the number of heads. Default is <code>full</code>.</p> </li> <li> <code>heads</code>             (<code>int</code>, default:                 <code>4</code> )         \u2013          <p>Number of heads. Default is 4.</p> </li> <li> <code>masked</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether apply a causal mask to the score. Default is <code>True</code>.</p> </li> <li> <code>transposed</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether the attention is applied to the <code>set_size</code> dimension (<code>False</code>) or the <code>filters</code> dimension (<code>True</code>). Default is <code>False</code>.</p> </li> <li> <code>attn_activation</code>             (<code>str</code>, default:                 <code>'softmax'</code> )         \u2013          <p>Name of activation function for the scores. Default is <code>softmax</code>.</p> </li> <li> <code>res_activation</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Name of activation function for the residual unit.  Default is <code>None</code>.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'mab'</code> )         \u2013          <p>Name of the model.  Default is <code>mab</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>keras.Model</code>.</p> </li> </ul> Model inputs <p>Tensor of shape <code>(set_size, input_length, filters)</code>.</p> Model outputs <p>Tensor of shape <code>(set_size, input_length, filters)</code>.</p> References <p>Vaswani et al. (2017): https://arxiv.org/abs/1706.03762v5.</p> Source code in <code>VAE/models.py</code> <pre><code>def MultiheadAttentionBlock(shape: tuple[int, int, int],\n                            filters: Union[int, str] = 'full',\n                            heads: int = 4,\n                            masked: bool = True,\n                            transposed: bool = False,\n                            attn_activation: str = 'softmax',\n                            res_activation: str = None,\n                            name: str = 'mab') -&gt; ks.Model:\n    \"\"\"Multihead-attention model.\n\n    This function creates a model for multihead attention for use in :func:`Decoder` and\n    :func:`Encoder`. The input shape of the model is `(set_size, input_length, filters)`. The dot-product\n    attention is applied over reshaped matrices of shape `(set_size * input_length, filters)` . The score has a shape of\n    `(set_size * input_length, set_size * input_length)`. Optional causal masking is applied to the scores and no\n    temporal information is merged.\n\n    Parameters:\n        shape:\n            Input shape of the model.\n        filters:\n            Number of filters in each of the heads. If `full`, the number of filters will be the same as in the input.\n            If `reduced`, the number of filters will be divided by the number of heads. Default is `full`.\n        heads:\n            Number of heads. Default is 4.\n        masked:\n            Whether apply a causal mask to the score. Default is `True`.\n        transposed:\n            Whether the attention is applied to the `set_size` dimension (`False`) or the `filters` dimension (`True`).\n            Default is `False`.\n        attn_activation:\n            Name of activation function for the scores. Default is `softmax`.\n        res_activation:\n            Name of activation function for the residual unit.  Default is `None`.\n        name:\n            Name of the model.  Default is `mab`.\n\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    Model inputs:\n        Tensor of shape `(set_size, input_length, filters)`.\n\n    Model outputs:\n        Tensor of shape `(set_size, input_length, filters)`.\n\n    References:\n        Vaswani et al. (2017): https://arxiv.org/abs/1706.03762v5.\n\n    \"\"\"\n    y_in = ks.layers.Input(shape=shape, name=name + '_y_in')\n\n    # batch normalization\n    y = ks.layers.BatchNormalization(name=name + '_bn')(y_in)\n\n    if isinstance(filters, str):\n        if filters not in ['full', 'reduced']:\n            raise ValueError(\"filters must be either 'full' or 'reduced'.\")\n        if filters == 'full':\n            filters = shape[-1]\n        elif filters == 'reduced':\n            filters = shape[-1] // heads\n\n    # attention heads\n    permute = (0, 3, 2, 1) if transposed else None\n    y_list = []\n    for n in range(heads):\n        q = ks.layers.Dense(units=filters, name=name + '_query_{}'.format(n + 1))(y)\n        k = ks.layers.Dense(units=filters, name=name + '_key_{}'.format(n + 1))(y)\n        v = ks.layers.Dense(units=filters, name=name + '_value_{}'.format(n + 1))(y)\n\n        y_list.append(\n            vaelayers.AttentionMasked(activation=attn_activation,\n                                      masked=masked,\n                                      permute=permute,\n                                      name=name + '_attn_{}'.format(n + 1))([q, k, v]))\n\n    # concatenate and merge outputs of different heads\n    if heads &gt; 1:\n        y = ks.layers.Concatenate(name=name + '_concat')(y_list)\n\n        # optionally revert to number of input channels\n        if filters * heads != shape[-1]:\n            y = ks.layers.Dense(units=shape[-1], name=name + '_dense')(y)\n    else:\n        y = y_list[-1]\n\n    # add residual connection\n    y = ks.layers.Add(name=name + '_add')([y_in, y])\n\n    # Final residual unit\n    out = ResidualUnit(filters=shape[-1], activation=res_activation, kernel_size=1, name=name + '_R')(y)\n\n    model = ks.Model(inputs=y_in, outputs=out, name=name)\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.ResidualUnit","title":"VAE.models.ResidualUnit","text":"<pre><code>ResidualUnit(filters, activation=None, depth_wise=False, kernel_size=1, ratio=1, name='residual_unit')\n</code></pre> <p>Residual unit.</p> <p>Residual unit for use in :func:<code>Decoder_block</code> and :func:<code>Encoder_block</code>.</p> <p>Parameters:</p> <ul> <li> <code>filters</code>             (<code>int</code>)         \u2013          <p>Number of filters in the convolutional layers.</p> </li> <li> <code>activation</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Name of activation function. Default is <code>None</code>.</p> </li> <li> <code>depth_wise</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to use depth-wise separable convolutions. Default is <code>False</code>.</p> </li> <li> <code>kernel_size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Kernel size of the convolutional layers. Default is 1.</p> </li> <li> <code>ratio</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Ratio of filters in the first convolutional layer, which will have <code>filters // ratio</code> filters. The second convolutional layer will have <code>filters</code> filters. Default is 1.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'residual_unit'</code> )         \u2013          <p>Name of the model.  Default is <code>residual_unit</code>.</p> </li> </ul> Model inputs <p>Tensor of shape <code>(set_size, input_length, filters)</code>.</p> Model outputs <p>Tensor of shape <code>(set_size, input_length, filters)</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def ResidualUnit(filters: int,\n                 activation: str = None,\n                 depth_wise: bool = False,\n                 kernel_size: int = 1,\n                 ratio: int = 1,\n                 name: str = 'residual_unit'):\n    \"\"\"Residual unit.\n\n    Residual unit for use in :func:`Decoder_block` and :func:`Encoder_block`.\n\n    Parameters:\n        filters:\n            Number of filters in the convolutional layers.\n        activation:\n            Name of activation function. Default is `None`.\n        depth_wise:\n            Whether to use depth-wise separable convolutions. Default is `False`.\n        kernel_size:\n            Kernel size of the convolutional layers. Default is 1.\n        ratio:\n            Ratio of filters in the first convolutional layer, which will have `filters // ratio` filters.\n            The second convolutional layer will have `filters` filters. Default is 1.\n        name:\n            Name of the model.  Default is `residual_unit`.\n\n    Model inputs:\n        Tensor of shape `(set_size, input_length, filters)`.\n\n    Model outputs:\n        Tensor of shape `(set_size, input_length, filters)`.\n\n    \"\"\"\n\n    # filters = y.shape.as_list()[-1]\n\n    def residal_unit(x: tf.Tensor) -&gt; tf.Tensor:\n        shortcut = x\n        Conv1D = ks.layers.SeparableConv1D if depth_wise else ks.layers.Conv1D\n\n        # 1. convolution\n        x = ks.layers.BatchNormalization(name=name + '_bn1')(x)\n        x = ks.layers.Activation(activation, name=name + '_act1')(x)\n        x = ks.layers.TimeDistributed(\n            Conv1D(filters=filters // ratio, kernel_size=kernel_size, padding='causal', name=name + '_conv1'))(x)\n\n        # 2. convolution\n        x = ks.layers.BatchNormalization(name=name + '_bn2')(x)\n        x = ks.layers.Activation(activation, name=name + '_act2')(x)\n        x = ks.layers.TimeDistributed(\n            Conv1D(filters=filters, kernel_size=kernel_size, padding='causal', name=name + '_conv2'))(x)\n\n        # residual connection\n        x = ks.layers.Add(name=name + '_add')([shortcut, x])\n\n        return x\n\n    return residal_unit\n</code></pre>"},{"location":"VAE.models/#VAE.models.VAE","title":"VAE.models.VAE","text":"<pre><code>VAE(encoder, decoder, latent_sampling, beta=1.0, delta=0.0, delta_between=0.0, gamma=0.0, gamma_between=0.0, gamma_within=0.0, repeat_samples=1, learning_rate=0.001, clipnorm=1.0, kl_threshold=None, free_bits=None, taper_range=None, trainable=None, name='mVAE', **kwargs)\n</code></pre> <p>Variational auto-encoder model.</p> <p>This function takes a <code>decoder</code>, <code>encoder</code>, and <code>latent sampling</code> model and creates and compiles a variational auto-encoder (VAE).</p> <p>Parameters:</p> <ul> <li> <code>encoder</code>             (<code>Model</code>)         \u2013          <p>Encoder model.</p> </li> <li> <code>decoder</code>             (<code>Model</code>)         \u2013          <p>Decoder model.</p> </li> <li> <code>latent_sampling</code>             (<code>Model</code>)         \u2013          <p>LatentSampling model.</p> </li> <li> <code>beta</code>             (<code>Union[float, str]</code>, default:                 <code>1.0</code> )         \u2013          <p>Loss weight of the KL divergence. If <code>str</code>, loss weight will be input to the model, which can be used to to anneal the KL divergence loss during training. The input name is determined by the <code>beta</code> argument.</p> </li> <li> <code>clipnorm</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Gradient clipping norm.</p> </li> <li> <code>delta</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of similarity loss.</p> </li> <li> <code>delta_between</code>         \u2013          <p>float (optional) Scale of similarity loss between repeated samples.</p> </li> <li> <code>gamma</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss.</p> </li> <li> <code>gamma_between</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss between repeated samples.</p> </li> <li> <code>gamma_within</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss within repeated samples.</p> </li> <li> <code>learning_rate</code>             (<code>float</code>, default:                 <code>0.001</code> )         \u2013          <p>Learning rate.</p> </li> <li> <code>kl_threshold</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Lower bound for the KL divergence.</p> </li> <li> <code>free_bits</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Number of bits to keep free for the KL divergence per latent dimension.</p> </li> <li> <code>repeat_samples</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of repetitions of input samples in a batch ensemble.</p> </li> <li> <code>taper_range</code>             (<code>tuple[float, float]</code>, default:                 <code>None</code> )         \u2013          <p>Start and stop of the linear taper used to scale the squared error loss of the decoder. The taper is normalized to have mean 1.</p> </li> <li> <code>trainable</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>Names of the model's trainable layers. Defaults is None, meaning all layers are trainable.</p> </li> <li> <code>name</code>         \u2013          <p>Name of the model.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>keras.Model</code>.</p> </li> </ul> Source code in <code>VAE/models.py</code> <pre><code>def VAE(encoder: ks.Model,\n        decoder: ks.Model,\n        latent_sampling: ks.Model,\n        beta: Union[float, str] = 1.,\n        delta: float = 0.,\n        delta_between: float = 0.,\n        gamma: float = 0.,\n        gamma_between: float = 0.,\n        gamma_within: float = 0.,\n        repeat_samples: int = 1,\n        learning_rate: float = 0.001,\n        clipnorm: float = 1.,\n        kl_threshold: float = None,\n        free_bits: float = None,\n        taper_range: tuple[float, float] = None,\n        trainable: list[str] = None,\n        name='mVAE',\n        **kwargs) -&gt; ks.Model:\n    \"\"\"Variational auto-encoder model.\n\n    This function takes a `decoder`, `encoder`, and `latent sampling` model and creates and compiles a variational\n    auto-encoder (VAE).\n\n    Parameters:\n        encoder:\n            Encoder model.\n        decoder:\n            Decoder model.\n        latent_sampling:\n            LatentSampling model.\n        beta:\n            Loss weight of the KL divergence. If `str`, loss weight will be input to the model, which can be used to\n            to anneal the KL divergence loss during training. The input name is determined by the `beta` argument.\n        clipnorm:\n            Gradient clipping norm.\n        delta:\n            Scale of similarity loss.\n        delta_between : float (optional)\n            Scale of similarity loss between repeated samples.\n        gamma:\n            Scale of total correlation loss.\n        gamma_between:\n            Scale of total correlation loss between repeated samples.\n        gamma_within:\n            Scale of total correlation loss within repeated samples.\n        learning_rate:\n            Learning rate.\n        kl_threshold:\n            Lower bound for the KL divergence.\n        free_bits:\n            Number of bits to keep free for the KL divergence per latent dimension.\n        repeat_samples:\n            Number of repetitions of input samples in a batch ensemble.\n        taper_range:\n            Start and stop of the linear taper used to scale the squared error loss of the decoder. The taper is\n            normalized to have mean 1.\n        trainable:\n            Names of the model's trainable layers. Defaults is None, meaning all layers are trainable.\n        name:\n            Name of the model.\n\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    \"\"\"\n    # model inputs\n    if len(encoder.inputs) == 1:\n        encoder_input = [ks.layers.Input(encoder.input_shape[1:], name=encoder.input_names[0])]\n        encoder_cond = []\n    else:\n        encoder_input = [ks.layers.Input(encoder.inputs[0].shape.as_list()[1:], name=encoder.input_names[0])]\n        encoder_cond = [ks.layers.Input(encoder.inputs[1].shape.as_list()[1:], name=encoder.input_names[1])]\n\n    if len(decoder.inputs) == 1:\n        decoder_cond = []\n    else:\n        decoder_cond = [ks.layers.Input(decoder.inputs[1].shape.as_list()[1:], name=decoder.input_names[1])]\n\n    if len(latent_sampling.inputs) == 2:\n        latent_sigma = []\n    else:\n        latent_sigma = [\n            ks.layers.Input(latent_sampling.inputs[2].shape.as_list()[1:], name=latent_sampling.input_names[2])\n        ]\n\n    inputs = encoder_input + encoder_cond + decoder_cond + latent_sigma\n\n    # add optional input for beta parameter\n    if isinstance(beta, str):\n        beta = ks.layers.Input((1, ), name=beta)\n        inputs += [beta]\n    else:\n        beta = tf.constant(beta, shape=(1, ), name='beta')\n\n    # encoding\n    z_mean, z_log_var = encoder(encoder_input + encoder_cond)\n\n    # latent sampling\n    z = latent_sampling([z_mean, z_log_var] + latent_sigma)\n\n    # decoding\n    outputs = decoder([z] + decoder_cond)\n\n    # create model\n    model = ks.Model(inputs=inputs, outputs=outputs, name=name)\n\n    # set trainable layers\n    if trainable is not None:\n        collection.set_trainable(model, trainable)\n\n    _, _, decoder_length, decoder_channels = decoder.outputs[0].shape.as_list()\n    decoder_size = decoder_length * decoder_channels\n\n    # optional taper\n    if taper_range is not None:\n        start, stop = taper_range\n        decoder_taper = np.linspace(start, stop, num=decoder_length)\n        decoder_taper /= np.mean(decoder_taper)\n    else:\n        decoder_taper = None\n\n    # training loss\n    loss = vaelosses.VAEloss(z,\n                             z_mean,\n                             z_log_var,\n                             size=decoder_size,\n                             beta=beta,\n                             delta=delta,\n                             delta_between=delta_between,\n                             gamma=gamma,\n                             gamma_between=gamma_between,\n                             gamma_within=gamma_within,\n                             kl_threshold=kl_threshold,\n                             free_bits=free_bits,\n                             repeat_samples=repeat_samples,\n                             taper=decoder_taper)\n\n    # metrics\n    weighted_metrics = [vaelosses.SquaredError(size=decoder_size), vaelosses.KLDivergence(z_mean, z_log_var), 'mse']\n\n    if gamma:\n        weighted_metrics.append(vaelosses.TotalCorrelation(z, z_mean, z_log_var))\n\n    if gamma_between:\n        weighted_metrics.append(vaelosses.TotalCorrelationBetween(z, z_mean, z_log_var, repeat_samples=repeat_samples))\n\n    if gamma_within:\n        weighted_metrics.append(vaelosses.TotalCorrelationWithin(z, z_mean, z_log_var, repeat_samples=repeat_samples))\n\n    if delta:\n        weighted_metrics.append(vaelosses.Similarity())\n\n    if delta_between:\n        weighted_metrics.append(vaelosses.SimilarityBetween(repeat_samples=repeat_samples))\n\n    metrics = [vaelogs.Beta(beta), vaelogs.ActiveUnits(z_mean, z_log_var)]\n\n    # compile model\n    optimizer = ks.optimizers.Adam(learning_rate=learning_rate, clipnorm=clipnorm)\n    model.compile(optimizer=optimizer,\n                  loss=loss,\n                  metrics=metrics,\n                  weighted_metrics=weighted_metrics,\n                  sample_weight_mode='temporal')\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.VAEp","title":"VAE.models.VAEp","text":"<pre><code>VAEp(encoder, decoder, latent_sampling, prediction, beta=1.0, gamma=0.0, gamma_between=0.0, gamma_within=0.0, delta=0.0, delta_between=0.0, repeat_samples=1, learning_rate=0.001, clipnorm=1.0, kl_threshold=None, free_bits=None, loss_weights=None, taper_ranges=None, trainable=None, name='mVAEp', **kwargs)\n</code></pre> <p>Variational auto-encoder model with prediction.</p> <p>This function takes <code>decoder</code>, <code>encoder</code>, <code>latent sampling</code>, and <code>prediction</code> models and creates and compiles a variational auto-encoder, combined with a decoder for prediction. The <code>prediction</code> model is second a decoder, also linked to the latent space, but that predicts samples forward in time.</p> <p>Parameters:</p> <ul> <li> <code>encoder</code>             (<code>Model</code>)         \u2013          <p>Encoder model.</p> </li> <li> <code>decoder</code>             (<code>Model</code>)         \u2013          <p>Decoder model.</p> </li> <li> <code>latent_sampling</code>             (<code>Model</code>)         \u2013          <p>LatentSampling model.</p> </li> <li> <code>prediction</code>             (<code>Model</code>)         \u2013          <p>Second decoder model for prediction.</p> </li> <li> <code>beta</code>             (<code>Union[float, str]</code>, default:                 <code>1.0</code> )         \u2013          <p>Loss weight of the KL divergence. If <code>str</code>, loss weight will be input to the model, which can be used to to anneal the KL divergence loss during training. The input name is determined by the <code>beta</code> argument.</p> </li> <li> <code>clipnorm</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Gradient clipping norm.</p> </li> <li> <code>delta</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of similarity loss.</p> </li> <li> <code>delta_between</code>         \u2013          <p>float (optional) Scale of similarity loss between repeated samples.</p> </li> <li> <code>free_bits</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Number of bits to keep free for the KL divergence per latent dimension.</p> </li> <li> <code>gamma</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss.</p> </li> <li> <code>gamma_between</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss between repeated samples.</p> </li> <li> <code>gamma_within</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Scale of total correlation loss within repeated samples.</p> </li> <li> <code>kl_threshold</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Lower bound for the KL divergence.</p> </li> <li> <code>learning_rate</code>             (<code>float</code>, default:                 <code>0.001</code> )         \u2013          <p>Learning rate.</p> </li> <li> <code>loss_weights</code>         \u2013          <p>dict Loss weights for the output of the decoder and prediction. The dict maps outputs names to scalar coefficients; e.g. <code>{'decoder': 1., 'prediction': 0.5}</code> .</p> </li> <li> <code>repeat_samples</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of repetitions of input samples.</p> </li> <li> <code>taper_range</code>         \u2013          <p>Start and stop of the linear taper used to scale the squared error loss of the decoder. The taper is normalized to have mean 1.</p> </li> <li> <code>trainable</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>Names of the model's trainable layers. Defaults is None, meaning all layers are trainable.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'mVAEp'</code> )         \u2013          <p>Name of the model.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>keras.Model</code>.</p> </li> </ul> Source code in <code>VAE/models.py</code> <pre><code>def VAEp(encoder: ks.Model,\n         decoder: ks.Model,\n         latent_sampling: ks.Model,\n         prediction: ks.Model,\n         beta: Union[float, str] = 1.,\n         gamma: float = 0.,\n         gamma_between: float = 0.,\n         gamma_within: float = 0.,\n         delta: float = 0.,\n         delta_between: float = 0.,\n         repeat_samples: int = 1,\n         learning_rate: float = 0.001,\n         clipnorm: float = 1.,\n         kl_threshold: float = None,\n         free_bits: float = None,\n         loss_weights: dict = None,\n         taper_ranges: tuple[float, float] = None,\n         trainable: list[str] = None,\n         name: str = 'mVAEp',\n         **kwargs) -&gt; ks.Model:\n    \"\"\"Variational auto-encoder model with prediction.\n\n    This function takes `decoder`, `encoder`, `latent sampling`, and `prediction` models and creates and compiles a\n    variational auto-encoder, combined with a decoder for prediction. The `prediction` model is second a decoder, also\n    linked to the latent space, but that predicts samples forward in time.\n\n    Parameters:\n        encoder:\n            Encoder model.\n        decoder:\n            Decoder model.\n        latent_sampling:\n            LatentSampling model.\n        prediction:\n            Second decoder model for prediction.\n        beta:\n            Loss weight of the KL divergence. If `str`, loss weight will be input to the model, which can be used to\n            to anneal the KL divergence loss during training. The input name is determined by the `beta` argument.\n        clipnorm:\n            Gradient clipping norm.\n        delta:\n            Scale of similarity loss.\n        delta_between : float (optional)\n            Scale of similarity loss between repeated samples.\n        free_bits:\n            Number of bits to keep free for the KL divergence per latent dimension.\n        gamma:\n            Scale of total correlation loss.\n        gamma_between:\n            Scale of total correlation loss between repeated samples.\n        gamma_within:\n            Scale of total correlation loss within repeated samples.\n        kl_threshold:\n            Lower bound for the KL divergence.\n        learning_rate:\n            Learning rate.\n        loss_weights : dict\n            Loss weights for the output of the decoder and prediction. The dict maps outputs names to scalar\n            coefficients; e.g. `{'decoder': 1., 'prediction': 0.5}` .\n        repeat_samples:\n            Number of repetitions of input samples.\n        taper_range:\n            Start and stop of the linear taper used to scale the squared error loss of the decoder. The taper is\n            normalized to have mean 1.\n        trainable:\n            Names of the model's trainable layers. Defaults is None, meaning all layers are trainable.\n        name:\n            Name of the model.\n\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    \"\"\"\n    # model inputs\n    if len(encoder.inputs) == 1:\n        encoder_input = [ks.layers.Input(encoder.input_shape[1:], name=encoder.input_names[0])]\n        encoder_cond = []\n    else:\n        encoder_input = [ks.layers.Input(encoder.inputs[0].shape.as_list()[1:], name=encoder.input_names[0])]\n        encoder_cond = [ks.layers.Input(encoder.inputs[1].shape.as_list()[1:], name=encoder.input_names[1])]\n\n    if len(decoder.inputs) == 1:\n        decoder_cond = []\n    else:\n        decoder_cond = [ks.layers.Input(decoder.inputs[1].shape.as_list()[1:], name=decoder.input_names[1])]\n\n    if len(prediction.inputs) == 1:\n        prediction_cond = []\n    else:\n        prediction_cond = [ks.layers.Input(prediction.inputs[1].shape.as_list()[1:], name=prediction.input_names[1])]\n\n    if len(latent_sampling.inputs) == 2:\n        latent_sigma = []\n    else:\n        latent_sigma = [\n            ks.layers.Input(latent_sampling.inputs[2].shape.as_list()[1:], name=latent_sampling.input_names[2])\n        ]\n\n    inputs = encoder_input + encoder_cond + decoder_cond + prediction_cond + latent_sigma\n\n    # add optional input for beta parameter\n    if isinstance(beta, str):\n        beta = ks.layers.Input((1, ), name=beta)\n        inputs += [beta]\n    else:\n        beta = tf.constant(beta, shape=(1, ), name='beta')\n\n    # encoding\n    z_mean, z_log_var = encoder(encoder_input + encoder_cond)\n\n    # latent sampling\n    z = latent_sampling([z_mean, z_log_var] + latent_sigma)\n\n    # decoding\n    outputs = [\n        decoder([z] + decoder_cond),\n        prediction([z] + prediction_cond),\n    ]\n\n    # create model\n    model = ks.Model(inputs=inputs, outputs=outputs, name=name)\n\n    # set trainable layers\n    if trainable is not None:\n        collection.set_trainable(model, trainable)\n\n    _, _, decoder_length, decoder_channels = decoder.outputs[0].shape.as_list()\n    decoder_size = decoder_length * decoder_channels\n\n    _, _, prediction_length, prediction_channels = prediction.outputs[0].shape.as_list()\n    prediction_size = prediction_length * prediction_channels\n\n    # optional taper\n    if taper_ranges is not None:\n        start, stop = taper_ranges.get(decoder.output_names[0], (1, 1))\n        decoder_taper = np.linspace(start, stop, num=decoder_length)\n        decoder_taper /= np.mean(decoder_taper)\n\n        start, stop = taper_ranges.get(prediction.output_names[0], (1, 1))\n        prediction_taper = np.linspace(start, stop, num=prediction_length)\n        prediction_taper /= np.mean(prediction_taper)\n    else:\n        decoder_taper = None\n        prediction_taper = None\n\n    # training loss\n    loss = {\n        decoder.name:\n            vaelosses.VAEloss(z,\n                              z_mean,\n                              z_log_var,\n                              beta=beta,\n                              delta=delta,\n                              delta_between=delta_between,\n                              gamma=gamma,\n                              gamma_between=gamma_between,\n                              gamma_within=gamma_within,\n                              kl_threshold=kl_threshold,\n                              free_bits=free_bits,\n                              repeat_samples=repeat_samples,\n                              size=decoder_size,\n                              taper=decoder_taper),\n        prediction.name:\n            vaelosses.VAEploss(beta=beta,\n                               delta=delta,\n                               delta_between=delta_between,\n                               repeat_samples=repeat_samples,\n                               size=prediction_size,\n                               taper=prediction_taper),\n    }\n\n    # metrics\n    weighted_metrics = {\n        decoder.name: [\n            vaelosses.SquaredError(size=decoder_size),\n            vaelosses.KLDivergence(z_mean, z_log_var),\n            'mse',\n        ],\n        prediction.name: [\n            vaelosses.SquaredError(size=prediction_size),\n            'mse',\n        ]\n    }\n\n    if gamma:\n        weighted_metrics[decoder.name].append(vaelosses.TotalCorrelation(z, z_mean, z_log_var))\n\n    if gamma_between:\n        weighted_metrics[decoder.name].append(\n            vaelosses.TotalCorrelationBetween(z, z_mean, z_log_var, repeat_samples=repeat_samples))\n\n    if gamma_within:\n        weighted_metrics[decoder.name].append(\n            vaelosses.TotalCorrelationWithin(z, z_mean, z_log_var, repeat_samples=repeat_samples))\n\n    if delta:\n        weighted_metrics[decoder.name].append(vaelosses.Similarity())\n        weighted_metrics[prediction.name].append(vaelosses.Similarity())\n\n    if delta_between:\n        weighted_metrics[decoder.name].append(vaelosses.SimilarityBetween(repeat_samples=repeat_samples))\n        weighted_metrics[prediction.name].append(vaelosses.SimilarityBetween(repeat_samples=repeat_samples))\n\n    metrics = {\n        decoder.name: [vaelogs.Beta(beta), vaelogs.ActiveUnits(z_mean, z_log_var)],\n    }\n\n    # compile model\n    optimizer = ks.optimizers.Adam(learning_rate=learning_rate, clipnorm=clipnorm)\n    model.compile(optimizer=optimizer,\n                  loss=loss,\n                  loss_weights=loss_weights,\n                  metrics=metrics,\n                  weighted_metrics=weighted_metrics,\n                  sample_weight_mode='temporal')\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.IdentityModel","title":"VAE.models.IdentityModel","text":"<pre><code>IdentityModel(input_shape, set_size=1)\n</code></pre> <p>Identity model.</p> <p>This function creates an identity model, which returns the input as output.</p> <p>Parameters:</p> <ul> <li> <code>input_shape</code>             (<code>tuple[int, int]</code>)         \u2013          <p>Input shape of the model, excluding the <code>set_size</code> dimension.</p> </li> <li> <code>set_size</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of input samples in a set.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>Instance of :class:<code>keras.Model</code>.</p> </li> </ul> Model inputs <p>Tensor of shape <code>(set_size, ) + input_shape</code>.</p> Model outputs <p>Tensor of shape <code>(set_size, ) + input_shape</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def IdentityModel(input_shape: tuple[int, int], set_size: int = 1) -&gt; ks.Model:\n    \"\"\"Identity model.\n\n    This function creates an identity model, which returns the input as output.\n\n    Parameters:\n        input_shape:\n            Input shape of the model, excluding the `set_size` dimension.\n        set_size:\n            Number of input samples in a set.\n\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    Model inputs:\n        Tensor of shape `(set_size, ) + input_shape`.\n\n    Model outputs:\n        Tensor of shape `(set_size, ) + input_shape`.\n\n    \"\"\"\n    xin = ks.layers.Input((set_size, ) + tuple(input_shape), name='encoder_input')\n    y = ks.layers.Lambda(lambda x: x, name='decoder')(xin)\n    model = ks.Model(xin, y, name='Identity')\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.example_VAE","title":"VAE.models.example_VAE","text":"<pre><code>example_VAE()\n</code></pre> <p>Example of a VAE model.</p> <p>This function demonstrates how to build a VAE model using the method :func:<code>VAE.models.VAE</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def example_VAE():\n    \"\"\"Example of a VAE model.\n\n    This function demonstrates how to build a VAE model using the method :func:`VAE.models.VAE`.\n    \"\"\"\n\n    # We first define the parameters of the model:\n    params = {\n        'encoder_blocks': 1,\n        'cond_size': 12,\n        'fc_units': 48,\n        'filters': 16,\n        'input_shape': [16, 7],\n        'latent_dim': 10,\n        'trainable': ['*bn*'],\n    }\n\n    # Then we build the different parts of the model. We start with the encoder:\n    encoder = Encoder(**params, name='encoder')\n\n    # and the latent sampling layer:\n    latent_sampling = LatentSampling(**params, name='latent')\n\n    # and finally the decoder:\n    decoder = Decoder(output_shape=params['input_shape'],\n                      decoder_blocks=params['encoder_blocks'],\n                      output_reverse=True,\n                      **params,\n                      name='decoder')\n\n    # Once we have the different parts of the model, we can build the full model:\n    model = VAE(encoder, decoder, latent_sampling, **params, name='VAE')\n\n    # Let's have a look at the model:\n    model.summary()\n\n    # We can also have a look at the trainable parameters:\n    collection.summary_trainable(model)\n\n    # and plot the model:\n    ks.utils.plot_model(model, show_shapes=True, dpi=75, rankdir='LR', to_file='example_VAE.png')\n\n    return model\n</code></pre>"},{"location":"VAE.models/#VAE.models.example_VAEp","title":"VAE.models.example_VAEp","text":"<pre><code>example_VAEp()\n</code></pre> <p>Example of a VAEp model.</p> <p>This function demonstrates how to build a VAEp model using the method :func:<code>VAE.models.VAEp</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def example_VAEp():\n    \"\"\"Example of a VAEp model.\n\n    This function demonstrates how to build a VAEp model using the method :func:`VAE.models.VAEp`.\n    \"\"\"\n\n    # We first define the parameters of the model:\n    params = {\n        'encoder_blocks': 1,\n        'cond_size': 12,\n        'fc_units': 48,\n        'filters': 16,\n        'input_shape': [16, 7],\n        'latent_dim': 10,\n        'trainable': ['*bn*'],\n        'prediction_shape': [16, 1],\n    }\n\n    # Then we build the different parts of the model. We start with the encoder:\n    encoder = Encoder(**params, name='encoder')\n\n    # and the latent sampling layer:\n    latent_sampling = LatentSampling(**params, name='latent')\n\n    # Then we build the decoder:\n    decoder = Decoder(output_shape=params['input_shape'],\n                      decoder_blocks=params['encoder_blocks'],\n                      output_reverse=True,\n                      **params,\n                      name='decoder')\n\n    # and a second decoder for the prediction:\n    prediction = Decoder(output_shape=params['prediction_shape'],\n                         decoder_blocks=params['encoder_blocks'],\n                         output_reverse=False,\n                         **params,\n                         name='prediction')\n\n    # Once we have the different parts of the model, we can build the full model:\n    model = VAEp(encoder, decoder, latent_sampling, prediction, **params, name='VAEp')\n\n    # Let's have a look at the model:\n    model.summary()\n\n    # We can also have a look at the trainable parameters:\n    collection.summary_trainable(model)\n\n    # and plot the model:\n    ks.utils.plot_model(model, show_shapes=True, dpi=75, rankdir='LR', to_file='example_VAEp.png')\n\n    return model\n</code></pre>"},{"location":"VAE.utils.beta_schedulers/","title":"Beta Scheduler","text":""},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers","title":"VAE.utils.beta_schedulers","text":"<p>Collection of beta schedulers.</p> <p>Beta schedulers are used to schedule the beta value of the KL divergence during training. Beta schedulers are used in the :class:<code>generators</code>.</p>"},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers.BetaScheduler","title":"VAE.utils.beta_schedulers.BetaScheduler","text":"<pre><code>BetaScheduler(dtype='float')\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Abstract class for beta schedulers.</p> <p>This is the abstract base class for all beta schedulers.</p> <p>Beta schedulers should implement the method :func:<code>__call__</code> and can optionally overwrite the method :func:<code>get_config</code></p> <p>Parameters:</p> <ul> <li> <code>dtype</code>             (<code>str</code>, default:                 <code>'float'</code> )         \u2013          <p>Data type of the returned beta values.</p> </li> </ul> Source code in <code>VAE/utils/beta_schedulers.py</code> <pre><code>def __init__(self, dtype: str = 'float'):\n    self.dtype = dtype\n</code></pre>"},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers.BetaScheduler.__call__","title":"VAE.utils.beta_schedulers.BetaScheduler.__call__  <code>abstractmethod</code>","text":"<pre><code>__call__(epoch, shape=(1))\n</code></pre> <p>Return beta value.</p> <p>Abstract method that has to be implemented by all beta schedulers. This method is called during training to obtain the beta values for the current <code>epoch</code>. The <code>shape</code> parameter defines the shape of the returned array of constant beta values.</p> <p>Parameters:</p> <ul> <li> <code>epoch</code>             (<code>int</code>)         \u2013          <p>Training epoch for with the beta values will be return.</p> </li> <li> <code>shape</code>             (<code>tuple[int, ...]</code>, default:                 <code>(1)</code> )         \u2013          <p>Output shape for the beta values that will be returned.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Array of shape <code>shape</code> filled with beta values.</p> </li> </ul> Source code in <code>VAE/utils/beta_schedulers.py</code> <pre><code>@abc.abstractmethod\ndef __call__(self, epoch: int, shape: tuple[int, ...] = (1, )) -&gt; np.ndarray:\n    \"\"\"Return beta value.\n\n    Abstract method that has to be implemented by all beta schedulers. This method is called during training to\n    obtain the beta values for the current `epoch`. The `shape` parameter defines the shape of the returned array\n    of constant beta values.\n\n    Parameters:\n        epoch:\n            Training epoch for with the beta values will be return.\n        shape:\n            Output shape for the beta values that will be returned.\n\n    Returns:\n        Array of shape `shape` filled with beta values.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers.BetaScheduler.get_config","title":"VAE.utils.beta_schedulers.BetaScheduler.get_config","text":"<pre><code>get_config()\n</code></pre> <p>Get configuration.</p> <p>Returns:</p> <ul> <li> <code>dict</code>         \u2013          <p>Dictionary with the configuration of the beta scheduler.</p> </li> </ul> Source code in <code>VAE/utils/beta_schedulers.py</code> <pre><code>def get_config(self) -&gt; dict:\n    \"\"\"Get configuration.\n\n    Returns:\n        Dictionary with the configuration of the beta scheduler.\n\n    \"\"\"\n    return {'dtype': self.dtype}\n</code></pre>"},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers.BetaScheduler.summary","title":"VAE.utils.beta_schedulers.BetaScheduler.summary","text":"<pre><code>summary()\n</code></pre> <p>Print a summary of the beta scheduler.</p> Source code in <code>VAE/utils/beta_schedulers.py</code> <pre><code>def summary(self):\n    \"\"\"Print a summary of the beta scheduler.\"\"\"\n    config = self.get_config()\n    cols = len(max(config.keys(), key=len))\n    print(f'Summary of \"{self.__class__.__name__}\" (BetaScheduler)')\n    for key, value in config.items():\n        print(f'  {key:{cols}} : {value}')\n</code></pre>"},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers.Constant","title":"VAE.utils.beta_schedulers.Constant","text":"<pre><code>Constant(value=1.0, **kwargs)\n</code></pre> <p>             Bases: <code>BetaScheduler</code></p> <p>Return constant beta value.</p> <p>This beta scheduler returns a constant beta value for all epochs.</p> <p>Parameters:</p> <ul> <li> <code>value</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Value of beta.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional arguments for :class:<code>BetaScheduler</code>.</p> </li> </ul> Source code in <code>VAE/utils/beta_schedulers.py</code> <pre><code>def __init__(self, value: float = 1., **kwargs):\n    super().__init__(**kwargs)\n    self.value = value\n</code></pre>"},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers.Linear","title":"VAE.utils.beta_schedulers.Linear","text":"<pre><code>Linear(lower=0.0, upper=1.0, epochs=10, **kwargs)\n</code></pre> <p>             Bases: <code>BetaScheduler</code></p> <p>Linearly increase beta value.</p> <p>This beta scheduler returns a linearly increasing beta value.</p> <p>Parameters:</p> <ul> <li> <code>lower</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Lower (left) bound of beta.</p> </li> <li> <code>upper</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Upper (right) bound of beta.</p> </li> <li> <code>epochs</code>             (<code>float</code>, default:                 <code>10</code> )         \u2013          <p>Number of epochs for which beta will be increased. If the number of epochs is reached, beta will be constant at the upper bound.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional arguments for :class:<code>BetaScheduler</code>.</p> </li> </ul> Source code in <code>VAE/utils/beta_schedulers.py</code> <pre><code>def __init__(self, lower: float = 0., upper: float = 1., epochs: float = 10, **kwargs):\n    super().__init__(**kwargs)\n    self.lower = lower\n    self.upper = upper\n    self.epochs = epochs\n    self.values = np.linspace(lower, upper, epochs)\n</code></pre>"},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers.LogisticGrowth","title":"VAE.utils.beta_schedulers.LogisticGrowth","text":"<pre><code>LogisticGrowth(lower=0.0, upper=1.0, midpoint=5.0, rate=1.0, **kwargs)\n</code></pre> <p>             Bases: <code>BetaScheduler</code></p> <p>Increase beta to maximum value at given rate.</p> <p>This beta scheduler returns a beta value that increases to a maximum value at a given rate. The beta value follows a logistic growth function.</p> <p>Parameters:</p> <ul> <li> <code>lower</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>Lower (left) asymptote of beta.</p> </li> <li> <code>upper</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Upper (right) asymptote of beta.</p> </li> <li> <code>midpoint</code>             (<code>float</code>, default:                 <code>5.0</code> )         \u2013          <p>Epoch at which beta equals the mean of the upper and lower asymptote.</p> </li> <li> <code>rate</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Growth rate at which beta increases.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional arguments for :class:<code>BetaScheduler</code>.</p> </li> </ul> Source code in <code>VAE/utils/beta_schedulers.py</code> <pre><code>def __init__(self, lower: float = 0., upper: float = 1., midpoint: float = 5., rate: float = 1., **kwargs):\n    super().__init__(**kwargs)\n    self.lower = lower\n    self.upper = upper\n    self.midpoint = midpoint\n    self.rate = rate\n</code></pre>"},{"location":"VAE.utils.beta_schedulers/#VAE.utils.beta_schedulers.LogUniform","title":"VAE.utils.beta_schedulers.LogUniform","text":"<pre><code>LogUniform(lower=0.01, upper=1.0, **kwargs)\n</code></pre> <p>             Bases: <code>BetaScheduler</code></p> <p>Draw beta values from log-uniform distribution.</p> <p>This beta scheduler draws beta values from a log-uniform distribution. The log-uniform distribution is a uniform distribution in log-space.</p> <p>Parameters:</p> <ul> <li> <code>lower</code>             (<code>float</code>, default:                 <code>0.01</code> )         \u2013          <p>Lower (minimum) value of the distribution.</p> </li> <li> <code>upper</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Upper (maximum) value of the distribution.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional arguments for :class:<code>BetaScheduler</code>.</p> </li> </ul> Source code in <code>VAE/utils/beta_schedulers.py</code> <pre><code>def __init__(self, lower: float = 0.01, upper: float = 1., **kwargs):\n    super().__init__(**kwargs)\n    self.lower = lower\n    self.upper = upper\n    self.fcn = loguniform(lower, upper)\n</code></pre>"},{"location":"VAE.utils.collection/","title":"Helper functions","text":""},{"location":"VAE.utils.collection/#VAE.utils.collection","title":"VAE.utils.collection","text":"<p>Collection of helper functions.</p>"},{"location":"VAE.utils.collection/#VAE.utils.collection.TrainerConfigCollection","title":"VAE.utils.collection.TrainerConfigCollection","text":"<pre><code>TrainerConfigCollection(path='.', filemask='*.yaml', recursive=True, verbose=True)\n</code></pre> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str</code>, default:                 <code>'.'</code> )         \u2013          <p>Path to the training configuration files. Defaults to <code>.</code>.</p> </li> <li> <code>filemask</code>             (<code>str</code>, default:                 <code>'*.yaml'</code> )         \u2013          <p>Filename or filemask of the training configuration files. Defaults to <code>*.yaml</code>.</p> </li> <li> <code>recursive</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Recursive search in subdirectories. Defaults to True.</p> </li> <li> <code>verbose</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Verbose output. Defaults to True.</p> </li> </ul> Source code in <code>VAE/utils/collection.py</code> <pre><code>def __init__(self, path: str = '.', filemask: str = '*.yaml', recursive: bool = True, verbose: bool = True):\n    \"\"\"Collect the training configurations for a given path.\n\n    Parameters:\n        path:\n            Path to the training configuration files. Defaults to `.`.\n        filemask:\n            Filename or filemask of the training configuration files. Defaults to `*.yaml`.\n        recursive:\n            Recursive search in subdirectories. Defaults to True.\n        verbose:\n            Verbose output. Defaults to True.\n    \"\"\"\n    self.path = os.path.abspath(path)\n    self.filemask = filemask\n    self.recursive = recursive\n    self.verbose = verbose\n    self.__read__()\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.TrainerConfigCollection.__getitem__","title":"VAE.utils.collection.TrainerConfigCollection.__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Get configurations for a given key.</p> <p>Parameters:</p> <ul> <li> <code>key</code>         \u2013          <p>str Key of the training configuration. For example 'fit_generator' or 'model'. For a list of keys see :func:<code>keys</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>         \u2013          <p>Dictionary of configuration parameters for the given key.</p> </li> </ul> Source code in <code>VAE/utils/collection.py</code> <pre><code>def __getitem__(self, key) -&gt; dict:\n    \"\"\"Get configurations for a given key.\n\n    Parameters:\n        key : str\n            Key of the training configuration. For example 'fit_generator' or 'model'.\n            For a list of keys see :func:`keys`.\n\n    Returns:\n        Dictionary of configuration parameters for the given key.\n    \"\"\"\n    return self.configs[key]\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.TrainerConfigCollection.__read__","title":"VAE.utils.collection.TrainerConfigCollection.__read__","text":"<pre><code>__read__()\n</code></pre> <p>Read the configuration files.</p> Source code in <code>VAE/utils/collection.py</code> <pre><code>def __read__(self):\n    \"\"\"Read the configuration files.\"\"\"\n    if self.recursive:\n        pathname = os.path.join(self.path, '**', self.filemask)\n    else:\n        pathname = os.path.join(self.path, self.filemask)\n\n    self.filenames = glob.glob(pathname, recursive=self.recursive)\n\n    self.filenames = [os.path.normpath(filename) for filename in self.filenames]\n\n    self.indices = []\n    for filename in self.filenames:\n        tail = os.path.relpath(os.path.dirname(os.path.abspath(filename)), start=self.path)\n        self.indices.append(tail)\n\n    self.configs = dict()\n    for index, filename in zip(self.indices, self.filenames):\n        with open(filename, 'r') as f:\n            config = yaml.load(f, Loader=yaml.FullLoader)\n            for key, values in config.items():\n                cfg = self.configs.setdefault(key, {})\n                cfg[index] = values\n\n    if self.verbose:\n        print(f'{len(self.filenames)} files found.')\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.TrainerConfigCollection.keys","title":"VAE.utils.collection.TrainerConfigCollection.keys","text":"<pre><code>keys()\n</code></pre> <p>Return list of keys.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>dictitems</p> </li> </ul> Source code in <code>VAE/utils/collection.py</code> <pre><code>def keys(self):\n    \"\"\"Return list of keys.\n\n    Returns:\n        dictitems\n    \"\"\"\n    return self.configs.keys()\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.TrainerConfigCollection.to_dataframe","title":"VAE.utils.collection.TrainerConfigCollection.to_dataframe","text":"<pre><code>to_dataframe(key, fillna='')\n</code></pre> <p>Convert configurations to dataframe.</p> <p>Parameters:</p> <ul> <li> <code>key</code>         \u2013          <p>str Key of the training configuration.</p> </li> <li> <code>fillna</code>         \u2013          <p>str, optional Fill value for missing values. Defaults to ''.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>pd.DataFrame</p> </li> </ul> Source code in <code>VAE/utils/collection.py</code> <pre><code>def to_dataframe(self, key, fillna=''):\n    \"\"\"Convert configurations to dataframe.\n\n    Parameters:\n        key : str\n            Key of the training configuration.\n        fillna : str, optional\n            Fill value for missing values. Defaults to ''.\n\n    Returns:\n        pd.DataFrame\n    \"\"\"\n    df = pd.DataFrame.from_records(self.__getitem__(key))\n    df = df.transpose()\n    df = df.fillna(fillna)\n    df.sort_index(axis=1, inplace=True)\n    df.sort_index(axis=0, inplace=True)\n\n    return df\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.TrainerConfigCollection.to_excel","title":"VAE.utils.collection.TrainerConfigCollection.to_excel","text":"<pre><code>to_excel(filename, key=None, fillna='', column_width=None)\n</code></pre> <p>Write configurations to excel file.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>         \u2013          <p>str Filename of excel file to write.</p> </li> <li> <code>key</code>         \u2013          <p>str, optional Key of the training configuration(s) to write, defaults to None, i.e. write all configurations.</p> </li> <li> <code>fillna</code>         \u2013          <p>str, optional Fill value for missing values, defaults to ''.</p> </li> <li> <code>column_width</code>         \u2013          <p>float, optional Fixed column width, defaults to None.</p> </li> </ul> Source code in <code>VAE/utils/collection.py</code> <pre><code>def to_excel(self, filename, key=None, fillna='', column_width=None):\n    \"\"\"Write configurations to excel file.\n\n    Parameters:\n        filename : str\n            Filename of excel file to write.\n        key : str, optional\n            Key of the training configuration(s) to write, defaults to None, i.e. write all configurations.\n        fillna : str, optional\n            Fill value for missing values, defaults to ''.\n        column_width : float, optional\n            Fixed column width, defaults to None.\n    \"\"\"\n    if key is None:\n        keys = self.keys()\n    else:\n        keys = list(key)\n\n    full_filename = os.path.abspath(os.path.join(self.path, filename))\n    if self.verbose:\n        print(f'Write output to {full_filename}')\n\n    with pd.ExcelWriter(full_filename) as writer:\n        for current_key in sorted(keys):\n            df = self.to_dataframe(current_key, fillna=fillna)\n            df.to_excel(writer, sheet_name=current_key)\n            writer.sheets[current_key].freeze_panes = \"B2\"\n\n            if column_width is None:\n                width = max([len(column) for column in df.columns])\n            else:\n                width = column_width\n\n            for column_cells in writer.sheets[current_key].columns:\n                header = column_cells[0]\n                writer.sheets[current_key].column_dimensions[header.column_letter].width = width\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.complete_shape","title":"VAE.utils.collection.complete_shape","text":"<pre><code>complete_shape(inputs, partial_shape)\n</code></pre> <p>Complete partially-known shape based on inputs shape.</p> <p>Input shape of <code>inputs</code> must be of the same length as <code>partial_shape</code>. <code>None</code> values in <code>partial_shape</code> will be replaced with the corresponding dimension of <code>inputs</code>. The resulting shape is returned as a tensor of the same length as the shape of <code>inputs</code>.</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor that is used to complete shape.</p> </li> <li> <code>partial_shape</code>             (<code>tuple[int, ...]</code>)         \u2013          <p>Partial shape to complete.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor with completed shape.</p> </li> </ul> Source code in <code>VAE/utils/collection.py</code> <pre><code>def complete_shape(inputs: tf.Tensor, partial_shape: tuple[int, ...]) -&gt; tf.Tensor:\n    \"\"\"Complete partially-known shape based on inputs shape.\n\n    Input shape of `inputs` must be of the same length as `partial_shape`. `None` values in `partial_shape` will be\n    replaced with the corresponding dimension of `inputs`. The resulting shape is returned as a tensor of the same\n    length as the shape of `inputs`.\n\n    Parameters:\n        inputs:\n            Input tensor that is used to complete shape.\n        partial_shape:\n            Partial shape to complete.\n\n    Returns:\n        Tensor with completed shape.\n    \"\"\"\n    inputs_shape = tf.shape(inputs)\n\n    if partial_shape is None:\n        return inputs_shape\n\n    complete_shape = []\n    for n, value in enumerate(partial_shape):\n        complete_shape.append(inputs_shape[n] if value is None else value)\n\n    return tf.convert_to_tensor(complete_shape)\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.summary_trainable","title":"VAE.utils.collection.summary_trainable","text":"<pre><code>summary_trainable(model, line_length=80)\n</code></pre> <p>Print model summary of trainable parameters.</p> <p>This function prints a summary of trainable layers of a model.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>Model</code>)         \u2013          <p>Model to be summarized.</p> </li> <li> <code>line_length</code>             (<code>int</code>, default:                 <code>80</code> )         \u2013          <p>Total length of each printed line.</p> </li> </ul> Source code in <code>VAE/utils/collection.py</code> <pre><code>def summary_trainable(model: ks.Model, line_length: int = 80):\n    \"\"\"Print model summary of trainable parameters.\n\n    This function prints a summary of trainable layers of a model.\n\n    Parameters:\n        model:\n            Model to be summarized.\n        line_length:\n            Total length of each printed line.\n\n    \"\"\"\n    def recursion(layer: ks.layers.Layer, level=0):\n        trainable_weights = sum(K.count_params(p) for p in layer.trainable_weights)\n\n        if trainable_weights:\n            if level == 0:\n                print('=' * line_length)\n            elif level == 1:\n                print('_' * line_length)\n\n            layer_name = ' ' * level * 2 + layer.name\n            layer_name = f'{layer_name:{c1}.{c1}s}'\n            layer_type = f'{layer.__class__.__name__:{c2}.{c2}s}'\n            layer_params = f'{trainable_weights:&gt;{c3},d}'\n            print(f'{layer_name} {layer_type} {layer_params}')\n\n        for children in layer._flatten_layers(recursive=False, include_self=False):\n            recursion(children, level + 1)\n\n    c1 = line_length // 2\n    c2 = line_length // 4\n    c3 = line_length - c1 - c2 - 2\n\n    print('_' * line_length)\n    print(f'{\"Layer\":{c1}} {\"Type\":{c2}} {\"# params\":&gt;{c3}}')\n    recursion(model)\n    print('_' * line_length)\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.set_trainable","title":"VAE.utils.collection.set_trainable","text":"<pre><code>set_trainable(model, trainable, verbose=False)\n</code></pre> <p>Set trainable layers of a Keras model.</p> <p>This function sets the trainable property of layers of a Keras model. The layers to be set trainable can be defined by their name. Unix shell-style wildcards can be used. If a layer is set to trainable, all its children will be set to trainable as well.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>Model</code>)         \u2013          <p>Model to be modified.</p> </li> <li> <code>trainable</code>             (<code>Union[str, List[str]]</code>)         \u2013          <p>Layer names to be set to trainable. Unix shell-style wildcards can be used.</p> </li> <li> <code>verbose</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Print the names of the layers that are set to trainable if <code>True</code>.</p> </li> </ul> Source code in <code>VAE/utils/collection.py</code> <pre><code>def set_trainable(model: ks.Model, trainable: Union[str, List[str]], verbose: bool = False):\n    \"\"\"Set trainable layers of a Keras model.\n\n    This function sets the trainable property of layers of a Keras model. The layers to be set trainable can be\n    defined by their name. Unix shell-style wildcards can be used. If a layer is set to trainable, all its children\n    will be set to trainable as well.\n\n    Parameters:\n        model:\n            Model to be modified.\n        trainable:\n            Layer names to be set to trainable. Unix shell-style wildcards can be used.\n        verbose:\n            Print the names of the layers that are set to trainable if `True`.\n\n    \"\"\"\n    def recursion(layer: ks.layers.Layer, layer_names: set):\n        sublayers = list(layer._flatten_layers(recursive=False, include_self=False))\n        if sublayers:\n            for sublayer in sublayers:\n                recursion(sublayer, layer_names)\n        else:\n            if layer.name not in layer_names:\n                layer.trainable = False\n\n    if isinstance(trainable, str):\n        trainable = [trainable]\n\n    model_layer_names = [layer.name for layer in model._flatten_layers()]\n    trainable_layers = []\n    for pattern in trainable:\n        trainable_layers.extend(fnmatch.filter(model_layer_names, pattern))\n\n    trainable_layers = set(trainable_layers)\n\n    if verbose:\n        names = '\\n  '.join(sorted(trainable_layers))\n        print(f'Setting trainable layers:\\n  {names}')\n\n    for layer in model._flatten_layers():\n        layer.trainable = True\n\n    recursion(model, trainable_layers)\n</code></pre>"},{"location":"VAE.utils.collection/#VAE.utils.collection.SubModel","title":"VAE.utils.collection.SubModel","text":"<pre><code>SubModel(model, layer_name, flatten=False)\n</code></pre> <p>Get a submodel of a Keras model.</p> <p>This function returns a submodel of a Keras model. The submodel takes the same input as the original model, and covers all layers of the original model between the input layer and the layer(s) with the specified name.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>Model</code>)         \u2013          <p>Model to be submodeled.</p> </li> <li> <code>layer_name</code>             (<code>Union[str, list[str]]</code>)         \u2013          <p>If str, it specifies the name of the layer to be used as output. In this case, <code>layer_name</code> can be a substring of the layer name. If list of str, it specifies the names of the layers to be used as outputs.</p> </li> <li> <code>flatten</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, the outputs of the submodel are flattened.</p> </li> </ul> <p>Returns:     Instance of :class:<code>keras.Model</code>.</p> Source code in <code>VAE/utils/collection.py</code> <pre><code>def SubModel(model: ks.Model, layer_name: Union[str, list[str]], flatten: bool = False) -&gt; ks.Model:\n    \"\"\"Get a submodel of a Keras model.\n\n    This function returns a submodel of a Keras model. The submodel takes the same input as the original model, and\n    covers all layers of the original model between the input layer and the layer(s) with the specified name.\n\n    Parameters:\n        model:\n            Model to be submodeled.\n        layer_name:\n            If str, it specifies the name of the layer to be used as output. In this case, `layer_name` can be a\n            substring of the layer name. If list of str, it specifies the names of the layers to be used as outputs.\n        flatten:\n            If True, the outputs of the submodel are flattened.\n    Returns:\n        Instance of :class:`keras.Model`.\n\n    \"\"\"\n    if isinstance(layer_name, str):\n        outputs = [layer.output for layer in model._flatten_layers() if layer_name in layer.name]\n    else:\n        outputs = [layer.output for layer in model._flatten_layers() if layer.name in layer_name]\n\n    if not outputs:\n        raise ValueError(f'No layers with name matching \"{layer_name}\" found.')\n\n    if flatten:\n        outputs = [ks.layers.Flatten()(output) for output in outputs]\n    return ks.Model(model.inputs, outputs=outputs)\n</code></pre>"},{"location":"VAE.utils.fileio/","title":"FileIO","text":""},{"location":"VAE.utils.fileio/#VAE.utils.fileio","title":"VAE.utils.fileio","text":"<p>Collection of file readers.</p>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.read_netcdf","title":"VAE.utils.fileio.read_netcdf","text":"<pre><code>read_netcdf(filename, level_range=None, time_interval=None, time_range=None, num2date=False, datetime_unit='D', scale=1.0, dtype=None)\n</code></pre> <p>Read netCDF file.</p> The function follows the CF-1 convention and assumes data of the form <p>2D: <code>(time, level)</code> 3D: <code>(time, lat, lon)</code> 4D: <code>(time, level, lat, lon)</code></p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>Name of the netCDF file.</p> </li> <li> <code>level_range</code>             (<code>tuple[int, int]</code>, default:                 <code>None</code> )         \u2013          <p>Start and stop indices of levels to be read (in slice notation). Defaults to <code>None</code>.</p> </li> <li> <code>time_interval</code>             (<code>tuple[str, str]</code>, default:                 <code>None</code> )         \u2013          <p>Start and stop time to be read (in datetime notation). Default is 'None'.</p> </li> <li> <code>time_range</code>             (<code>tuple[int, int]</code>, default:                 <code>None</code> )         \u2013          <p>Start and stop indices along time dimensions to be read (in slice notation). Default is 'None'.</p> </li> <li> <code>num2date</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Convert time to Numpy datetime. Defaults to 'True' if 'time_interval' is given otherwise default is 'False'.</p> </li> <li> <code>datetime_unit</code>             (<code>str</code>, default:                 <code>'D'</code> )         \u2013          <p>Unit of datetime if <code>num2date</code> is set to <code>True</code>. Defaults to <code>D</code>, meaning day. For a list of units see https://numpy.org/doc/stable/reference/arrays.datetime.html#datetime-units.</p> </li> <li> <code>scale</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Scale all variables by this factor. Defaults to 1.</p> </li> <li> <code>dtype</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Data type of the variables that will be returned. Default is None, meaning dtype of netCDF file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[dict, dict, dict]</code>         \u2013          <p>tuple of three dicts containing the variables, dimensions, and attributes.</p> </li> </ul> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def read_netcdf(filename: str,\n                level_range: tuple[int, int] = None,\n                time_interval: tuple[str, str] = None,\n                time_range: tuple[int, int] = None,\n                num2date: bool = False,\n                datetime_unit: str = 'D',\n                scale: float = 1.,\n                dtype: str = None) -&gt; tuple[dict, dict, dict]:\n    \"\"\"Read netCDF file.\n\n    The function follows the CF-1 convention and assumes data of the form:\n        2D: `(time, level)`\n        3D: `(time, lat, lon)`\n        4D: `(time, level, lat, lon)`\n\n    Parameters:\n        filename:\n            Name of the netCDF file.\n        level_range:\n            Start and stop indices of levels to be read (in slice notation). Defaults to `None`.\n        time_interval:\n            Start and stop time to be read (in datetime notation). Default is 'None'.\n        time_range:\n            Start and stop indices along time dimensions to be read (in slice notation). Default is 'None'.\n        num2date:\n            Convert time to Numpy datetime. Defaults to 'True' if 'time_interval' is given otherwise default is 'False'.\n        datetime_unit:\n            Unit of datetime if `num2date` is set to `True`. Defaults to `D`, meaning day. For a list of units see\n            https://numpy.org/doc/stable/reference/arrays.datetime.html#datetime-units.\n        scale:\n            Scale all variables by this factor. Defaults to 1.\n        dtype:\n            Data type of the variables that will be returned. Default is None, meaning dtype of netCDF file.\n\n    Returns:\n        tuple of three dicts containing the variables, dimensions, and attributes.\n    \"\"\"\n\n    variables = {}\n    dimensions = {}\n    attributes = {}\n\n    with netCDF4.Dataset(filename) as dataset:\n        # read global attributes\n        attributes['.'] = {attr: dataset.getncattr(attr) for attr in dataset.ncattrs()}\n\n        # read variables\n        for var_name, variable in dataset.variables.items():\n            if variable.ndim in (2, 3, 4):\n                # extract dimensions\n                var_dims = [dataset.variables.get(name) for name in variable.dimensions]\n\n                if None not in var_dims:\n                    # extract variable\n                    variables[var_name] = variable[:].filled(fill_value=np.nan)\n                    if dtype is not None:\n                        variables[var_name] = variables[var_name].astype(dtype)\n\n                    attributes[var_name] = {attr: variable.getncattr(attr) for attr in variable.ncattrs()}\n\n                    # scale variable\n                    variables[var_name] *= scale\n                    attributes[var_name]['scale'] = scale\n\n                    # follow CF-1 convention\n                    if variable.ndim == 2:\n                        dim_keys = ('time', 'level')\n                    elif variable.ndim == 3:\n                        dim_keys = ('time', 'lat', 'lon')\n                    elif variable.ndim == 4:\n                        dim_keys = ('time', 'level', 'lat', 'lon')\n\n                    for dim_name, var_dim in zip(dim_keys, var_dims):\n                        dimensions[dim_name] = var_dim[:].filled(fill_value=np.nan)\n                        attributes[dim_name] = {\n                            attr: var_dim.getncattr(attr)\n                            for attr in var_dim.ncattrs() if attr not in {'bounds'}\n                        }\n\n        # replace time with Numpy datetime\n        if num2date | (time_interval is not None):\n            datetime = netCDF4.num2date(dimensions['time'],\n                                        units=attributes['time']['units'],\n                                        calendar=attributes['time']['calendar'])\n            datetime = [np.datetime64(d.strftime('%Y-%m-%d %H:%M:%S')) for d in datetime]\n            datetime = np.array(datetime)\n            datetime = datetime.astype(f'datetime64[{datetime_unit}]')\n            dimensions['time'] = datetime\n\n        # restrict time interval\n        if time_interval is not None:\n            ti0, ti1 = time_interval\n            idx = (np.datetime64(ti0) &lt;= dimensions['time']) &amp; (dimensions['time'] &lt;= np.datetime64(ti1))\n            dimensions['time'] = dimensions['time'][idx]\n            variables = {key: val[idx, ...] for key, val in variables.items()}\n\n        # restrict time range\n        if time_range is not None:\n            idx = slice(*time_range)\n            dimensions['time'] = dimensions['time'][idx]\n            variables = {key: val[idx, ...] for key, val in variables.items()}\n\n        # restrict level range\n        if level_range is not None:\n            idx = slice(*level_range)\n            if 'level' in dimensions:\n                dimensions['level'] = dimensions['level'][idx]\n                variables = {key: val[:, idx, ...] for key, val in variables.items() if val.ndim in (2, 4)}\n\n    return variables, dimensions, attributes\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.write_netcdf","title":"VAE.utils.fileio.write_netcdf","text":"<pre><code>write_netcdf(filename, variables, dimensions, attributes, scale=None, dtype='f4', compression='zlib', verbose=True)\n</code></pre> <p>Write netCDF file.</p> The function follows the CF-1 convention and assumes data of the form <p>2D: <code>(time, level)</code> 3D: <code>(time, lat, lon)</code> 4D: <code>(time, level, lat, lon)</code></p> <p>The structure of the dictionaries <code>variables</code>, <code>dimensions</code>, and <code>attributes</code> follows that of :func:<code>read_netcdf</code>.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>Name of the netCDF file.</p> </li> <li> <code>variables</code>             (<code>dict[str, ndarray]</code>)         \u2013          <p>Dictionary of variables with the items defining the variable name and values.</p> </li> <li> <code>dimensions</code>             (<code>dict[str, ndarray]</code>)         \u2013          <p>Dictionary of dimensions with the items defining the dimension name and values. Dimension names must be either <code>time</code>, <code>level</code>, <code>lat</code>, or <code>lon</code>.</p> </li> <li> <code>attributes</code>             (<code>dict[str, dict]</code>)         \u2013          <p>Dictionary of attributes for the variables and the dimensions with the items defining the variable/dimension name and a dict of attributes. Global attributes will be taken from <code>attributes['.']</code>.</p> </li> <li> <code>scale</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Scale all variables. If scale is <code>None</code>, scale is obtained from <code>attributes[variable_name]['scale']</code>.</p> </li> <li> <code>dtype</code>             (<code>str</code>, default:                 <code>'f4'</code> )         \u2013          <p>Data type of the variables that will be written. Default is 'float'.</p> </li> <li> <code>compression</code>             (<code>str</code>, default:                 <code>'zlib'</code> )         \u2013          <p>Data will be compressed in the netCDF file using the specified compression algorithm.</p> </li> </ul> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def write_netcdf(filename: str,\n                 variables: dict[str, np.ndarray],\n                 dimensions: dict[str, np.ndarray],\n                 attributes: dict[str, dict],\n                 scale: float = None,\n                 dtype: str = 'f4',\n                 compression: str = 'zlib',\n                 verbose: bool = True):\n    \"\"\"Write netCDF file.\n\n    The function follows the CF-1 convention and assumes data of the form:\n        2D: `(time, level)`\n        3D: `(time, lat, lon)`\n        4D: `(time, level, lat, lon)`\n\n    The structure of the dictionaries `variables`, `dimensions`, and `attributes` follows that of :func:`read_netcdf`.\n\n    Parameters:\n        filename:\n            Name of the netCDF file.\n        variables:\n            Dictionary of variables with the items defining the variable name and values.\n        dimensions:\n            Dictionary of dimensions with the items defining the dimension name and values. Dimension names must be\n            either `time`, `level`, `lat`, or `lon`.\n        attributes:\n            Dictionary of attributes for the variables and the dimensions with the items defining the variable/dimension\n            name and a dict of attributes. Global attributes will be taken from `attributes['.']`.\n        scale:\n            Scale all variables. If scale is `None`, scale is obtained from `attributes[variable_name]['scale']`.\n        dtype:\n            Data type of the variables that will be written. Default is 'float'.\n        compression:\n            Data will be compressed in the netCDF file using the specified compression algorithm.\n\n    \"\"\"\n\n    valid_dims = {'time', 'level', 'lat', 'lon'}\n    if set(dimensions.keys()) &gt; valid_dims:\n        raise KeyError(f'Dimension keys must be subset of {valid_dims}')\n\n    with netCDF4.Dataset(filename, 'w', format='NETCDF4') as dataset:\n        if verbose:\n            print('Write:', os.path.normpath(filename))\n\n        # write dimensions\n        for name, value in dimensions.items():\n            dataset.createDimension(name, len(value))\n            variable = dataset.createVariable(name, dtype, (name, ))\n            atts = {k: v for k, v in attributes[name].items() if k not in {'bounds'}}\n            variable.setncatts(atts)\n\n            if name == 'time':\n                value = netCDF4.date2num([pd.to_datetime(v) for v in value],\n                                         units=attributes['time']['units'],\n                                         calendar=attributes['time']['calendar'])\n\n            variable[:] = value\n\n        # write variables\n        for name, value in variables.items():\n            atts = attributes[name].copy()\n            if scale is None:\n                scale = 1 / atts.pop('scale', 1.)\n\n            value *= scale\n\n            # follow CF-1 convention\n            if value.ndim == 2:\n                dims = ('time', 'level')\n            elif value.ndim == 3:\n                dims = ('time', 'lat', 'lon')\n            elif value.ndim == 4:\n                dims = ('time', 'level', 'lat', 'lon')\n\n            variable = dataset.createVariable(name,\n                                              dtype,\n                                              dimensions=dims,\n                                              compression=compression,\n                                              fill_value=atts.pop('_FillValue', None))\n            variable.setncatts(atts)\n            variable[:] = value\n\n        # write global attributes\n        dataset.setncatts(attributes.get('.', {}))\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.read_netcdf_multi","title":"VAE.utils.fileio.read_netcdf_multi","text":"<pre><code>read_netcdf_multi(filename, level_range=None, time_interval=None, time_range=None, scale=1.0, recursive=False, num2date=False, datetime_unit='D', dtype=None, verbose=True)\n</code></pre> <p>Read multiple files of netCDF data.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>list[str]</code>)         \u2013          <p>Name of file(s). Glob patterns can be used.</p> </li> <li> <code>level_range</code>             (<code>tuple[int, int]</code>, default:                 <code>None</code> )         \u2013          <p>Start and stop indices of levels to be read (in slice notation). If a list of tuples, length of list must match the length of <code>filename</code>. Defaults to <code>None</code>.</p> </li> <li> <code>time_interval</code>             (<code>tuple[str, str]</code>, default:                 <code>None</code> )         \u2013          <p>Time intervaL to be read. If a list of tuples, length of list must match the length of <code>filename</code>. Defaults to <code>None</code>.</p> </li> <li> <code>time_range</code>             (<code>tuple[int, int]</code>, default:                 <code>None</code> )         \u2013          <p>Start and stop indices along time dimensions to be read (in slice notation). If a list of tuples, length of list must match the length of <code>filename</code>. Defaults to <code>None</code>.</p> </li> <li> <code>recursive</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If recursive is true, the pattern '**' will match any files and zero or more directories and subdirectories.</p> </li> <li> <code>num2date</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Convert time to Numpy datetime. Defaults to 'True' if 'time_interval' is given otherwise default is 'False'.</p> </li> <li> <code>datetime_unit</code>             (<code>str</code>, default:                 <code>'D'</code> )         \u2013          <p>Unit of datetime if <code>num2date</code> is set to <code>True</code>. Defaults to <code>D</code>, meaning day. For a list of units see https://numpy.org/doc/stable/reference/arrays.datetime.html#datetime-units.</p> </li> <li> <code>dtype</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Data type of the variables that will be returned. Default is None, meaning dtype of netCDF file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[dict, dict, dict]</code>         \u2013          <p>tuple of three dicts containing the variables, dimensions, and attributes of each file.</p> </li> </ul> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def read_netcdf_multi(filename: list[str],\n                      level_range: tuple[int, int] = None,\n                      time_interval: tuple[str, str] = None,\n                      time_range: tuple[int, int] = None,\n                      scale: float = 1.,\n                      recursive: bool = False,\n                      num2date: bool = False,\n                      datetime_unit: str = 'D',\n                      dtype: str = None,\n                      verbose: bool = True) -&gt; tuple[dict, dict, dict]:\n    \"\"\"Read multiple files of netCDF data.\n\n    Parameters:\n        filename:\n            Name of file(s). Glob patterns can be used.\n        level_range:\n            Start and stop indices of levels to be read (in slice notation). If a list of tuples, length of list must\n            match the length of `filename`. Defaults to `None`.\n        time_interval:\n            Time intervaL to be read. If a list of tuples, length of list must match the length of `filename`. Defaults\n            to `None`.\n        time_range:\n            Start and stop indices along time dimensions to be read (in slice notation). If a list of tuples, length of\n            list must match the length of `filename`. Defaults to `None`.\n        recursive:\n            If recursive is true, the pattern '**' will match any files and zero or more directories and subdirectories.\n        num2date:\n            Convert time to Numpy datetime. Defaults to 'True' if 'time_interval' is given otherwise default is 'False'.\n        datetime_unit:\n            Unit of datetime if `num2date` is set to `True`. Defaults to `D`, meaning day. For a list of units see\n            https://numpy.org/doc/stable/reference/arrays.datetime.html#datetime-units.\n        dtype:\n            Data type of the variables that will be returned. Default is None, meaning dtype of netCDF file.\n\n    Returns:\n        tuple of three dicts containing the variables, dimensions, and attributes of each file.\n\n    \"\"\"\n\n    if isinstance(filename, str):\n        filename = [filename]\n\n    filename = [os.path.normpath(fn) for fn in filename]\n    time_interval = _check_arg(filename, time_interval)\n    time_range = _check_arg(filename, time_range)\n    level_range = _check_arg(filename, level_range)\n    scale = np.broadcast_to(scale, len(filename)).tolist()\n\n    filenames = []\n    time_intervals = []\n    time_ranges = []\n    level_ranges = []\n    scales = []\n    ml = max(len(fn) for fn in filename)\n    for fn, ti, tr, lr, sc in zip(filename, time_interval, time_range, level_range, scale):\n        new_filenames = sorted(glob.glob(fn, recursive=recursive))\n        if new_filenames:\n            filenames += new_filenames\n            time_intervals += [ti] * len(new_filenames)\n            time_ranges += [tr] * len(new_filenames)\n            level_ranges += [lr] * len(new_filenames)\n            scales += [sc] * len(new_filenames)\n\n            if verbose:\n                print(f'{fn:{ml}.{ml}} : {len(new_filenames)} file(s) found.')\n        else:\n            raise FileNotFoundError(f'No files found for: {fn}')\n\n    if not filenames:\n        raise FileNotFoundError('No files found.')\n\n    variables = {}\n    dimensions = {}\n    attributes = {}\n    # commonpath = os.path.commonpath(filenames)\n\n    pbar = Progbar(len(filenames), verbose=verbose, unit_name='file')\n    for fn, ti, tr, lr, sc in zip(filenames, time_intervals, time_ranges, level_ranges, scales):\n        try:\n            variable, dimension, attribute = read_netcdf(fn,\n                                                         level_range=lr,\n                                                         time_interval=ti,\n                                                         time_range=tr,\n                                                         scale=sc,\n                                                         num2date=num2date,\n                                                         datetime_unit=datetime_unit,\n                                                         dtype=dtype)\n        except Exception as error:\n            print('Error reading', os.path.normpath(fn), ':', error)\n            raise\n\n        # key = os.path.relpath(fn, commonpath)\n        # key, _ = os.path.splitext(key)\n        key = os.path.normpath(fn)\n        variables[key] = variable\n        dimensions[key] = dimension\n        attributes[key] = attribute\n        pbar.add(1)\n\n    return variables, dimensions, attributes\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.read_climexp_raw_data","title":"VAE.utils.fileio.read_climexp_raw_data","text":"<pre><code>read_climexp_raw_data(filename, ensemble_members=None, time_interval=None, dtype='float')\n</code></pre> <p>Read single file of raw data from climexp.</p> <p>Read a single file of raw data downloaded from https://climexp.knmi.nl.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>File name.</p> </li> <li> <code>ensemble_members</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Ensemble members that will be returned. Defaults to <code>None</code>, meaning all members are returned.</p> </li> <li> <code>time_interval</code>             (<code>tuple[str, str]</code>, default:                 <code>None</code> )         \u2013          <p>Time interval to be read.</p> </li> <li> <code>dtype</code>             (<code>str</code>, default:                 <code>'float'</code> )         \u2013          <p>Data type of the returned DataFrame. Default is 'float'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[DataFrame, dict]</code>         \u2013          <p>tuple of DataFrame and dict, where the dataframe contains the data and the dict contains the metadata.</p> </li> </ul> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def read_climexp_raw_data(filename: str,\n                          ensemble_members: list[int] = None,\n                          time_interval: tuple[str, str] = None,\n                          dtype: str = 'float') -&gt; tuple[pd.DataFrame, dict]:\n    \"\"\"Read single file of raw data from climexp.\n\n    Read a single file of raw data downloaded from https://climexp.knmi.nl.\n\n    Parameters:\n        filename:\n            File name.\n        ensemble_members:\n            Ensemble members that will be returned. Defaults to `None`, meaning all members are returned.\n        time_interval:\n            Time interval to be read.\n        dtype:\n            Data type of the returned DataFrame. Default is 'float'.\n\n    Returns:\n        tuple of DataFrame and dict, where the dataframe contains the data and the dict contains the metadata.\n    \"\"\"\n    # split file into datasets\n    with open(filename) as file:\n        datasets = file.read().split('# ensemble member')\n\n    # split datasets into list of lines\n    datasets = [dataset.splitlines() for dataset in datasets]\n\n    if len(datasets) == 1:\n        # single dataset\n        comments = [line for line in datasets[0] if line.startswith('#')]\n        data = [line for line in datasets[0] if not line.startswith('#')]\n        datasets = [comments, ['0'] + data]\n\n    # remove whitespace and comment symbol from each line\n    datasets = [[line.strip('# ') for line in dataset] for dataset in datasets]\n\n    # remove empty lines, inplace\n    datasets[:] = [[line for line in dataset if line] for dataset in datasets]\n\n    # extract metadata\n    metadata = datasets.pop(0)\n\n    # convert header into dict\n    metadata = [line.partition('::') for line in metadata]\n    variable_name = metadata.pop()[0]\n    metadata = {key.strip(): val.strip() for key, sep, val in metadata if sep}\n    metadata['variable'] = variable_name\n\n    # first line contains ensemble number\n    datasets_dict = {dataset[0]: [line.split() for line in dataset[1:]] for dataset in datasets if len(dataset) &gt; 1}\n\n    # filter ensemble members\n    if ensemble_members is not None:\n        ensemble_members = set(ensemble_members)\n        datasets_dict = {key: val for key, val in datasets_dict.items() if int(key) in ensemble_members}\n\n    # convert list of datasets into list of dataframes\n    dataframes = []\n    for key, dataset in datasets_dict.items():\n        dataframe = pd.DataFrame(dataset, columns=['time', key], dtype=dtype)\n        dataframe.set_index('time', inplace=True)\n        dataframes.append(dataframe)\n\n    # concatenate dataframes in one dataframe\n    df = pd.concat(dataframes, axis=1)\n\n    # convert time into datetime\n    year = df.index.astype(np.int32)\n    month = np.rint((df.index % 1) * 12 + 1).astype(np.int32)\n    date = pd.to_datetime({'year': year, 'month': month, 'day': 1}, unit='D')\n    df.set_index(date, inplace=True)\n\n    if time_interval is not None:\n        df = df.loc[time_interval[0]:time_interval[1]]\n\n    return df, metadata\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.read_climexp_raw_data_multi","title":"VAE.utils.fileio.read_climexp_raw_data_multi","text":"<pre><code>read_climexp_raw_data_multi(filename, ensemble_members=None, time_interval=None, recursive=False, join='inner', dtype='float')\n</code></pre> <p>Read multiple files of raw data from climexp.</p> <p>Read multiples files of raw data downloaded from https://climexp.knmi.nl.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>list[str]</code>)         \u2013          <p>Name of file(s). Glob patterns can be used.</p> </li> <li> <code>ensemble_members</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Ensemble members that will be returned. Defaults to <code>None</code>, meaning all members are returned.</p> </li> <li> <code>time_interval</code>             (<code>tuple[str, str]</code>, default:                 <code>None</code> )         \u2013          <p>Time interval to be read. If a list, it must match the length of <code>filename</code>.</p> </li> <li> <code>recursive</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If recursive is true, the pattern '**' will match any files and zero or more directories and subdirectories.</p> </li> <li> <code>join</code>             (<code>str</code>, default:                 <code>'inner'</code> )         \u2013          <p>How to join the different files. 'inner' means that only the common rows will be kept. 'outer' means that all rows will be kept and missing values will be filled with NaN. Default is 'inner'.</p> </li> <li> <code>dtype</code>             (<code>str</code>, default:                 <code>'float'</code> )         \u2013          <p>Data type of the returned DataFrame. Default is 'float'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>tuple of DataFrame and dict of dict. The dataframe contains the data and the dict contains the metadata. In the</p> </li> <li> <code>dict[str, dict]</code>         \u2013          <p>DataFrame, the filename is used as level-zero index in a multi-index. In the dict, the filename is used as key.</p> </li> </ul> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def read_climexp_raw_data_multi(filename: list[str],\n                                ensemble_members: list[int] = None,\n                                time_interval: tuple[str, str] = None,\n                                recursive: bool = False,\n                                join: str = 'inner',\n                                dtype: str = 'float') -&gt; tuple[pd.DataFrame, dict[str, dict]]:\n    \"\"\"Read multiple files of raw data from climexp.\n\n    Read multiples files of raw data downloaded from https://climexp.knmi.nl.\n\n    Parameters:\n        filename:\n            Name of file(s). Glob patterns can be used.\n        ensemble_members:\n            Ensemble members that will be returned. Defaults to `None`, meaning all members are returned.\n        time_interval:\n            Time interval to be read. If a list, it must match the length of `filename`.\n        recursive:\n            If recursive is true, the pattern '**' will match any files and zero or more directories and subdirectories.\n        join:\n            How to join the different files. 'inner' means that only the common rows will be kept. 'outer' means that\n            all rows will be kept and missing values will be filled with NaN. Default is 'inner'.\n        dtype:\n            Data type of the returned DataFrame. Default is 'float'.\n\n    Returns:\n        tuple of DataFrame and dict of dict. The dataframe contains the data and the dict contains the metadata. In the\n        DataFrame, the filename is used as level-zero index in a multi-index. In the dict, the filename is used as key.\n    \"\"\"\n    if isinstance(filename, str):\n        filename = [filename]\n\n    time_interval = _check_arg(filename, time_interval)\n\n    filenames = []\n    time_ranges = []\n    for file, tr in zip(filename, time_interval):\n        new_filenames = sorted(glob.glob(file, recursive=recursive))\n        if new_filenames:\n            filenames += new_filenames\n            time_ranges += [tr] * len(new_filenames)\n        else:\n            warnings.warn(f'No files found for pattern: {os.path.normpath(file)}')\n\n    if not filenames:\n        raise ValueError('No files found.')\n\n    commonpath = os.path.commonpath(filenames)\n    df = {}\n    metadata = {}\n    for name, tr in zip(filenames, time_ranges):\n        try:\n            new_df, new_metadata = read_climexp_raw_data(name,\n                                                         ensemble_members=ensemble_members,\n                                                         time_interval=tr,\n                                                         dtype=dtype)\n        except ValueError:\n            raise ValueError('Error reading file {}.'.format(name))\n\n        key = os.path.relpath(name, commonpath)\n        key, _ = os.path.splitext(key)\n        df[key] = new_df\n        metadata[key] = new_metadata\n\n    df = pd.concat(df, axis=1, join=join)\n\n    return df, metadata\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.example_read_climexp_raw_data_multi","title":"VAE.utils.fileio.example_read_climexp_raw_data_multi","text":"<pre><code>example_read_climexp_raw_data_multi()\n</code></pre> <p>Example of how to use the function <code>read_climexp_raw_data_multi</code>.</p> <p>The function reads multiple files of raw data from the <code>example_data/</code> folder.</p> <pre><code>example_data/icmip5_tos_Omon_one_rcp45_pc01.txt\nexample_data/icmip5_tos_Omon_one_rcp45_pc02.txt\n</code></pre> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example_read_climexp_raw_data_multi():\n    \"\"\"Example of how to use the function `read_climexp_raw_data_multi`.\n\n    The function reads multiple files of raw data from the `example_data/` folder.\n\n    ```\n    example_data/icmip5_tos_Omon_one_rcp45_pc01.txt\n    example_data/icmip5_tos_Omon_one_rcp45_pc02.txt\n    ```\n\n    \"\"\"\n\n    filename = [\n        'example_data/icmip5_tos_Omon_one_rcp45_pc01.txt',\n        'example_data/icmip5_tos_Omon_one_rcp45_pc02.txt',\n    ]\n\n    # read data\n    df, metadata = read_climexp_raw_data_multi(filename, ensemble_members=[0, 1, 2, 3, 4, 5], join='outer')\n\n    with pd.option_context('display.precision', 3):\n        print(df)\n\n    _, ax = plt.subplots(1, 1, figsize=(10, 5))\n    time = df.index.to_numpy()\n\n    # access data by level-zero index\n    for idx in df.columns.levels[0]:\n        x = df[idx]\n        x = x.to_numpy()\n        x_mean = x.mean(axis=1)\n        x_std = x.std(axis=1) * 3\n\n        ax.plot(time, x_mean, label=metadata[idx].get('description'), zorder=2.2)\n        ax.fill_between(time, x_mean - x_std, x_mean + x_std, alpha=0.5, zorder=2.1)\n\n    ax.legend(loc='upper left')\n    ax.grid(linestyle=':')\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.example1_read_netcdf","title":"VAE.utils.fileio.example1_read_netcdf","text":"<pre><code>example1_read_netcdf()\n</code></pre> <p>Example of how to use the function <code>read_netcdf</code>.</p> <p>This function reads EOFs in a netCDF file from the Climate explorer from the <code>example_data/</code> folder:</p> <pre><code>example_data/eofs_icmip5_tos_Omon_one_rcp45.nc\n</code></pre> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example1_read_netcdf():\n    \"\"\"Example of how to use the function `read_netcdf`.\n\n    This function reads EOFs in a netCDF file from the Climate explorer from the `example_data/` folder:\n\n    ```\n    example_data/eofs_icmip5_tos_Omon_one_rcp45.nc\n    ```\n\n    \"\"\"\n\n    filename = 'example_data/eofs_icmip5_tos_Omon_one_rcp45.nc'\n\n    # read data\n    variables, dimensions, attributes = read_netcdf(filename)\n\n    print('variables')\n    for key, value in variables.items():\n        print('  ', key, value.shape)\n\n    print('dimensions')\n    for key, value in dimensions.items():\n        print('  ', key, value.shape)\n\n    print('attributes')\n    pprint(attributes)\n\n    # remove singleton dimensions\n    squeeze_variables = {key: np.squeeze(value) for key, value in variables.items()}\n    # plot variables\n    vplt.map_plot(dimensions['lat'], dimensions['lon'], squeeze_variables, ncols=5, figwidth=20, cmap='seismic')\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.example2_read_netcdf","title":"VAE.utils.fileio.example2_read_netcdf","text":"<pre><code>example2_read_netcdf()\n</code></pre> <p>Example of how to use the function <code>read_netcdf</code>.</p> <p>This function reads EOFs in a netCDF file from the output of the climate data operators (CDO). The file is from the <code>example_data/</code> folder:</p> <pre><code>example_data/eofs_anom_gpcc_v2020_1dgr.nc\n</code></pre> <p>:material-github: For the calculation of the EOFs and PCs with CDO see the CDO     scripts.</p> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example2_read_netcdf():\n    \"\"\"Example of how to use the function `read_netcdf`.\n\n    This function reads EOFs in a netCDF file from the output of the climate data operators (CDO). The file is from the\n    `example_data/` folder:\n\n    ```\n    example_data/eofs_anom_gpcc_v2020_1dgr.nc\n    ```\n\n    :material-github: For the calculation of the EOFs and PCs with CDO see the [CDO\n        scripts](https://github.com/andr-groth/cdo-scripts).\n\n    \"\"\"\n\n    filename = 'example_data/eofs_anom_gpcc_v2020_1dgr.nc'\n\n    # read data\n    variables, dimensions, attributes = read_netcdf(filename)\n\n    print('variables')\n    for key, value in variables.items():\n        print('  ', key, value.shape)\n\n    print('dimensions')\n    for key, value in dimensions.items():\n        print('  ', key, value.shape)\n\n    print('attributes')\n    pprint(attributes)\n\n    # plot first variable\n    key, *_ = list(variables)\n    variable = variables[key]\n    vplt.map_plot(dimensions['lat'], dimensions['lon'], variable, ncols=10, figwidth=20, cmap='seismic')\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.example3_read_netcdf","title":"VAE.utils.fileio.example3_read_netcdf","text":"<pre><code>example3_read_netcdf()\n</code></pre> <p>Example of how to use the function <code>read_netcdf</code>.</p> <p>This function reads PCs in a netCDF file from the output of the climate data operators (CDO). The file is from the <code>example_data/</code> folder:</p> <pre><code>example_data/pcs_anom_gpcc_v2020_1dgr.nc\n</code></pre> <p>:material-github: For the calculation of the EOFs and PCs with CDO see the CDO     scripts.</p> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example3_read_netcdf():\n    \"\"\"Example of how to use the function `read_netcdf`.\n\n    This function reads PCs in a netCDF file from the output of the climate data operators (CDO). The file is from the\n    `example_data/` folder:\n\n    ```\n    example_data/pcs_anom_gpcc_v2020_1dgr.nc\n    ```\n\n    :material-github: For the calculation of the EOFs and PCs with CDO see the [CDO\n        scripts](https://github.com/andr-groth/cdo-scripts).\n\n    \"\"\"\n\n    filename = 'example_data/pcs_anom_gpcc_v2020_1dgr.nc'\n\n    # read data\n    variables, dimensions, attributes = read_netcdf(filename, num2date=True)\n\n    print('variables')\n    for key, value in variables.items():\n        print('  ', key, value.shape)\n\n    print('dimensions')\n    for key, value in dimensions.items():\n        print('  ', key, value.shape)\n\n    print('attribtutes')\n    pprint(attributes)\n\n    # plot first variable\n    key, *_ = list(variables)\n    variable = np.squeeze(variables[key])  # remove singleton spatial dimensions\n    variable = variable.T\n    variable = np.atleast_2d(variable)\n    cols = min(len(variable), 5)\n    rows = -(-len(variable) // cols)\n    _, axs = plt.subplots(rows, cols, figsize=(4 * cols, 2 * rows), sharex=True, sharey=True, squeeze=False)\n    for n, (ax, value) in enumerate(zip(axs.flatten(), variable)):\n        ax.plot(dimensions['time'], value)\n        ax.set_title(n)\n</code></pre>"},{"location":"VAE.utils.fileio/#VAE.utils.fileio.example_read_netcdf_multi","title":"VAE.utils.fileio.example_read_netcdf_multi","text":"<pre><code>example_read_netcdf_multi(filename)\n</code></pre> <p>Example of how to use the function <code>read_netcdf_multi</code>.</p> <p>This function reads PCs in multiple netCDF files from the output of the climate data operators (CDO). The files are from the <code>example_data/</code> folder:</p> <pre><code>example_data/pcs_anom_pr_*.nc\n</code></pre> <p>:material-github: For the calculation of the EOFs and PCs with CDO see the CDO     scripts.</p> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example_read_netcdf_multi(filename: str):\n    \"\"\"Example of how to use the function `read_netcdf_multi`.\n\n    This function reads PCs in multiple netCDF files from the output of the climate data operators (CDO). The files are\n    from the `example_data/` folder:\n\n    ```\n    example_data/pcs_anom_pr_*.nc\n    ```\n\n    :material-github: For the calculation of the EOFs and PCs with CDO see the [CDO\n        scripts](https://github.com/andr-groth/cdo-scripts).\n\n    \"\"\"\n\n    filename = 'example_data/pcs_anom_pr_*.nc'\n\n    # read data\n    variables, dimensions, attributes = read_netcdf_multi(filename, num2date=True)\n\n    print('variables')\n    for key, value in variables.items():\n        print('  ', key)\n        for k, v in value.items():\n            print('    ', k, v.shape)\n\n    print('dimensions')\n    for key, value in dimensions.items():\n        print('  ', key)\n        for k, v in value.items():\n            print('    ', k, v.shape)\n\n    rows = 5\n    cols = 2\n    _, axs = plt.subplots(rows, cols, figsize=(8 * cols, 3 * rows), sharex=True, sharey=True, squeeze=False)\n    # cycle through different files\n    for key, variable in variables.items():\n        var_name, *_ = list(variable)  # extract first variable\n        values = np.squeeze(variable[var_name])  # remove singleton spatial dimensions\n        values = values.T\n        values = np.atleast_2d(values)\n        for n, (ax, value) in enumerate(zip(axs.flatten(), values)):\n            ax.plot(dimensions[key]['time'], value, label=key)\n            ax.set_title(n)\n\n    axs.flat[0].legend()\n</code></pre>"},{"location":"VAE.utils.learning_rate/","title":"VAE.utils.learning rate","text":""},{"location":"VAE.utils.learning_rate/#VAE.utils.learning_rate","title":"VAE.utils.learning_rate","text":"<p>Learning rate utilities.</p>"},{"location":"VAE.utils.learning_rate/#VAE.utils.learning_rate.LearningRateFinder","title":"VAE.utils.learning_rate.LearningRateFinder","text":"<pre><code>LearningRateFinder(model, beta=0.98, stop_factor=4, filename=None, update_freq=10)\n</code></pre> <p>Learning rate finder.</p> See also <p>https://github.com/surmenok/keras_lr_finder</p> Source code in <code>VAE/utils/learning_rate.py</code> <pre><code>def __init__(self, model, beta=0.98, stop_factor=4, filename=None, update_freq=10):\n\n    self.model = model\n    self.best_loss = 1e9\n    self.beta = beta\n    self.stop_factor = stop_factor\n    self.ave_loss = None\n    self.filename = filename\n    self.update_freq = update_freq\n    self.log = []\n</code></pre>"},{"location":"VAE.utils.learning_rate/#VAE.utils.learning_rate.LearningRateFinder.on_batch_end","title":"VAE.utils.learning_rate.LearningRateFinder.on_batch_end","text":"<pre><code>on_batch_end(batch, logs)\n</code></pre> <p>Get loss and increase learning rate</p> Source code in <code>VAE/utils/learning_rate.py</code> <pre><code>def on_batch_end(self, batch, logs):\n    \"\"\"Get loss and increase learning rate\"\"\"\n\n    # Get the learning rate and loss\n    lr = ks.backend.get_value(self.model.optimizer.lr)\n    loss = logs['loss']\n\n    # Exponentially smoothed loss\n    if self.ave_loss is None:\n        self.ave_loss = loss\n    else:\n        self.ave_loss = (self.beta * self.ave_loss) + ((1 - self.beta) * loss)\n\n    self.log.append('{:5d} {:10.8f} {:10.8f} {:10.8f}\\n'.format(batch, lr, loss, self.ave_loss))\n\n    # Save log to file\n    if (self.filename is not None) and (batch % self.update_freq == 0):\n        file = open(self.filename, 'a')\n        file.writelines(self.log)\n        file.close()\n        self.log = []\n\n    # Check whether the loss gets large again\n    decaytime = 1 / (1 - self.beta)\n    if (batch &gt; decaytime) and (self.ave_loss &gt; self.best_loss * self.stop_factor):\n        self.model.stop_training = True\n        return\n\n    if (batch &gt; decaytime) and (self.ave_loss &lt; self.best_loss):\n        self.best_loss = self.ave_loss\n\n    # Increase the learning rate for the next batch\n    lr *= self.lr_mult\n    ks.backend.set_value(self.model.optimizer.lr, lr)\n</code></pre>"},{"location":"VAE.utils.learning_rate/#VAE.utils.learning_rate.LearningRateFinder.on_train_end","title":"VAE.utils.learning_rate.LearningRateFinder.on_train_end","text":"<pre><code>on_train_end(logs)\n</code></pre> <p>Final save log file</p> Source code in <code>VAE/utils/learning_rate.py</code> <pre><code>def on_train_end(self, logs):\n    \"\"\"Final save log file\"\"\"\n    if (self.filename is not None):\n        file = open(self.filename, 'a')\n        file.writelines(self.log)\n        file.close()\n</code></pre>"},{"location":"VAE.utils.learning_rate/#VAE.utils.learning_rate.LearningRateFinder.find_generator","title":"VAE.utils.learning_rate.LearningRateFinder.find_generator","text":"<pre><code>find_generator(generator, start_lr=0.0001, end_lr=1.0, callbacks=[], **kw_fit)\n</code></pre> <p>Start model training with increasing learning rate.</p> Source code in <code>VAE/utils/learning_rate.py</code> <pre><code>def find_generator(self, generator, start_lr=1e-4, end_lr=1., callbacks=[], **kw_fit):\n    \"\"\"Start model training with increasing learning rate.\"\"\"\n\n    epochs = kw_fit['epochs']\n    num_batches = epochs * len(generator)\n    self.lr_mult = (end_lr / start_lr)**(1 / num_batches)\n\n    # Set the initial learning rate\n    ks.backend.set_value(self.model.optimizer.lr, start_lr)\n\n    callback = ks.callbacks.LambdaCallback(on_batch_end=lambda batch, logs: self.on_batch_end(batch, logs),\n                                           on_train_end=lambda logs: self.on_train_end(logs))\n\n    # merge callbacks\n    callbacks = callbacks + [callback]\n\n    self.model.fit_generator(generator=generator, callbacks=callbacks, **kw_fit)\n</code></pre>"},{"location":"VAE.utils.learning_rate/#VAE.utils.learning_rate.StepDecay","title":"VAE.utils.learning_rate.StepDecay","text":"<pre><code>StepDecay(lr, decay_rate, steps)\n</code></pre> <p>Learning rate scheduler with exponential decay.</p> <p>Learning rate scheduler for use in :class:<code>keras.callbacks.LearningRateScheduler</code>.</p> <p>Parameters::     lr:         Float, specifying the initial learning rate.     decay_rate:         Float, specifying the decay rate.     steps:         Integer, specifying the number of epochs at which the learning rate is reduced by         <code>decay_rate</code>.</p> <p>Returns:</p> <ul> <li> <code>Float</code>        \u2013          <p>Learning rate at given epoch.</p> </li> </ul> Source code in <code>VAE/utils/learning_rate.py</code> <pre><code>def __init__(self, lr, decay_rate, steps):\n\n    self.lr = lr\n    self.decay_rate = decay_rate\n    self.steps = steps\n</code></pre>"},{"location":"VAE.utils.learning_rate/#VAE.utils.learning_rate.ExponentialDecay","title":"VAE.utils.learning_rate.ExponentialDecay","text":"<pre><code>ExponentialDecay(initial_learning_rate, decay_steps, decay_rate, warmup_steps=0, staircase=False)\n</code></pre> <p>A learning rate scheduler that uses an exponential decay schedule.</p> <p>Parameters:</p> <ul> <li> <code>initial_learning_rate</code>         \u2013          <p>float Initial learning rate.</p> </li> <li> <code>decay_steps</code>         \u2013          <p>int Number of steps after which the learning rate decays by the decay rate specified in <code>decay_rate</code>.</p> </li> <li> <code>decay_rate</code>         \u2013          <p>float Decay rate at which the learning rate decays.</p> </li> <li> <code>warmup_steps</code>         \u2013          <p>int Number of steps for warmup in which the learning rate increases.</p> </li> <li> <code>staircase</code>         \u2013          <p>bool If <code>True</code>, the learning rate decays at discrete intervals.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>float</p> </li> </ul> Source code in <code>VAE/utils/learning_rate.py</code> <pre><code>def __init__(self, initial_learning_rate, decay_steps, decay_rate, warmup_steps=0, staircase=False):\n    self.initial_learning_rate = initial_learning_rate\n    self.decay_steps = decay_steps\n    self.decay_rate = decay_rate\n    self.warmup_steps = warmup_steps\n    self.staircase = staircase\n</code></pre>"},{"location":"VAE.utils.math/","title":"Mathematical functions","text":""},{"location":"VAE.utils.math/#VAE.utils.math","title":"VAE.utils.math","text":"<p>Collection of mathematical functions used in the VAE.</p>"},{"location":"VAE.utils.math/#VAE.utils.math.log_density_gaussian","title":"VAE.utils.math.log_density_gaussian","text":"<pre><code>log_density_gaussian(sample, mean, logvar, all_combinations=False, axis=0)\n</code></pre> <p>Calculates the sampled log density of a Gaussian.</p> <p>Version for Tensor arrays as inputs.</p> <p>Parameters:</p> <ul> <li> <code>sample</code>             (<code>Tensor</code>)         \u2013          <p>Sample at which to compute the density.</p> </li> <li> <code>mean</code>             (<code>Tensor</code>)         \u2013          <p>Mean of Gaussian distribution.</p> </li> <li> <code>logvar</code>             (<code>Tensor</code>)         \u2013          <p>Log variance of Gaussian distribution.</p> </li> <li> <code>all_combinations</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to return values for all combinations of batch pairs of <code>sample</code> and <code>mean</code>.</p> </li> <li> <code>axis</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>The dimension over which all combinations are computed. Default is 0 meaning the batch dimension.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor</p> </li> </ul> Source code in <code>VAE/utils/math.py</code> <pre><code>def log_density_gaussian(sample: tf.Tensor,\n                         mean: tf.Tensor,\n                         logvar: tf.Tensor,\n                         all_combinations: bool = False,\n                         axis: int = 0) -&gt; tf.Tensor:\n    \"\"\"Calculates the sampled log density of a Gaussian.\n\n    Version for Tensor arrays as inputs.\n\n    Parameters:\n        sample:\n            Sample at which to compute the density.\n        mean:\n            Mean of Gaussian distribution.\n        logvar:\n            Log variance of Gaussian distribution.\n        all_combinations:\n            Whether to return values for all combinations of batch pairs of `sample` and `mean`.\n        axis:\n            The dimension over which all combinations are computed. Default is 0 meaning the batch dimension.\n\n    Returns:\n        Tensor\n\n    \"\"\"\n    if all_combinations:\n        sample = tf.expand_dims(sample, axis=axis + 1)\n        mean = tf.expand_dims(mean, axis=axis)\n        logvar = tf.expand_dims(logvar, axis=axis)\n\n    log_density = LOG2PI + logvar + tf.exp(-logvar) * (sample - mean)**2\n    log_density *= -0.5\n    return log_density\n</code></pre>"},{"location":"VAE.utils.math/#VAE.utils.math.reduce_logmeanexp","title":"VAE.utils.math.reduce_logmeanexp","text":"<pre><code>reduce_logmeanexp(input_tensor, axis=None, keepdims=False)\n</code></pre> <p>Calculates Log(Mean(Exp(x))).</p> <p>Version for Tensor arrays as inputs.</p> <p>Parameters:</p> <ul> <li> <code>input_tensor</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor.</p> </li> <li> <code>axis</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>The dimensions to reduce.</p> </li> <li> <code>keepdims</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to keep the axis as singleton dimensions.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor.</p> </li> </ul> Source code in <code>VAE/utils/math.py</code> <pre><code>def reduce_logmeanexp(input_tensor: tf.Tensor, axis: int = None, keepdims: bool = False) -&gt; tf.Tensor:\n    \"\"\"Calculates Log(Mean(Exp(x))).\n\n    Version for Tensor arrays as inputs.\n\n    Parameters:\n        input_tensor:\n            Input tensor.\n        axis:\n            The dimensions to reduce.\n        keepdims:\n            Whether to keep the axis as singleton dimensions.\n\n    Returns:\n        Tensor.\n\n    \"\"\"\n    lse = tf.reduce_logsumexp(input_tensor, axis=axis, keepdims=keepdims)\n    n = tf.size(input_tensor) // tf.size(lse)\n    log_n = tf.math.log(tf.cast(n, lse.dtype))\n    return lse - log_n\n</code></pre>"},{"location":"VAE.utils.math/#VAE.utils.math.similarity","title":"VAE.utils.math.similarity","text":"<pre><code>similarity(input_tensor, temperature=1.0)\n</code></pre> <p>Returns the cosine similarity.</p> <p>The function returns a similarity measure between all samples in a batch. First, a correlation matrix of the normalized input is obtained (the cosine similarity matrix). Then, the similarity measure is defined as the categorical cross entropy of the cosine similarity matrix of shape <code>(batch_size, batch_size)</code> with the identity matrix as target. The correlation can be scaled by <code>temperature</code> prior to the calculation of the cross entropy.</p> <p>Parameters:</p> <ul> <li> <code>input_tensor</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor of shape <code>(batch_size, channels)</code>.</p> </li> <li> <code>temperature</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>Temperature for the softmax.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>Tensor of shape <code>(batch_size,)</code>.</p> </li> </ul> Source code in <code>VAE/utils/math.py</code> <pre><code>def similarity(input_tensor: tf.Tensor, temperature: float = 1.) -&gt; tf.Tensor:\n    \"\"\"Returns the cosine similarity.\n\n    The function returns a similarity measure between all samples in a batch. First, a correlation matrix of the\n    normalized input is obtained (the cosine similarity matrix). Then, the similarity measure is defined as the\n    categorical cross entropy of the cosine similarity matrix of shape `(batch_size, batch_size)` with the identity\n    matrix as target. The correlation can be scaled by `temperature` prior to the calculation of the cross entropy.\n\n    Parameters:\n        input_tensor:\n            Input tensor of shape `(batch_size, channels)`.\n        temperature:\n            Temperature for the softmax.\n\n    Returns:\n        Tensor of shape `(batch_size,)`.\n\n    \"\"\"\n    # normalize input\n    l2 = tf.math.l2_normalize(input_tensor, axis=-1)\n    # correlation matrix\n    similarity = tf.matmul(l2, l2, transpose_b=True)\n    # apply temperature\n    similarity /= temperature\n    # target labels = diagonal elements\n    labels = tf.range(tf.shape(similarity)[0])\n    # cross entropy loss\n    loss = ks.losses.sparse_categorical_crossentropy(labels, similarity, from_logits=True, axis=-1)\n    return loss\n</code></pre>"},{"location":"VAE.utils.math/#VAE.utils.math.log_density_gaussian_numpy","title":"VAE.utils.math.log_density_gaussian_numpy","text":"<pre><code>log_density_gaussian_numpy(sample, mean, logvar, all_combinations=False)\n</code></pre> <p>Calculates the sampled log density of a Gaussian.</p> <p>Numpy version of :func:<code>log_density_gaussian</code>.</p> <p>Parameters:</p> <ul> <li> <code>sample</code>             (<code>ndarray</code>)         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> at which to compute the density.</p> </li> <li> <code>mean</code>             (<code>ndarray</code>)         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> represnting the mean of Gaussian distribution.</p> </li> <li> <code>logvar</code>             (<code>ndarray</code>)         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> represnting the log variance of Gaussian distribution.</p> </li> <li> <code>all_combinations</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to return values for all combinations of batch pairs of <code>sample</code> and <code>mean</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>If <code>all_combinations=True</code> returns an array of shape <code>(batch_size, batch_size, latent_dim)</code>.</p> </li> <li> <code>ndarray</code>         \u2013          <p>If <code>all_combinations=False</code> returns an array of shape <code>(batch_size, latent_dim)</code>.</p> </li> </ul> Source code in <code>VAE/utils/math.py</code> <pre><code>def log_density_gaussian_numpy(sample: np.ndarray,\n                               mean: np.ndarray,\n                               logvar: np.ndarray,\n                               all_combinations: bool = False) -&gt; np.ndarray:\n    \"\"\"Calculates the sampled log density of a Gaussian.\n\n    Numpy version of :func:`log_density_gaussian`.\n\n    Parameters:\n        sample:\n            Array of shape `(batch_size, laten_dim)` at which to compute the density.\n        mean:\n            Array of shape `(batch_size, laten_dim)` represnting the mean of Gaussian distribution.\n        logvar:\n            Array of shape `(batch_size, laten_dim)` represnting the log variance of Gaussian distribution.\n        all_combinations:\n            Whether to return values for all combinations of batch pairs of `sample` and `mean`.\n\n    Returns:\n        If `all_combinations=True` returns an array of shape `(batch_size, batch_size, latent_dim)`.\n        If `all_combinations=False` returns an array of shape `(batch_size, latent_dim)`.\n\n    \"\"\"\n    if all_combinations:\n        # reshape to (batch_size, 1, latent_dim)\n        sample = np.expand_dims(sample, axis=1)\n\n        # reshape to (1, batch_size, latent_dim)\n        mean = np.expand_dims(mean, axis=0)\n        logvar = np.expand_dims(logvar, axis=0)\n\n    log_density = np.log(2 * np.pi) + logvar + np.exp(-logvar) * (sample - mean)**2\n    log_density *= -0.5\n    return log_density\n</code></pre>"},{"location":"VAE.utils.math/#VAE.utils.math.logmeanexp_numpy","title":"VAE.utils.math.logmeanexp_numpy","text":"<pre><code>logmeanexp_numpy(x, axis=None, keepdims=False)\n</code></pre> <p>Calculates Log(Mean(Exp(x))).</p> <p>Numpy version of :func:<code>logmeanexp</code>.</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>ndarray</code>)         \u2013          <p>Input array.</p> </li> <li> <code>axis</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>The dimensions to reduce.</p> </li> <li> <code>keepdims</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to keep the axis as singleton dimensions.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Numpy array.</p> </li> </ul> Source code in <code>VAE/utils/math.py</code> <pre><code>def logmeanexp_numpy(x: np.ndarray, axis: int = None, keepdims: bool = False) -&gt; np.ndarray:\n    \"\"\"Calculates Log(Mean(Exp(x))).\n\n    Numpy version of :func:`logmeanexp`.\n\n    Parameters:\n        x:\n            Input array.\n        axis:\n            The dimensions to reduce.\n        keepdims:\n            Whether to keep the axis as singleton dimensions.\n\n    Returns:\n        Numpy array.\n\n    \"\"\"\n    lse = logsumexp(x, axis=axis, keepdims=keepdims)\n    n = np.size(x) // np.size(lse)\n    log_n = np.log(n)\n    return lse - log_n\n</code></pre>"},{"location":"VAE.utils.math/#VAE.utils.math.kl_divergence_numpy","title":"VAE.utils.math.kl_divergence_numpy","text":"<pre><code>kl_divergence_numpy(mean1, logvar1, mean2=0, logvar2=0, all_combinations=False)\n</code></pre> <p>Calculates the KL divergence between two multivariate Gaussian distributions with diagonal covariance matrices.</p> <p>The KL divergence is returned for each latent dimensions separately. Since the KL divergence is additive in the case of diagonal covariance matrices, the KL divergence can be obtained from the sum over the last dimensions of the output.</p> <p>Parameters:</p> <ul> <li> <code>mean1</code>             (<code>float</code>)         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> representing the mean of the first Gaussian distribution.</p> </li> <li> <code>logvar1</code>             (<code>float</code>)         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> representing the log variance of the second Gaussian distribution.</p> </li> <li> <code>mean2</code>             (<code>float</code>, default:                 <code>0</code> )         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> representing the mean of the second Gaussian distribution. Defaults to 0.</p> </li> <li> <code>logvar2</code>             (<code>float</code>, default:                 <code>0</code> )         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> representing the log variance of the second Gaussian distribution. Defaults to 0.</p> </li> <li> <code>all_combinations</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to return values for all combinations of batch pairs of <code>sample</code> and <code>mean</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>If <code>all_combinations=True</code> returns an array of shape <code>(batch_size, batch_size, latent_dim)</code>.</p> </li> <li> <code>ndarray</code>         \u2013          <p>If <code>all_combinations=False</code> returns an array of shape <code>(batch_size, latent_dim)</code>.</p> </li> </ul> Source code in <code>VAE/utils/math.py</code> <pre><code>def kl_divergence_numpy(mean1: float,\n                        logvar1: float,\n                        mean2: float = 0,\n                        logvar2: float = 0,\n                        all_combinations: bool = False) -&gt; np.ndarray:\n    \"\"\"Calculates the KL divergence between two multivariate Gaussian distributions with diagonal covariance matrices.\n\n    The KL divergence is returned for each latent dimensions separately. Since the KL divergence is additive in the case\n    of diagonal covariance matrices, the KL divergence can be obtained from the sum over the last dimensions of the\n    output.\n\n    Parameters:\n        mean1:\n            Array of shape `(batch_size, laten_dim)` representing the mean of the first Gaussian distribution.\n        logvar1:\n            Array of shape `(batch_size, laten_dim)` representing the log variance of the second Gaussian distribution.\n        mean2:\n            Array of shape `(batch_size, laten_dim)` representing the mean of the second Gaussian distribution. Defaults\n            to 0.\n        logvar2:\n            Array of shape `(batch_size, laten_dim)` representing the log variance of the second Gaussian distribution.\n            Defaults to 0.\n        all_combinations:\n            Whether to return values for all combinations of batch pairs of `sample` and `mean`.\n\n    Returns:\n        If `all_combinations=True` returns an array of shape `(batch_size, batch_size, latent_dim)`.\n        If `all_combinations=False` returns an array of shape `(batch_size, latent_dim)`.\n\n    \"\"\"\n    if all_combinations:\n        # reshape to (batch_size, 1, latent_dim)\n        mean1 = np.expand_dims(mean1, axis=1)\n        logvar1 = np.expand_dims(logvar1, axis=1)\n\n        # reshape to (1, batch_size, latent_dim)\n        mean2 = np.expand_dims(mean2, axis=0)\n        logvar2 = np.expand_dims(logvar2, axis=0)\n\n    kl_div = logvar2 - logvar1 + (np.exp(logvar1) + (mean1 - mean2)**2) * np.exp(-logvar2) - 1\n    kl_div *= 0.5\n    return kl_div\n</code></pre>"},{"location":"VAE.utils.math/#VAE.utils.math.wasserstein_distance_numpy","title":"VAE.utils.math.wasserstein_distance_numpy","text":"<pre><code>wasserstein_distance_numpy(mean1, logvar1, mean2=0, logvar2=0, all_combinations=False)\n</code></pre> <p>Calculates the Wasserstein distance between two multivariate Gaussian distributions with diagonal covariance matrices.</p> <p>The Wasserstein distance is returned for each latent dimensions separately. Since the Wasserstein distance is additive in the case of diagonal covariance matrices, the Wasserstein distance can be obtained from the sum over the last dimensions of the output.</p> <p>Parameters:</p> <ul> <li> <code>mean1</code>             (<code>float</code>)         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> representing the mean of the first Gaussian distribution.</p> </li> <li> <code>logvar1</code>             (<code>float</code>)         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> representing the log variance of the second Gaussian distribution.</p> </li> <li> <code>mean2</code>             (<code>float</code>, default:                 <code>0</code> )         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> representing the mean of the second Gaussian distribution. Defaults to 0.</p> </li> <li> <code>logvar2</code>             (<code>float</code>, default:                 <code>0</code> )         \u2013          <p>Array of shape <code>(batch_size, laten_dim)</code> representing the log variance of the second Gaussian distribution. Defaults to 0.</p> </li> <li> <code>all_combinations</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to return values for all combinations of batch pairs of <code>sample</code> and <code>mean</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>If <code>all_combinations=True</code> returns an array of shape <code>(batch_size, batch_size, latent_dim)</code>.</p> </li> <li> <code>ndarray</code>         \u2013          <p>If <code>all_combinations=False</code> returns an array of shape <code>(batch_size, latent_dim)</code>.</p> </li> </ul> Source code in <code>VAE/utils/math.py</code> <pre><code>def wasserstein_distance_numpy(mean1: float,\n                               logvar1: float,\n                               mean2: float = 0,\n                               logvar2: float = 0,\n                               all_combinations: bool = False) -&gt; np.ndarray:\n    \"\"\"Calculates the Wasserstein distance between two multivariate Gaussian distributions with diagonal covariance\n    matrices.\n\n    The Wasserstein distance is returned for each latent dimensions separately. Since the Wasserstein distance is\n    additive in the case of diagonal covariance matrices, the Wasserstein distance can be obtained from the sum over the\n    last dimensions of the output.\n\n    Parameters:\n        mean1:\n            Array of shape `(batch_size, laten_dim)` representing the mean of the first Gaussian distribution.\n        logvar1:\n            Array of shape `(batch_size, laten_dim)` representing the log variance of the second Gaussian distribution.\n        mean2:\n            Array of shape `(batch_size, laten_dim)` representing the mean of the second Gaussian distribution. Defaults\n            to 0.\n        logvar2:\n            Array of shape `(batch_size, laten_dim)` representing the log variance of the second Gaussian distribution.\n            Defaults to 0.\n        all_combinations:\n            Whether to return values for all combinations of batch pairs of `sample` and `mean`.\n\n    Returns:\n        If `all_combinations=True` returns an array of shape `(batch_size, batch_size, latent_dim)`.\n        If `all_combinations=False` returns an array of shape `(batch_size, latent_dim)`.\n\n    \"\"\"\n    if all_combinations:\n        # reshape to (batch_size, 1, latent_dim)\n        mean1 = np.expand_dims(mean1, axis=1)\n        logvar1 = np.expand_dims(logvar1, axis=1)\n\n        # reshape to (1, batch_size, latent_dim)\n        mean2 = np.expand_dims(mean2, axis=0)\n        logvar2 = np.expand_dims(logvar2, axis=0)\n\n    wd = (mean1 - mean2)**2 + np.exp(logvar1) + np.exp(logvar2) - 2 * np.exp(0.5 * (logvar1 + logvar2))\n\n    return wd\n</code></pre>"},{"location":"VAE.utils.ode/","title":"VAE.utils.ode","text":""},{"location":"VAE.utils.ode/#VAE.utils.ode","title":"VAE.utils.ode","text":"<p>Collection of ODE systems.</p> <p>This module provides a collection of ODE systems that can be integrated with :func:<code>scipy.integrate.solveivp</code>.</p>"},{"location":"VAE.utils.ode/#VAE.utils.ode.roessler","title":"VAE.utils.ode.roessler","text":"<pre><code>roessler(t, X, a=0.15, b=0.1, c=8.5)\n</code></pre> <p>Roessler model.</p> Source code in <code>VAE/utils/ode.py</code> <pre><code>@jit\ndef roessler(t, X, a=0.15, b=0.1, c=8.5):\n    \"\"\"Roessler model.\"\"\"\n    x, y, z = X\n    dx = -y - z\n    dy = x + a * y\n    dz = b + z * (x - c)\n    return [dx, dy, dz]\n</code></pre>"},{"location":"VAE.utils.ode/#VAE.utils.ode.van_der_pol","title":"VAE.utils.ode.van_der_pol","text":"<pre><code>van_der_pol(t, X)\n</code></pre> <p>van-der-Pol model.</p> Source code in <code>VAE/utils/ode.py</code> <pre><code>@jit\ndef van_der_pol(t, X):\n    \"\"\"van-der-Pol model.\"\"\"\n    x, y = X\n    dx = y\n    dy = 5 * (1 - x**2) * y - x\n    return [dx, dy]\n</code></pre>"},{"location":"VAE.utils.ode/#VAE.utils.ode.lorenz63","title":"VAE.utils.ode.lorenz63","text":"<pre><code>lorenz63(t, X)\n</code></pre> <p>Lorenz'63 model.</p> Source code in <code>VAE/utils/ode.py</code> <pre><code>@jit\ndef lorenz63(t, X):\n    \"\"\"Lorenz'63 model.\"\"\"\n    x, y, z = X\n    dx = 10 * (y - x)\n    dy = x * (28 - z) - y\n    dz = x * y - 8 / 3 * z\n    return [dx, dy, dz]\n</code></pre>"},{"location":"VAE.utils.ode/#VAE.utils.ode.lorenz96a","title":"VAE.utils.ode.lorenz96a","text":"<pre><code>lorenz96a(t, X, F)\n</code></pre> <p>Lorenz'96 model with single scale.</p> Source code in <code>VAE/utils/ode.py</code> <pre><code>@jit\ndef lorenz96a(t, X, F):\n    \"\"\"Lorenz'96 model with single scale.\"\"\"\n    Xm1 = np.roll(X, 1)\n    Xm2 = np.roll(X, 2)\n    Xp1 = np.roll(X, -1)\n\n    return Xm1 * (Xp1 - Xm2) - X + F\n</code></pre>"},{"location":"VAE.utils.ode/#VAE.utils.ode.lorenz96b","title":"VAE.utils.ode.lorenz96b","text":"<pre><code>lorenz96b(t, Xin, K, J, F, h, b, c)\n</code></pre> <p>Lorenz'96 model with two scales.</p> Source code in <code>VAE/utils/ode.py</code> <pre><code>@jit\ndef lorenz96b(t, Xin, K, J, F, h, b, c):\n    \"\"\"Lorenz'96 model with two scales.\"\"\"\n    X = Xin[:K]\n    Y = Xin[K:].reshape((K, J))\n\n    # large scale\n    X_m1 = np.roll(X, 1)\n    X_m2 = np.roll(X, 2)\n    X_p1 = np.roll(X, -1)\n    dX = -X_m1 * (X_m2 - X_p1) - X + F\n\n    # small scale\n    Y_m1 = np.roll(Y, 1)\n    Y_p1 = np.roll(Y, -1)\n    Y_p2 = np.roll(Y, -2)\n    dY = -c * b * Y_p1 * (Y_p2 - Y_m1) - c * Y\n\n    # coupling between scales\n    dX -= h * c / b * np.sum(Y, axis=1)\n    dY += h * c / b * X.reshape((K, 1))\n\n    dY = dY.flatten()\n\n    return np.concatenate((dX, dY))\n</code></pre>"},{"location":"VAE.utils.ode/#VAE.utils.ode.sample_lorenz96a","title":"VAE.utils.ode.sample_lorenz96a","text":"<pre><code>sample_lorenz96a()\n</code></pre> <p>Sample run of Lorenz'96 model with single scale.</p> Source code in <code>VAE/utils/ode.py</code> <pre><code>def sample_lorenz96a():\n    \"\"\"Sample run of Lorenz'96 model with single scale.\"\"\"\n    F = 5.25\n    K = 21\n\n    N = 2**12\n    dt = 0.1\n    t_start = -50\n    t_eval = np.arange(0, N) * dt\n\n    x0 = F + 0.1 * np.random.randn(K)\n\n    sol = solve_ivp(lorenz96a, [t_start, t_eval[-1]], x0, t_eval=t_eval, method='RK45', args=(F, ))\n\n    x = sol.y\n    t = sol.t\n\n    return x, t\n</code></pre>"},{"location":"VAE.utils.ode/#VAE.utils.ode.sample_lorenz96b","title":"VAE.utils.ode.sample_lorenz96b","text":"<pre><code>sample_lorenz96b()\n</code></pre> <p>Sample run of Lorenz'96 model with two scales.</p> Parameters from <p>Christensen, H. M., I. M. Moroz, and T. N. Palmer, 2015: Simulating weather regimes: impact of stochastic and perturbed parameter schemes in a simple atmospheric model. Climate Dynamics, 44, 2195\u20132214, https://doi.org/10.1007/s00382-014-2239-9.</p> Source code in <code>VAE/utils/ode.py</code> <pre><code>def sample_lorenz96b():\n    \"\"\"Sample run of Lorenz'96 model with two scales.\n\n    Parameters from:\n        Christensen, H. M., I. M. Moroz, and T. N. Palmer, 2015: Simulating weather regimes: impact of\n        stochastic and perturbed parameter schemes in a simple atmospheric model. Climate Dynamics, 44,\n        2195\u20132214, https://doi.org/10.1007/s00382-014-2239-9.\n    \"\"\"\n    K = 8\n    J = 32\n    F = 20\n    h = 1\n    b = 10\n    c = 10\n\n    N = 2**10\n    dt = 0.05\n    t_start = -5\n    t_eval = np.arange(0, N) * dt\n\n    x0 = F + 0.1 * np.random.randn(K)\n    y0 = 0.01 * np.random.randn(J * K)\n\n    sol = solve_ivp(lorenz96b, [t_start, t_eval[-1]],\n                    np.concatenate((x0, y0)),\n                    t_eval=t_eval,\n                    method='RK45',\n                    args=(K, J, F, h, b, c))\n\n    x = sol.y[:K]\n    y = sol.y[K:]\n    t = sol.t\n\n    return x, y, t\n</code></pre>"},{"location":"VAE.utils.plot/","title":"Plot functions","text":""},{"location":"VAE.utils.plot/#VAE.utils.plot","title":"VAE.utils.plot","text":"<p>Collection of plot functions.</p>"},{"location":"VAE.utils.plot/#VAE.utils.plot.decoder_plot","title":"VAE.utils.plot.decoder_plot","text":"<pre><code>decoder_plot(decoder, z_values, z_mean=0, cond=None, target=None, order=None, index=0, channels=None, labels=None, highlight='lightgray', name='Decoder plot', batch_size=32, verbose=True, sharex=True, sharey=True)\n</code></pre> <p>Plot decoder output for sampled latent variable. One variable at a time.</p> <p>Draw samples from latent space and plot decoder output. The function varies one latent variable at a time, while all others are set to <code>z_mean</code>.</p> <p>Parameters:</p> <ul> <li> <code>decoder</code>             (<code>Model</code>)         \u2013          <p>Decoder model.</p> </li> <li> <code>z_values</code>             (<code>ndarray</code>)         \u2013          <p>Values by which the latent variables will be varied.</p> </li> <li> <code>z_mean</code>             (<code>ndarray</code>, default:                 <code>0</code> )         \u2013          <p>Values of the unchanged latent variables. If Numpy array, <code>z_mean</code> must be broadcastable to an array of shape <code>(len(z_values), set_size, latent_dim)</code>.</p> </li> <li> <code>cond</code>             (<code>ndarray</code>, default:                 <code>None</code> )         \u2013          <p>Optional input condition.</p> </li> <li> <code>target</code>             (<code>ndarray</code>, default:                 <code>None</code> )         \u2013          <p>Optional target data.</p> </li> <li> <code>order</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Plotting order of the latent dimensions.</p> </li> <li> <code>index</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Index of the decoder output that will be shown. Index refers to the second dimension of size <code>set_size</code>.</p> </li> <li> <code>channels</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels will be shown.</p> </li> <li> <code>labels</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>Labels of the channels.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'Decoder plot'</code> )         \u2013          <p>Name of the figure.</p> </li> <li> <code>verbose</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Verbosity level.</p> </li> </ul> <p>Returns:     Tuple of figure and axes.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def decoder_plot(decoder: Model,\n                 z_values: np.ndarray,\n                 z_mean: np.ndarray = 0,\n                 cond: np.ndarray = None,\n                 target: np.ndarray = None,\n                 order: list[int] = None,\n                 index: int = 0,\n                 channels: list[int] = None,\n                 labels: list[str] = None,\n                 highlight: str = 'lightgray',\n                 name: str = 'Decoder plot',\n                 batch_size: int = 32,\n                 verbose: bool = True,\n                 sharex: bool = True,\n                 sharey: bool = True):\n    \"\"\"Plot decoder output for sampled latent variable. One variable at a time.\n\n    Draw samples from latent space and plot decoder output. The function varies one latent variable at a time, while all\n    others are set to `z_mean`.\n\n    Parameters:\n        decoder:\n            Decoder model.\n        z_values:\n            Values by which the latent variables will be varied.\n        z_mean:\n            Values of the unchanged latent variables. If Numpy array, `z_mean` must be broadcastable to an array of\n            shape `(len(z_values), set_size, latent_dim)`.\n        cond:\n            Optional input condition.\n        target:\n            Optional target data.\n        order:\n            Plotting order of the latent dimensions.\n        index:\n            Index of the decoder output that will be shown. Index refers to the second dimension of size `set_size`.\n        channels:\n            Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels\n            will be shown.\n        labels:\n            Labels of the channels.\n        name:\n            Name of the figure.\n        verbose:\n            Verbosity level.\n\n     Returns:\n        Tuple of figure and axes.\n\n    \"\"\"\n    _, set_size, latent_dim = decoder.inputs[0].get_shape().as_list()\n    _, set_size, output_length, output_channels = decoder.outputs[0].get_shape().as_list()\n\n    z_mean = np.broadcast_to(z_mean, (len(z_values), set_size, latent_dim))\n    z_values = np.array(z_values)[:, None]\n    idx_z0 = np.argmin(np.abs(z_values - z_mean[:, 0, :]), axis=0)\n\n    if channels is None:\n        channels = range(output_channels)\n\n    if cond is not None:\n        cond = np.broadcast_to(cond, (len(z_values), set_size, cond.shape[-1]))\n\n    if order is None:\n        order = np.arange(latent_dim)\n\n    output_reverse = [layer.name for layer in decoder.layers if 'reverse' in layer.name]\n    if output_reverse:\n        x = range(-output_length, 0)\n    else:\n        x = range(output_length)\n\n    linestyles = cycler(color=[plt.get_cmap('tab10')(n) for n in channels])\n\n    fig, axs = _create_figure(fig=name, rows=len(z_values), columns=len(order), sharex=sharex, sharey=sharey)\n    pbar = Progbar(len(order), unit_name='latent dimension', verbose=verbose, interval=1)\n    for column, k in enumerate(order):\n        z = z_mean.copy()\n        z[..., k] = z_values\n\n        # predict\n        if cond is None:\n            y = decoder.predict(z, batch_size=batch_size)\n        else:\n            y = decoder.predict([z, cond], batch_size=batch_size)\n\n        y = y[:, index, ...][..., channels]\n\n        axs[-1, column].set_title('$k={}$'.format(k))\n\n        for row, yr in enumerate(y):\n            ax = axs[row, column]\n            ax.set_prop_cycle(linestyles)\n            p = ax.plot(x, yr, zorder=1.1, linewidth=2)\n            if target is not None:\n                ax.plot(x, target, zorder=1, alpha=0.5)\n\n            ax.grid(axis='both', linestyle=':')\n            ax.axhline(0, color='k', linewidth=1.25, linestyle=':')\n            if column == 0:\n                ax.set_ylabel(z_values[row, 0])\n\n            if row == idx_z0[k]:\n                ax.set_facecolor(highlight)\n\n            if (row == len(y) - 1) and (column == len(order) - 1):\n                if labels is not None:\n                    ax.legend(p, labels, loc='upper left', bbox_to_anchor=(1, 1.05))\n\n        pbar.add(1)\n\n    fig.text(0.01, 0.5, '$z_k$', va='center', rotation='vertical', fontsize='large')\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.decoder_plot2d","title":"VAE.utils.plot.decoder_plot2d","text":"<pre><code>decoder_plot2d(decoder, latent_pair, z_values, z_mean=0, cond=None, target=None, index=0, channels=None, labels=None, highlight='lightgray', batch_size=32, name='Decoder plot 2D', verbose=True, sharex=True, sharey=True)\n</code></pre> <p>Plot decoder output for sampled latent variable. Two variables at a time.</p> <p>Draw samples from latent space and plot decoder output. The function varies two latent variable at a time and sets all others to <code>z0</code>.</p> Note <p>For models in :mod:<code>models_single</code>.</p> <p>Parameters:</p> <ul> <li> <code>decoder</code>             (<code>Model</code>)         \u2013          <p>Instance of the decoder model.</p> </li> <li> <code>latent_pair</code>             (<code>tuple[int, int]</code>)         \u2013          <p>Latent dimensions that will be varied.</p> </li> <li> <code>z_values</code>             (<code>ndarray</code>)         \u2013          <p>Values by which the latent variables will be varied.</p> </li> <li> <code>z_mean</code>             (<code>ndarray</code>, default:                 <code>0</code> )         \u2013          <p>Values of the unchanged latent variables. If Numpy array, <code>z_mean</code> must be broadcastable to an array of shape <code>(len(z_values), set_size, latent_dim)</code>.</p> </li> <li> <code>cond</code>             (<code>ndarray</code>, default:                 <code>None</code> )         \u2013          <p>Optional input condition.</p> </li> <li> <code>target</code>         \u2013          <p>Optional target data.</p> </li> <li> <code>index</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Index of the decoder output that will be shown. Index refers to the second dimension of size <code>set_size</code>.</p> </li> <li> <code>channels</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels will be shown.</p> </li> <li> <code>labels</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>Labels of the channels.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'Decoder plot 2D'</code> )         \u2013          <p>Name of the figure.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Tuple of figure and axes.</p> </li> </ul> Source code in <code>VAE/utils/plot.py</code> <pre><code>def decoder_plot2d(decoder: Model,\n                   latent_pair: tuple[int, int],\n                   z_values: np.ndarray,\n                   z_mean: np.ndarray = 0,\n                   cond: np.ndarray = None,\n                   target=None,\n                   index: int = 0,\n                   channels: list[int] = None,\n                   labels: list[str] = None,\n                   highlight: str = 'lightgray',\n                   batch_size: int = 32,\n                   name: str = \"Decoder plot 2D\",\n                   verbose: bool = True,\n                   sharex: bool = True,\n                   sharey: bool = True):\n    \"\"\"Plot decoder output for sampled latent variable. Two variables at a time.\n\n    Draw samples from latent space and plot decoder output. The function varies two latent variable at a time and sets\n    all others to ``z0``.\n\n    Note:\n        For models in :mod:`models_single`.\n\n    Parameters:\n        decoder:\n            Instance of the decoder model.\n        latent_pair:\n            Latent dimensions that will be varied.\n        z_values:\n            Values by which the latent variables will be varied.\n        z_mean:\n            Values of the unchanged latent variables. If Numpy array, `z_mean` must be broadcastable to an array of\n            shape `(len(z_values), set_size, latent_dim)`.\n        cond:\n            Optional input condition.\n        target:\n            Optional target data.\n        index:\n            Index of the decoder output that will be shown. Index refers to the second dimension of size `set_size`.\n        channels:\n            Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels\n            will be shown.\n        labels:\n            Labels of the channels.\n        name:\n            Name of the figure.\n\n    Returns:\n        Tuple of figure and axes.\n\n    \"\"\"\n    _, set_size, latent_dim = decoder.inputs[0].get_shape().as_list()\n    _, set_size, output_length, output_channels = decoder.outputs[0].get_shape().as_list()\n\n    z_mean = np.broadcast_to(z_mean, (len(z_values), set_size, latent_dim))\n    z_values = np.array(z_values)[:, None]\n    k0, k1 = latent_pair\n    idx_z0 = np.argmin(np.abs(z_values - z_mean[:, 0, :]), axis=0)\n\n    if channels is None:\n        channels = range(output_channels)\n\n    if cond is not None:\n        cond = np.broadcast_to(cond, (len(z_values), set_size, cond.shape[-1]))\n\n    output_reverse = [layer.name for layer in decoder.layers if 'reverse' in layer.name]\n    if output_reverse:\n        x = range(-output_length, 0)\n    else:\n        x = range(output_length)\n\n    linestyles = cycler(color=[plt.get_cmap('tab10')(n) for n in channels])\n\n    fig, axs = _create_figure(fig=name, rows=len(z_values), columns=len(z_values), sharex=sharex, sharey=sharey)\n    pbar = Progbar(len(z_values), unit_name='column', verbose=verbose, interval=1)\n    for column in range(len(z_values)):\n        # prepare latent samples\n        z = z_mean.copy()\n        z[..., k0] = z_values[column, ...]\n        z[..., k1] = z_values\n\n        # predict\n        if cond is None:\n            y = decoder.predict(z, batch_size=batch_size)\n        else:\n            y = decoder.predict([z, cond], batch_size=batch_size)\n\n        y = y[:, index, ...][..., channels]\n\n        axs[0, column].set_xlabel(z_values[column, 0])\n        for row, yr in enumerate(y):\n            ax = axs[row, column]\n            ax.set_prop_cycle(linestyles)\n            p = ax.plot(x, yr, zorder=1, linewidth=2)\n            if target is not None:\n                ax.plot(x, target, zorder=1, alpha=0.5)\n\n            ax.grid(axis='both', linestyle=':')\n            ax.axhline(0, color='k', linewidth=1.25, linestyle=':')\n            if column == 0:\n                ax.set_ylabel(z_values[row, 0])\n\n            if (column == idx_z0[k0]) and (row == idx_z0[k1]):\n                ax.set_facecolor(highlight)\n\n            if (row == len(y) - 1) and (column == len(z_values) - 1):\n                if labels is not None:\n                    ax.legend(p, labels, loc='upper left', bbox_to_anchor=(1, 1.05))\n\n        pbar.add(1)\n\n    fig.text(0.01, 0.5, f'$z_{{{k1}}}$', va='center', rotation='vertical', fontsize='large')\n    fig.text(0.5, 0.01, f'$z_{{{k0}}}$', ha='center', fontsize='large')\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.decoder_pcolormesh","title":"VAE.utils.plot.decoder_pcolormesh","text":"<pre><code>decoder_pcolormesh(decoder, z_values, z0=0, cond=None, channel=0, order=None, vmin=None, vmax=None, cmap=None, highlight='#bbbbbb', name='Decoder plot', batch_size=32, verbose=True)\n</code></pre> <p>Plot decoder output for sampled latent variable. One variable at a time.</p> <p>Draw samples from latent space and plot decoder output. The function varies one latent variable at a time, while all others are set to <code>z0</code>.</p> <p>Parameters:</p> <ul> <li> <code>decoder</code>             (<code>Model</code>)         \u2013          <p>Instance of the decoder model.</p> </li> <li> <code>z_values</code>             (<code>ndarray</code>)         \u2013          <p>Values by which the latent variables will be varied.</p> </li> <li> <code>z0</code>             (<code>ndarray</code>, default:                 <code>0</code> )         \u2013          <p>Values of the unchanged latent variables. If Numpy array, <code>z0</code> must be compatible with shape <code>(len(z_values), latent_dim)</code>.</p> </li> <li> <code>cond</code>             (<code>ndarray</code>, default:                 <code>None</code> )         \u2013          <p>Optional input condition.</p> </li> <li> <code>channel</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Channel to be shown.</p> </li> <li> <code>order</code>             (<code>list[int]</code>, default:                 <code>None</code> )         \u2013          <p>Plotting order of the latent dimensions.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>'Decoder plot'</code> )         \u2013          <p>Name of the figure.</p> </li> <li> <code>verbose</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Verbosity mode.</p> </li> </ul> <p>Returns:     Tuple of figure and axes.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def decoder_pcolormesh(decoder: Model,\n                       z_values: np.ndarray,\n                       z0: np.ndarray = 0,\n                       cond: np.ndarray = None,\n                       channel: int = 0,\n                       order: list[int] = None,\n                       vmin: float = None,\n                       vmax: float = None,\n                       cmap: str = None,\n                       highlight: str = '#bbbbbb',\n                       name: str = 'Decoder plot',\n                       batch_size: int = 32,\n                       verbose: bool = True):\n    \"\"\"Plot decoder output for sampled latent variable. One variable at a time.\n\n    Draw samples from latent space and plot decoder output. The function varies one latent variable at a time, while all\n    others are set to ``z0``.\n\n    Parameters:\n        decoder:\n            Instance of the decoder model.\n        z_values:\n            Values by which the latent variables will be varied.\n        z0:\n            Values of the unchanged latent variables. If Numpy array, ``z0`` must be compatible\n            with shape ``(len(z_values), latent_dim)``.\n        cond:\n            Optional input condition.\n        channel:\n            Channel to be shown.\n        order:\n            Plotting order of the latent dimensions.\n        name:\n            Name of the figure.\n        verbose:\n            Verbosity mode.\n\n     Returns:\n        Tuple of figure and axes.\n\n    \"\"\"\n    z_values = np.array(z_values)\n    latent_dim = decoder.inputs[0].get_shape().as_list()[1]\n    z0 = np.broadcast_to(z0, (1, latent_dim))\n    z0 = np.repeat(z0, len(z_values), axis=0)\n\n    if cond is not None:\n        cond = np.repeat(cond, len(z_values), axis=0)\n\n    idx_z0 = np.argmin(np.abs(z_values[:, None] - z0), axis=0)\n\n    if order is None:\n        order = np.arange(latent_dim)\n\n    fig, axs = _create_figure(fig=name, rows=len(z_values), columns=len(order), subplots_adjust=False)\n\n    pbar = Progbar(len(order), unit_name='latent dimension', verbose=verbose, interval=1)\n\n    for column, column_k in enumerate(order):\n        # sample from latent space\n        # vary single value and set others to z0\n        z = z0.copy()\n        z[:, column_k] = z_values\n\n        # predict\n        if cond is None:\n            y = decoder.predict(z, batch_size=batch_size)\n        else:\n            y = decoder.predict([z, cond], batch_size=batch_size)\n\n        axs[-1, column].set_title('$k={}$'.format(column_k))\n\n        for row, yr in enumerate(y):\n            ax = axs[row, column]\n            ax.pcolormesh(yr[..., channel], vmin=vmin, vmax=vmax, cmap=cmap, zorder=1)\n\n            if column == 0:\n                ax.set_ylabel('$z_k={:.1f}$'.format(z_values[row]))\n\n            if row == idx_z0[column_k]:\n                ax.patch.set_edgecolor(highlight)\n                ax.patch.set_linewidth(10)\n\n        pbar.add(1)\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.decoder_response","title":"VAE.utils.plot.decoder_response","text":"<pre><code>decoder_response(decoder, inputs, z_pertub_p=None, z_pertub_n=None, order=None, index=0, channels=None, labels=None, batch_size=32, name='Decoder response', verbose=1, showmax=True, sharex=True, sharey=True)\n</code></pre> <p>Plot decoder response.</p> <p>Decoder response with respect to changes in the latent variables. The response is the difference between the decoder output of the positive response from <code>z_pertub_p</code> and the negative response from <code>z_pertub_n</code>.</p> <p>Parameters:</p> <ul> <li> <code>decoder</code>             (<code>Model</code>)         \u2013          <p>Model Instance of the decoder model.</p> </li> <li> <code>inputs</code>         \u2013          <p>Inputs to the decoder.</p> </li> <li> <code>z_pertub_p</code>         \u2013          <p>callable, optional Callable applied to the latent variables that will be used to calculate the positive response.</p> </li> <li> <code>z_pertub_n</code>         \u2013          <p>callable, optional Callable applied to the latent variables that will be used to calculate the negative/neutral response.</p> </li> <li> <code>order</code>         \u2013          <p>list of int Plotting order of the latent dimensions.</p> </li> <li> <code>index</code>         \u2013          <p>int Index of the decoder output that will be shown. Index refers to the first dimension after the batch dimension.</p> </li> <li> <code>channels</code>         \u2013          <p>list of ints Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels will be shown.</p> </li> <li> <code>labels</code>         \u2013          <p>list of str Labels of the channels.</p> </li> <li> <code>name</code>         \u2013          <p>str Name of the figure.</p> </li> </ul> <p>Returns:     tuple:         fig: :class:<code>matplotlib.figure.Figure</code>             The figure instance.         axs: Array of :class:<code>matplotlib.axes.Axes</code>             Array of axes objects.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def decoder_response(decoder: Model,\n                     inputs,\n                     z_pertub_p=None,\n                     z_pertub_n=None,\n                     order=None,\n                     index=0,\n                     channels=None,\n                     labels=None,\n                     batch_size=32,\n                     name='Decoder response',\n                     verbose=1,\n                     showmax=True,\n                     sharex=True,\n                     sharey=True):\n    \"\"\"Plot decoder response.\n\n    Decoder response with respect to changes in the latent variables. The response is the difference between the decoder\n    output of the positive response from `z_pertub_p` and the negative response from `z_pertub_n`.\n\n    Parameters:\n        decoder: Model\n            Instance of the decoder model.\n        inputs:\n            Inputs to the decoder.\n        z_pertub_p : callable, optional\n            Callable applied to the latent variables that will be used to calculate the positive response.\n        z_pertub_n : callable, optional\n            Callable applied to the latent variables that will be used to calculate the negative/neutral response.\n        order: list of int\n            Plotting order of the latent dimensions.\n        index : int\n            Index of the decoder output that will be shown. Index refers to the first dimension after the batch\n            dimension.\n        channels : list of ints\n            Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels\n            will be shown.\n        labels : list of str\n            Labels of the channels.\n        name: str\n            Name of the figure.\n\n     Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: Array of :class:`matplotlib.axes.Axes`\n                Array of axes objects.\n\n    \"\"\"\n    if isinstance(inputs, list):\n        z_mean, condition = inputs\n        condition = [condition]\n    else:\n        z_mean = inputs\n        condition = []\n\n    _, set_size, output_length, output_channels = decoder.outputs[0].get_shape().as_list()\n    latent_dim = decoder.inputs[0].get_shape().as_list()[-1]\n    if channels is None:\n        channels = range(output_channels)\n\n    if z_mean.ndim == 2:\n        z_mean = z_mean[:, None, :]\n\n    z_mean = np.broadcast_to(z_mean, (len(z_mean), set_size, latent_dim))\n\n    if order is None:\n        order = range(latent_dim)\n\n    pbar = Progbar(len(order), unit_name='latent dimension', verbose=verbose, interval=1)\n    fig, axs = _create_figure(fig=name,\n                              rows=len(channels),\n                              columns=len(order),\n                              flip_rows=False,\n                              sharex=sharex,\n                              sharey=sharey)\n\n    output_reverse = [layer.name for layer in decoder.layers if 'reverse' in layer.name]\n    if output_reverse:\n        x = range(-output_length, 0)\n    else:\n        x = range(output_length)\n\n    for column, k in enumerate(order):\n        zp = z_mean.copy()\n        zn = z_mean.copy()\n\n        if z_pertub_p is not None:\n            zp[..., k] = z_pertub_p(zp[..., k])\n\n        if z_pertub_n is not None:\n            zn[..., k] = z_pertub_n(zp[..., k])\n\n        # predict\n        yp = decoder.predict([zp] + condition, batch_size=batch_size)\n        yn = decoder.predict([zn] + condition, batch_size=batch_size)\n        y_diff = yp - yn\n        y_diff = y_diff[:, index, ...][..., channels]\n\n        # average over batches\n        y_diff_mean = np.mean(y_diff, axis=0)\n        y_diff_prcs = np.percentile(y_diff, [5, 95], axis=0)\n\n        axs[0, column].set_title(f'$z_{{{k}}}$')\n        for row in range(len(channels)):\n            ax = axs[row, column]\n            ax.plot(x, y_diff_mean[:, row], color='tab:blue', zorder=1.2)\n            ax.fill_between(x,\n                            y_diff_prcs[0, :, row],\n                            y_diff_prcs[1, :, row],\n                            facecolor='lightsteelblue',\n                            edgecolor='tab:blue',\n                            linewidth=1,\n                            zorder=1.1)\n\n            ax.grid(axis='both', linestyle=':')\n            ax.axhline(0, color='k', linewidth=1.25, linestyle=':')\n            if column == 0:\n                if labels is not None:\n                    ax.set_ylabel(labels[row])\n                else:\n                    ax.set_ylabel(row)\n            if showmax:\n                peaks, _ = find_peaks(np.abs(y_diff_mean[:, row]))\n                if len(peaks) &gt; 0:\n                    plt.text(0.05,\n                             0.95,\n                             f'\\u0394={x[peaks[0]]}',\n                             transform=ax.transAxes,\n                             ha='left',\n                             va='top',\n                             bbox=dict(facecolor='white', alpha=0.5))\n\n        pbar.add(1)\n\n    for ax_row in axs:\n        ylims = [np.max(np.abs(ax.get_ylim())) for ax in ax_row]\n        if sharey:\n            ax_row[0].set_ylim(-ylims[0], ylims[0])\n        else:\n            for ax, ylim in zip(ax_row, ylims):\n                ax.set_ylim(-ylim, ylim)\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.decoder_composite","title":"VAE.utils.plot.decoder_composite","text":"<pre><code>decoder_composite(decoder, inputs, order=None, index=0, channels=None, adjusted=False, labels=None, batch_size=32, name='Decoder composite', verbose=1, showmax=True, sharex=True, sharey=True)\n</code></pre> <p>Plot decoder composite.</p> <p>The decoder composite is obtained by setting all but one latent dimension to zero.</p> <p>Parameters:</p> <ul> <li> <code>decoder</code>             (<code>Model</code>)         \u2013          <p>Model Instance of the decoder model.</p> </li> <li> <code>inputs</code>         \u2013          <p>Inputs to the decoder.</p> </li> <li> <code>order</code>         \u2013          <p>list of int Plotting order of the latent dimensions.</p> </li> <li> <code>index</code>         \u2013          <p>int Index of the decoder output that will be shown. Index refers to the first dimension after the batch dimension.</p> </li> <li> <code>channels</code>         \u2013          <p>list of ints Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels will be shown.</p> </li> <li> <code>adjusted</code>         \u2013          <p>bool Whether the composite is adjusted by removing the average decoder output sampled from the prior.</p> </li> <li> <code>labels</code>         \u2013          <p>list of str Labels of the channels.</p> </li> <li> <code>name</code>         \u2013          <p>str Name of the figure.</p> </li> </ul> <p>Returns:     tuple:         fig: :class:<code>matplotlib.figure.Figure</code>             The figure instance.         axs: Array of :class:<code>matplotlib.axes.Axes</code>             Array of axes objects.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def decoder_composite(decoder: Model,\n                      inputs,\n                      order=None,\n                      index=0,\n                      channels=None,\n                      adjusted=False,\n                      labels=None,\n                      batch_size=32,\n                      name='Decoder composite',\n                      verbose=1,\n                      showmax=True,\n                      sharex=True,\n                      sharey=True):\n    \"\"\"Plot decoder composite.\n\n    The decoder composite is obtained by setting all but one latent dimension to zero.\n\n    Parameters:\n        decoder: Model\n            Instance of the decoder model.\n        inputs:\n            Inputs to the decoder.\n        order: list of int\n            Plotting order of the latent dimensions.\n        index : int\n            Index of the decoder output that will be shown. Index refers to the first dimension after the batch\n            dimension.\n        channels : list of ints\n            Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels\n            will be shown.\n        adjusted: bool\n            Whether the composite is adjusted by removing the average decoder output sampled from the prior.\n        labels : list of str\n            Labels of the channels.\n        name: str\n            Name of the figure.\n\n     Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: Array of :class:`matplotlib.axes.Axes`\n                Array of axes objects.\n\n    \"\"\"\n    if isinstance(inputs, list):\n        z_mean, condition = inputs\n        condition = [condition]\n    else:\n        z_mean = inputs\n        condition = []\n\n    _, set_size, output_length, output_channels = decoder.outputs[0].get_shape().as_list()\n    latent_dim = decoder.inputs[0].get_shape().as_list()[-1]\n    if channels is None:\n        channels = range(output_channels)\n\n    if z_mean.ndim == 2:\n        z_mean = z_mean[:, None, :]\n\n    z_mean = np.broadcast_to(z_mean, (len(z_mean), set_size, latent_dim))\n\n    if order is None:\n        order = range(latent_dim)\n\n    pbar = Progbar(len(order), unit_name='latent dimension', verbose=verbose, interval=1)\n    fig, axs = _create_figure(fig=name,\n                              rows=len(channels),\n                              columns=len(order),\n                              flip_rows=False,\n                              sharex=sharex,\n                              sharey=sharey)\n\n    output_reverse = [layer.name for layer in decoder.layers if 'reverse' in layer.name]\n    if output_reverse:\n        x = range(-output_length, 0)\n    else:\n        x = range(output_length)\n\n    for column, k in enumerate(order):\n        zc = np.zeros_like(z_mean)\n        zc[..., k] = z_mean[..., k]\n\n        # predict\n        yc = decoder.predict([zc] + condition, batch_size=batch_size)\n\n        if adjusted:\n            yc -= decoder.predict([zc * 0] + condition, batch_size=batch_size)\n\n        yc = yc[:, index, ...][..., channels]\n\n        # average over batches\n        # positive\n        idx = z_mean[:, 0, k] &gt; 0\n        yp_mean = np.mean(yc[idx, ...], axis=0)\n        yp_prcs = np.percentile(yc[idx, ...], [5, 95], axis=0)\n        # negative\n        idx = z_mean[:, 0, k] &lt; 0\n        yn_mean = np.mean(yc[idx, ...], axis=0)\n        yn_prcs = np.percentile(yc[idx, ...], [5, 95], axis=0)\n\n        axs[0, column].set_title(f'$z_{{{k}}}$')\n        for row in range(len(channels)):\n            ax = axs[row, column]\n            hp1, = ax.plot(x, yp_mean[:, row], color='tab:red', zorder=1.2)\n            hp2 = ax.fill_between(x,\n                                  yp_prcs[0, :, row],\n                                  yp_prcs[1, :, row],\n                                  alpha=0.5,\n                                  facecolor='tab:red',\n                                  edgecolor='tab:red',\n                                  linewidth=1,\n                                  zorder=1.1)\n\n            hn1, = ax.plot(x, yn_mean[:, row], color='tab:blue', zorder=1.2)\n            hn2 = ax.fill_between(x,\n                                  yn_prcs[0, :, row],\n                                  yn_prcs[1, :, row],\n                                  alpha=0.5,\n                                  facecolor='tab:blue',\n                                  edgecolor='tab:blue',\n                                  linewidth=1,\n                                  zorder=1.1)\n\n            ax.grid(axis='both', linestyle=':')\n            ax.axhline(0, color='k', linewidth=1.25, linestyle=':')\n            if column == 0:\n                if labels is not None:\n                    ax.set_ylabel(labels[row])\n                else:\n                    ax.set_ylabel(row)\n\n            if ax == axs[0, -1]:\n                ax.legend([(hp1, hp2), (hn1, hn2)], ['$z&gt;0$', '$z&lt;0$'], loc='upper left', bbox_to_anchor=(1, 1))\n\n            if showmax:\n                peaks, _ = find_peaks(np.abs(yp_mean[:, row]))\n                if len(peaks) &gt; 0:\n                    plt.text(0.05,\n                             0.95,\n                             f'\\u0394={x[peaks[0]]}',\n                             transform=ax.transAxes,\n                             ha='left',\n                             va='top',\n                             bbox=dict(facecolor='white', alpha=0.5))\n\n        pbar.add(1)\n\n    for ax_row in axs:\n        ylims = [np.max(np.abs(ax.get_ylim())) for ax in ax_row]\n        if sharey:\n            ax_row[0].set_ylim(-ylims[0], ylims[0])\n        else:\n            for ax, ylim in zip(ax_row, ylims):\n                ax.set_ylim(-ylim, ylim)\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.decoder_response_hist","title":"VAE.utils.plot.decoder_response_hist","text":"<pre><code>decoder_response_hist(decoder, inputs, z_pertub_p=None, z_pertub_n=None, order=None, index=0, channels=None, bins=10, vmin=None, vmax=None, cmap=None, norm=None, batch_size=32, name='Temporal response', labels=None, verbose=1, sharex=True, sharey=True)\n</code></pre> <p>Plot decoder response histogram.</p> <p>Decoder response with respect to changes in the latent variables.</p> <p>Parameters:</p> <ul> <li> <code>decoder</code>         \u2013          <p>Model Instance of the decoder.</p> </li> <li> <code>inputs</code>         \u2013          <p>Inputs to the decoder.</p> </li> <li> <code>z_pertub_p</code>         \u2013          <p>callable, optional Callable applied to the latent variables that will be used to calculate the positive response.</p> </li> <li> <code>z_pertub_n</code>         \u2013          <p>callable, optional Callable applied to the latent variables that will be used to calculate the negative/neutral response.</p> </li> <li> <code>bins</code>         \u2013          <p>int or Sequence See :func:<code>numpy.histogram</code>.</p> </li> <li> <code>order</code>         \u2013          <p>iterable Plotting order of the latent dimensions.</p> </li> <li> <code>index</code>         \u2013          <p>int Index of the decoder output that will be shown. Index refers to the first dimension after the batch dimension.</p> </li> <li> <code>channels</code>         \u2013          <p>list of ints Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels will be shown.</p> </li> <li> <code>labels</code>         \u2013          <p>list of str Labels of the channels.</p> </li> <li> <code>name</code>         \u2013          <p>str Name of the figure.</p> </li> </ul> <p>Returns:     tuple:         fig: :class:<code>matplotlib.figure.Figure</code>             The figure instance.         axs: Array of :class:<code>matplotlib.axes.Axes</code>             Array of axes objects.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def decoder_response_hist(decoder: Model,\n                          inputs,\n                          z_pertub_p=None,\n                          z_pertub_n=None,\n                          order=None,\n                          index=0,\n                          channels=None,\n                          bins=10,\n                          vmin=None,\n                          vmax=None,\n                          cmap=None,\n                          norm=None,\n                          batch_size=32,\n                          name='Temporal response',\n                          labels=None,\n                          verbose=1,\n                          sharex=True,\n                          sharey=True):\n    \"\"\"Plot decoder response histogram.\n\n    Decoder response with respect to changes in the latent variables.\n\n    Parameters:\n        decoder : Model\n            Instance of the decoder.\n        inputs :\n            Inputs to the decoder.\n        z_pertub_p : callable, optional\n            Callable applied to the latent variables that will be used to calculate the positive response.\n        z_pertub_n : callable, optional\n            Callable applied to the latent variables that will be used to calculate the negative/neutral response.\n        bins : int or Sequence\n            See :func:`numpy.histogram`.\n        order : iterable\n            Plotting order of the latent dimensions.\n        index : int\n            Index of the decoder output that will be shown. Index refers to the first dimension after the batch\n            dimension.\n        channels : list of ints\n            Channels to be shown. Channels refer to the last dimension of the decoder output. If None, all channels\n            will be shown.\n        labels : list of str\n            Labels of the channels.\n        name : str\n            Name of the figure.\n\n     Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: Array of :class:`matplotlib.axes.Axes`\n                Array of axes objects.\n\n    \"\"\"\n    def _hist(x, bins):\n        pdf = []\n        for x_row in x.T:\n            new_pdf, bins = np.histogram(x_row, bins=bins, density=True)\n            pdf.append(new_pdf)\n\n        return np.stack(pdf, axis=1), bins\n\n    if isinstance(inputs, list):\n        z_mean, condition = inputs\n        condition = [condition]\n    else:\n        z_mean = inputs\n        condition = []\n\n    _, set_size, output_length, output_channels = decoder.outputs[0].get_shape().as_list()\n    latent_dim = decoder.inputs[0].get_shape().as_list()[-1]\n    if channels is None:\n        channels = range(output_channels)\n\n    if z_mean.ndim == 2:\n        z_mean = z_mean[:, None, :]\n\n    z_mean = np.broadcast_to(z_mean, (len(z_mean), set_size, latent_dim))\n\n    if order is None:\n        order = np.arange(latent_dim)\n\n    output_reverse = [layer.name for layer in decoder.layers if 'reverse' in layer.name]\n    if output_reverse:\n        x = range(-output_length, 0)\n    else:\n        x = range(output_length)\n\n    pbar = Progbar(len(order), unit_name='latent dimension', verbose=verbose, interval=1)\n    fig, axs = _create_figure(fig=name,\n                              rows=len(channels),\n                              columns=len(order),\n                              flip_rows=False,\n                              sharex=sharex,\n                              sharey=sharey)\n\n    for column, k in enumerate(order):\n        zp = z_mean.copy()\n        zn = z_mean.copy()\n\n        if z_pertub_p is not None:\n            zp[..., k] = z_pertub_p(zp[..., k])\n\n        if z_pertub_n is not None:\n            zn[..., k] = z_pertub_n(zp[..., k])\n\n        # predict\n        yp = decoder.predict([zp] + condition, batch_size=batch_size)\n        yn = decoder.predict([zn] + condition, batch_size=batch_size)\n        yp = yp[:, index, ...][..., channels]\n        yn = yn[:, index, ...][..., channels]\n\n        axs[0, column].set_title(f'$z_{{{k}}}$')\n        bins = np.array(bins)\n        for row in range(len(channels)):\n            yp_pdf, bins = _hist(yp[:, :, row], bins=bins)\n            yn_pdf, bins = _hist(yn[:, :, row], bins=bins)\n            y_pdf = yp_pdf - yn_pdf\n\n            ax = axs[row, column]\n            ax.pcolormesh(x, bins, y_pdf, vmin=vmin, vmax=vmax, cmap=cmap, norm=norm, zorder=1.1)\n            ax.grid(axis='x')\n            if column == 0:\n                if labels is not None:\n                    ax.set_ylabel(labels[row])\n                else:\n                    ax.set_ylabel(channels[row])\n\n        pbar.add(1)\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.encoder_boxplot","title":"VAE.utils.plot.encoder_boxplot","text":"<pre><code>encoder_boxplot(encoder, inputs, plottype='kl', sort=True, batch_size=None, name='Encoder boxplot', verbose=1)\n</code></pre> <p>Boxplot of latent variables from encoder output.</p> <p>If <code>plottype</code> equals to <code>mean</code>, the function creates a boxplot of the latent variable <code>z_mean</code> that correspond to <code>inputs</code> given to the encoder. If <code>plottype</code> equals to <code>var</code>, the function creates a boxplot of the latent variable <code>z_log_var</code>. If <code>plottype</code> equals to <code>kl</code>, the function  creates a boxplot of the KL divergence.</p> <p>Parameters:</p> <ul> <li> <code>encoder</code>         \u2013          <p>class:<code>keras.Model</code> Instance of the encoder model.</p> </li> <li> <code>inputs</code>         \u2013          <p>Numpy array or generator Input to the encoder.</p> </li> <li> <code>plottype</code>         \u2013          <p>str Type of boxplot. One of <code>mean</code>, <code>var</code>, <code>kl</code>.</p> </li> <li> <code>sort</code>         \u2013          <p>bool Plot latent dimension in descending order of mean Kullback-Leibler divergence.</p> </li> <li> <code>name</code>         \u2013          <p>String Name of the figure.</p> </li> </ul> <p>Returns:     tuple:         fig: :class:<code>matplotlib.figure.Figure</code>             The figure instance.         axs: :class:<code>matplotlib.axes.Axes</code>             Axes object.         idx: Sequence             Order of sorted latent dimensions.         kl_loss : 2D Numpy array             Values of the KL divergence corresponding to the input.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def encoder_boxplot(encoder, inputs, plottype='kl', sort=True, batch_size=None, name=\"Encoder boxplot\", verbose=1):\n    \"\"\"Boxplot of latent variables from encoder output.\n\n    If `plottype` equals to `mean`, the function creates a boxplot of the latent variable `z_mean` that correspond\n    to `inputs` given to the encoder. If `plottype` equals to `var`, the function creates a boxplot of the latent\n    variable `z_log_var`. If `plottype` equals to `kl`, the function  creates a boxplot of the KL divergence.\n\n    Parameters:\n        encoder : class:`keras.Model`\n            Instance of the encoder model.\n        inputs : Numpy array or generator\n            Input to the encoder.\n        plottype : str\n            Type of boxplot. One of `mean`, `var`, `kl`.\n        sort : bool\n            Plot latent dimension in descending order of mean Kullback-Leibler divergence.\n        name: String\n            Name of the figure.\n\n     Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: :class:`matplotlib.axes.Axes`\n                Axes object.\n            idx: Sequence\n                Order of sorted latent dimensions.\n            kl_loss : 2D Numpy array\n                Values of the KL divergence corresponding to the input.\n\n    \"\"\"\n    # get latent samples\n    z_mean, z_log_var, *_ = encoder.predict(inputs, verbose=verbose, batch_size=batch_size)\n\n    # z has shape (samples, latent_dim)\n    latent_dim = z_mean.shape[1]\n\n    fig = plt.figure(name)\n    fig.clf()\n    ax = fig.add_subplot(1, 1, 1)\n\n    kl_loss = 1 + z_log_var - np.square(z_mean) - np.exp(z_log_var)\n    kl_loss *= -0.5\n    kl_loss_mean = np.mean(kl_loss, axis=0)\n\n    if sort:\n        idx = np.argsort(kl_loss_mean)\n        idx = idx[::-1]\n    else:\n        idx = np.arange(latent_dim)\n\n    labels = ['{}'.format(i) for i in idx]\n\n    if plottype.lower() == 'mean':\n        variable = z_mean\n        yscale = 'Linear'\n        ylabel = 'Mean'\n    elif plottype.lower() == 'var':\n        variable = np.exp(z_log_var)\n        yscale = 'log'\n        ylabel = 'Variance'\n    elif plottype.lower() == 'kl':\n        variable = kl_loss\n        yscale = 'linear'\n        ylabel = 'KL divergence'\n    else:\n        assert False, \"Unknown option in `plottype` argument.\"\n\n    ax.boxplot(\n        variable[:, idx],\n        showfliers=False,\n        labels=labels,\n        patch_artist=True,\n        showmeans=True,\n        boxprops=dict(facecolor='lightsteelblue'),\n        medianprops=dict(color='tab:blue'),\n        meanprops=dict(markerfacecolor='tab:blue'),\n        zorder=2,\n    )\n\n    ax.set_xlabel('k')\n    ax.set_ylabel(ylabel)\n    ax.set_yscale(yscale)\n    ax.grid(axis='both', linestyle=':')\n\n    return fig, ax, idx, kl_loss\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.encoder_hist","title":"VAE.utils.plot.encoder_hist","text":"<pre><code>encoder_hist(encoder, inputs, latent_sampling=None, bins=30, order=None, show_null=True, batch_size=None, name='Encoder hist', verbose=1)\n</code></pre> <p>Histogram of latent variables from encoder output.</p> <p>The function plots the histogram of the latent variable <code>z_mean</code> that correspond to <code>inputs</code> given to the encoder. If <code>latent_sampling</code> is specified, then the histogram of random samples <code>z</code> from <code>latent_sampling</code> is shown instead.</p> <p>Together with the histogram, the prior distribution is shown as a bold line.</p> <p>Parameters:</p> <ul> <li> <code>encoder</code>         \u2013          <p>class:<code>keras.Model</code> Instance of the encoder model.</p> </li> <li> <code>inputs</code>         \u2013          <p>4D Numpy array Input to the encoder. The first dimension is the batch dimension.</p> </li> <li> <code>latent_sampling</code>         \u2013          <p>class:<code>keras.Model</code> Instance of the latent sampling model. Defaults to <code>None</code>.</p> </li> <li> <code>bins</code>         \u2013          <p>Integer or sequence Number or edges of bins.</p> </li> <li> <code>order</code>         \u2013          <p>Sequence Plotting order of the latent dimensions.</p> </li> <li> <code>show_null</code>         \u2013          <p>boolean Whether to show the null hypothesis of a normal distribution with mean 0 and standard deviation 1.</p> </li> <li> <code>name</code>         \u2013          <p>String Name of the figure.</p> </li> </ul> <p>Returns:     tuple:         fig: :class:<code>matplotlib.figure.Figure</code>             The figure instance.         axs: Array of :class:<code>matplotlib.axes.Axes</code>             Array of axes objects.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def encoder_hist(encoder,\n                 inputs,\n                 latent_sampling=None,\n                 bins=30,\n                 order=None,\n                 show_null=True,\n                 batch_size=None,\n                 name=\"Encoder hist\",\n                 verbose=1):\n    \"\"\"Histogram of latent variables from encoder output.\n\n    The function plots the histogram of the latent variable `z_mean` that correspond to `inputs` given to the encoder.\n    If `latent_sampling` is specified, then the histogram of random samples `z` from `latent_sampling` is shown instead.\n\n    Together with the histogram, the prior distribution is shown as a bold line.\n\n    Parameters:\n        encoder: class:`keras.Model`\n            Instance of the encoder model.\n        inputs: 4D Numpy array\n            Input to the encoder. The first dimension is the batch dimension.\n        latent_sampling : class:`keras.Model`\n            Instance of the latent sampling model. Defaults to `None`.\n        bins: Integer or sequence\n            Number or edges of bins.\n        order: Sequence\n            Plotting order of the latent dimensions.\n        show_null : boolean\n            Whether to show the null hypothesis of a normal distribution with mean 0 and standard deviation 1.\n        name: String\n            Name of the figure.\n\n     Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: Array of :class:`matplotlib.axes.Axes`\n                Array of axes objects.\n\n    \"\"\"\n    # get latent samples\n    z_mean, z_log_var, *_ = encoder.predict(inputs, verbose=verbose, batch_size=batch_size)\n\n    # draw random z\n    if latent_sampling is not None:\n        zs = latent_sampling.predict([z_mean, z_log_var], verbose=verbose, batch_size=batch_size)\n        if zs.ndim == 3:\n            zs = zs[:, 0, :]\n\n    bins = np.array(bins)\n    if bins.size == 1:\n        bins = np.linspace(np.min(z_mean), np.max(z_mean), bins)\n\n    norm_pdf = norm.pdf(bins, 0, 1)\n\n    fig, axs = _create_figure(fig=name, rows=1, columns=len(order))\n\n    for column, column_k in enumerate(order):\n        ax = axs[0, column]\n        if latent_sampling is None:\n            ax.hist(z_mean[:, column_k],\n                    bins=bins,\n                    density=True,\n                    color='red',\n                    histtype='stepfilled',\n                    edgecolor='k',\n                    zorder=2.2)\n        else:\n            ax.hist(zs[:, column_k],\n                    bins=bins,\n                    density=True,\n                    color='tab:cyan',\n                    histtype='stepfilled',\n                    edgecolor='k',\n                    zorder=2.1)\n\n        if show_null:\n            ax.plot(bins, norm_pdf, color='k', zorder=2.3)\n\n        ax.axvline(0, color='k', linewidth=1.25, linestyle=':', zorder=2.2)\n        ax.set_xlabel('$z_{{{}}}$'.format(column_k))\n        ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n\n    xl = np.max(np.abs(ax.get_xlim()))\n    ax.set_xlim([-xl, xl])\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.encoder_hist2d","title":"VAE.utils.plot.encoder_hist2d","text":"<pre><code>encoder_hist2d(encoder, inputs, latent_sampling=None, bins=30, order=None, batch_size=None, cmap=None, norm=None, name='Encoder hist2d', verbose=1)\n</code></pre> <p>Histogram of pairs of latent variables from encoder output.</p> <p>The function creates pariwise histograms of the latent variable <code>z_mean</code> that correspond to <code>inputs</code> given to the encoder. If <code>latent_sampling</code> is specified, then pairwise histograms of random samples <code>z</code> from <code>latent_sampling</code> are shown instead.</p> <p>Parameters:</p> <ul> <li> <code>encoder</code>         \u2013          <p>:class:<code>keras.Model</code> Instance of the encoder model.</p> </li> <li> <code>inputs</code>         \u2013          <p>4D Numpy array Input to the encoder. The first dimension is the batch dimension.</p> </li> <li> <code>latent_sampling</code>         \u2013          <p>class:<code>keras.Model</code> Instance of the latent sampling model. Defaults to <code>None</code>.</p> </li> <li> <code>bins</code>         \u2013          <p>int or sequence Number or edges of bins.</p> </li> <li> <code>order</code>         \u2013          <p>Sequence Plotting order of the latent dimensions.</p> </li> <li> <code>name</code>         \u2013          <p>str Name of the figure.</p> </li> </ul> <p>Returns:     tuple:         fig: :class:<code>matplotlib.figure.Figure</code>             The figure instance.         axs: Array of :class:<code>matplotlib.axes.Axes</code>             Array of axes objects.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def encoder_hist2d(encoder,\n                   inputs,\n                   latent_sampling=None,\n                   bins=30,\n                   order=None,\n                   batch_size=None,\n                   cmap=None,\n                   norm=None,\n                   name=\"Encoder hist2d\",\n                   verbose=1):\n    \"\"\"Histogram of pairs of latent variables from encoder output.\n\n    The function creates pariwise histograms of the latent variable `z_mean` that correspond to ``inputs`` given to the\n    encoder. If `latent_sampling` is specified, then pairwise histograms of random samples `z` from `latent_sampling`\n    are shown instead.\n\n    Parameters:\n        encoder : :class:`keras.Model`\n            Instance of the encoder model.\n        inputs : 4D Numpy array\n            Input to the encoder. The first dimension is the batch dimension.\n        latent_sampling : class:`keras.Model`\n            Instance of the latent sampling model. Defaults to `None`.\n        bins : int or sequence\n            Number or edges of bins.\n        order : Sequence\n            Plotting order of the latent dimensions.\n        name : str\n            Name of the figure.\n\n     Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: Array of :class:`matplotlib.axes.Axes`\n                Array of axes objects.\n\n    \"\"\"\n    # get latent samples\n    z_mean, z_log_var, *_ = encoder.predict(inputs, verbose=verbose, batch_size=batch_size)\n\n    # draw random z\n    if latent_sampling is not None:\n        z = latent_sampling.predict([z_mean, z_log_var], verbose=verbose, batch_size=batch_size)\n        if z.ndim == 3:\n            z = z[:, 0, :]\n\n    # z_mean has shape (samples, latent_dim)\n    latent_dim = z_mean.shape[-1]\n\n    if order is None:\n        order = np.arange(latent_dim)\n\n    limit = np.max(np.abs(z_mean[:, order]))\n    bins = np.array(bins)\n    if bins.size == 1:\n        bins = np.linspace(-limit, limit, bins)\n\n    fig, axs = _create_figure(fig=name, rows=len(order), columns=len(order), sharex=False, sharey=False)\n\n    for row, row_k in enumerate(order):\n        for column, column_k in enumerate(order):\n            ax = axs[row, column]\n\n            if row == column:\n                if latent_sampling is None:\n                    ax.hist(z_mean[:, column_k],\n                            bins=bins,\n                            density=True,\n                            color='red',\n                            histtype='stepfilled',\n                            edgecolor='k')\n                else:\n                    ax.hist(z[:, column_k],\n                            bins=bins,\n                            density=True,\n                            color='tab:cyan',\n                            histtype='stepfilled',\n                            edgecolor='k')\n\n            else:\n                if latent_sampling is None:\n                    ax.hist2d(z_mean[:, column_k], z_mean[:, row_k], bins=bins, density=True, norm=norm, cmap=cmap)\n                else:\n                    ax.hist2d(z[:, column_k], z[:, row_k], bins=bins, density=True, norm=norm, cmap=cmap)\n\n                ax.axhline(0, color='k', zorder=0)\n                ax.axvline(0, color='k', zorder=0)\n                ax.set_xlim([-limit, limit])\n                ax.set_ylim([-limit, limit])\n\n            if row == 0:\n                ax.set_xlabel('$z_{{{}}}$'.format(column_k))\n\n            if column == 0:\n                ax.set_ylabel('$z_{{{}}}$'.format(row_k), rotation=0)\n\n            if row == len(order):\n                z_var = np.median(np.exp(z_log_var[:, column_k]))\n                title = r'$\\sigma_{{{}}}^2={:1.2f}$'.format(column_k, z_var)\n                ax.set_title(title)\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.encoder_scatter","title":"VAE.utils.plot.encoder_scatter","text":"<pre><code>encoder_scatter(encoder, inputs, latent_sampling=None, bins=30, order=None, batch_size=None, name='Encoder scatter', verbose=1)\n</code></pre> <p>Scatter plot of latent variables from encoder output.</p> <p>The function creates pairwise scatter plots of the latent variable <code>z_mean</code> that correspond to <code>inputs</code> given to the encoder. If <code>latent_sampling</code> is specified, then pairwise scatter plots of the random samples <code>z</code> from <code>latent_sampling</code> are likewwise shown.</p> <p>Parameters:</p> <ul> <li> <code>encoder</code>         \u2013          <p>class:<code>ks.Model</code> Instance of the encoder model.</p> </li> <li> <code>inputs</code>         \u2013          <p>4D Numpy array Input to the encoder. The first dimension is the batch dimension.</p> </li> <li> <code>latent_sampling</code>         \u2013          <p>class:<code>keras.Model</code> Instance of the latent sampling model. Defaults to <code>None</code>. bins: Integer or sequence Number or edges of bins of histograms along main diagonal.</p> </li> <li> <code>order</code>         \u2013          <p>Sequence Plotting order of the latent dimensions.</p> </li> <li> <code>name</code>         \u2013          <p>String Name of the figure.</p> </li> </ul> <p>Returns:     tuple:         fig: :class:<code>matplotlib.figure.Figure</code>             The figure instance.         axs: Array of :class:<code>matplotlib.axes.Axes</code>             Array of axes objects.</p> Source code in <code>VAE/utils/plot.py</code> <pre><code>def encoder_scatter(encoder,\n                    inputs,\n                    latent_sampling=None,\n                    bins=30,\n                    order=None,\n                    batch_size=None,\n                    name='Encoder scatter',\n                    verbose=1):\n    \"\"\"Scatter plot of latent variables from encoder output.\n\n    The function creates pairwise scatter plots of the latent variable `z_mean` that correspond to ``inputs`` given to\n    the encoder. If `latent_sampling` is specified, then pairwise scatter plots of the random samples `z` from\n    `latent_sampling` are likewwise shown.\n\n    Parameters:\n        encoder : class:`ks.Model`\n            Instance of the encoder model.\n        inputs : 4D Numpy array\n            Input to the encoder. The first dimension is the batch dimension.\n        latent_sampling : class:`keras.Model`\n            Instance of the latent sampling model. Defaults to `None`.\n         bins: Integer or sequence\n            Number or edges of bins of histograms along main diagonal.\n        order: Sequence\n            Plotting order of the latent dimensions.\n        name: String\n            Name of the figure.\n\n     Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: Array of :class:`matplotlib.axes.Axes`\n                Array of axes objects.\n\n    \"\"\"\n    # get latent samples\n    z_mean, z_log_var, *_ = encoder.predict(inputs, verbose=verbose, batch_size=batch_size)\n\n    # draw random z\n    if latent_sampling is not None:\n        z = latent_sampling.predict([z_mean, z_log_var], verbose=verbose, batch_size=batch_size)\n        if z.ndim == 3:\n            z = z[:, 0, :]\n\n    # z has shape (samples, latent_dim)\n    latent_dim = z_mean.shape[1]\n\n    limit = np.max(np.abs(z_mean))\n    bins = np.array(bins)\n    if bins.size == 1:\n        bins = np.linspace(-limit, limit, bins)\n\n    if order is None:\n        order = np.arange(latent_dim)\n\n    fig, axs = _create_figure(fig=name, rows=len(order), columns=len(order), sharex=False, sharey=False)\n\n    for row, row_k in enumerate(order):\n        for column, column_k in enumerate(order):\n            ax = axs[row, column]\n\n            if row == column:\n                if latent_sampling is None:\n                    ax.hist(z_mean[:, column_k],\n                            bins=bins,\n                            density=True,\n                            color='tab:red',\n                            histtype='stepfilled',\n                            edgecolor='k')\n                else:\n                    ax.hist(z[:, column_k],\n                            bins=bins,\n                            density=True,\n                            color='tab:cyan',\n                            histtype='stepfilled',\n                            edgecolor='k')\n\n            else:\n                if latent_sampling is not None:\n                    ax.plot(z[:, column_k], z[:, row_k], '.', color='tab:cyan', markersize=3, zorder=1)\n\n                ax.plot(z_mean[:, column_k], z_mean[:, row_k], '.', color='tab:red', markersize=3, zorder=1.2)\n                ax.axhline(0, color='k', zorder=1.1)\n                ax.set_ylim([-limit, limit])\n\n            ax.set_xlim([-limit, limit])\n            ax.axvline(0, color='k', zorder=0)\n\n            if row == 0:\n                ax.set_xlabel('$z_{{{}}}$'.format(column_k))\n\n            if column == 0:\n                ax.set_ylabel('$z_{{{}}}$'.format(row_k), rotation=0)\n\n            if row == len(order):\n                z_var = np.median(np.exp(z_log_var[:, column_k]))\n                title = r'$\\sigma_{{{}}}^2={:1.2f}$'.format(column_k, z_var)\n                ax.set_title(title)\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.map_plot","title":"VAE.utils.plot.map_plot","text":"<pre><code>map_plot(latitude, longitude, map_data, labels=None, ncols=1, vmin=None, vmax=None, projection=ccrs.PlateCarree(), coastlinespec_kw=None, colorbar_kw=None, gridlinespec_kw=None, gridspec_kw=None, landspec_kw=None, figwidth=None, **kwargs)\n</code></pre> <p>Plot a sequence of maps.</p> <p>The function creates a map for each entry in <code>map_data</code>.</p> <p>Parameters:</p> <ul> <li> <code>latitude</code>         \u2013          <p>Numpy array Latitude coordinate corresponding to the leading dimension of the maps.</p> </li> <li> <code>longitude</code>         \u2013          <p>Numpy array Longitude coordinate corresponding to the second dimension of the maps.</p> </li> <li> <code>map_data</code>         \u2013          <p>dict or sequence of ndarray Dictionary or sequence of 2D map data. Can also be a 3D array.</p> </li> <li> <code>labels</code>         \u2013          <p>List of str List of labels for the sequence of the map data. Length must match the length of map_data.</p> </li> <li> <code>ncols</code>         \u2013          <p>int Number of columns in which the subplots will be arranged.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments passed to the plotting function.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>fig : Figure object. axs : Array of axes objects. cb :  Colorbar object.</p> </li> </ul> Source code in <code>VAE/utils/plot.py</code> <pre><code>def map_plot(latitude,\n             longitude,\n             map_data,\n             labels=None,\n             ncols=1,\n             vmin=None,\n             vmax=None,\n             projection=ccrs.PlateCarree(),\n             coastlinespec_kw=None,\n             colorbar_kw=None,\n             gridlinespec_kw=None,\n             gridspec_kw=None,\n             landspec_kw=None,\n             figwidth=None,\n             **kwargs):\n    \"\"\"Plot a sequence of maps.\n\n    The function creates a map for each entry in `map_data`.\n\n    Parameters:\n        latitude : Numpy array\n            Latitude coordinate corresponding to the leading dimension of the maps.\n        longitude : Numpy array\n            Longitude coordinate corresponding to the second dimension of the maps.\n        map_data : dict or sequence of ndarray\n            Dictionary or sequence of 2D map data. Can also be a 3D array.\n        labels : List of str\n            List of labels for the sequence of the map data. Length must match the length of map_data.\n        ncols : int\n            Number of columns in which the subplots will be arranged.\n\n        **kwargs :\n            Additional keyword arguments passed to the plotting function.\n\n    Returns:\n        tuple:\n            fig : Figure object.\n            axs : Array of axes objects.\n            cb :  Colorbar object.\n\n    \"\"\"\n    map_data, labels = _map_to_dict(map_data, labels)\n    nrows = -(-len(map_data) // ncols)  # ceil\n\n    coastlinespec_kw = coastlinespec_kw or {'color': 'k', 'alpha': 1, 'linewidth': 1}\n    colorbar_kw = colorbar_kw or {'shrink': 0.7 / nrows, 'pad': 0.01, 'aspect': 40 / nrows, 'extend': 'both'}\n    gridspec_kw = gridspec_kw or {'wspace': 0.05, 'hspace': 0.25}\n    gridlinespec_kw = gridlinespec_kw or {'draw_labels': True, 'linestyle': ':'}\n\n    subplot_kw = dict(projection=projection)\n    fig, axs = plt.subplots(nrows, ncols, subplot_kw=subplot_kw, gridspec_kw=gridspec_kw, squeeze=False)\n\n    if (vmin is None) and ('norm' not in kwargs):\n        vmin = np.nanmin([np.nanmin(value) for value in map_data.values()])\n\n    if (vmax is None) and ('norm' not in kwargs):\n        vmax = np.nanmax([np.nanmax(value) for value in map_data.values()])\n\n    for ax, label, value in zip(axs.flat, labels, map_data.values()):\n        value_cyclic, longitude_cyclic = add_cyclic_point(value, coord=longitude)\n        im = ax.pcolormesh(longitude_cyclic,\n                           latitude,\n                           value_cyclic,\n                           vmin=vmin,\n                           vmax=vmax,\n                           shading='nearest',\n                           transform=ccrs.PlateCarree(),\n                           **kwargs)\n        gl = ax.gridlines(**gridlinespec_kw)\n        gl.top_labels = False\n        gl.right_labels = False\n        if ax not in axs[:, 0]:\n            gl.left_labels = False\n\n        if ax not in axs[-1, :]:\n            gl.bottom_labels = False\n\n        ax.coastlines(**coastlinespec_kw)\n        if landspec_kw is not None:\n            ax.add_feature(cfeature.LAND, **landspec_kw)\n        ax.set_title(label)\n\n    if figwidth:\n        _set_figure_size(fig, axs, figwidth)\n\n    for ax in axs.flat[len(map_data):]:\n        fig.delaxes(ax)\n\n    if len(map_data) == axs.size:\n        cb = fig.colorbar(im, ax=axs, **colorbar_kw)\n    else:\n        pad = colorbar_kw.get('pad', 0.05)\n        if colorbar_kw.get('orientation', 'vertical').lower() == 'vertical':\n            cb = fig.colorbar(im, ax=axs[-1, :], **{**colorbar_kw, 'pad': pad - 1 / ncols})\n        else:\n            cb = fig.colorbar(im, ax=axs[:, -1], **{**colorbar_kw, 'pad': pad - 1 / nrows})\n\n    return fig, axs, cb\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.map_zonal","title":"VAE.utils.plot.map_zonal","text":"<pre><code>map_zonal(datetime, latitude, longitude, map_data, lon_lim=(-180, 180), labels=None, cmap='seismic', norm=None, vmin=None, vmax=None, figsize=None)\n</code></pre> <p>Plot a sequencde of zonal averages.</p> <p>The function plots the zonal average for each entry in <code>map_data</code>.</p> <p>Parameters:</p> <ul> <li> <code>datetime</code>         \u2013          <p>datetime Datetime corresponding to the leading dimension in the entries of <code>map_data</code>.</p> </li> <li> <code>latitude</code>         \u2013          <p>Numpy array Latitude coordinate corresponding to the second dimension in the entries of <code>map_data</code>.</p> </li> <li> <code>longitude</code>         \u2013          <p>Numpy array Longitude coordinate corresponding to the third dimension in the entries of <code>map_data</code>.</p> </li> <li> <code>map_data</code>         \u2013          <p>dict or sequence of ndarray Dictionary or sequence of 2D map data. Can also be a 3D array.</p> </li> <li> <code>lon_lim</code>         \u2013          <p>tuple of two float Longitude limits in which the zonal average is obtained.</p> </li> <li> <code>labels</code>         \u2013          <p>List of str List of labels . Must match the length of map_data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>fig: :class:<code>matplotlib.figure.Figure</code>     The figure instance. axs: Array of :class:<code>matplotlib.axes.Axes</code>     Array of axes objects.</p> </li> </ul> Source code in <code>VAE/utils/plot.py</code> <pre><code>def map_zonal(datetime,\n              latitude,\n              longitude,\n              map_data,\n              lon_lim=(-180, 180),\n              labels=None,\n              cmap='seismic',\n              norm=None,\n              vmin=None,\n              vmax=None,\n              figsize=None):\n    \"\"\"Plot a sequencde of zonal averages.\n\n    The function plots the zonal average for each entry in `map_data`.\n\n    Parameters:\n        datetime: datetime\n            Datetime corresponding to the leading dimension in the entries of `map_data`.\n        latitude : Numpy array\n            Latitude coordinate corresponding to the second dimension in the entries of `map_data`.\n        longitude : Numpy array\n            Longitude coordinate corresponding to the third dimension in the entries of `map_data`.\n        map_data : dict or sequence of ndarray\n            Dictionary or sequence of 2D map data. Can also be a 3D array.\n        lon_lim : tuple of two float\n            Longitude limits in which the zonal average is obtained.\n        labels : List of str\n            List of labels . Must match the length of map_data.\n\n    Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: Array of :class:`matplotlib.axes.Axes`\n                Array of axes objects.\n\n    \"\"\"\n    map_data, labels = _map_to_dict(map_data, labels)\n\n    minimum, maximum = lon_lim\n    minimum = np.deg2rad(minimum) % (2 * np.pi)\n    maximum = np.deg2rad(maximum) % (2 * np.pi)\n    lon = np.deg2rad(longitude) % (2 * np.pi)\n\n    if minimum &lt; maximum:\n        lon_idx = np.flatnonzero(np.logical_and(minimum &lt;= lon, lon &lt;= maximum))\n    elif minimum &gt;= maximum:\n        lon_idx = np.flatnonzero(np.logical_or(minimum &lt;= lon, lon &lt;= maximum))\n\n    nrows = len(map_data)\n    fig, axs = plt.subplots(nrows, 1, squeeze=True, sharex=True, sharey=True, figsize=figsize)\n    lon_fmt = cticker.LongitudeFormatter()\n\n    for ax, label, value in zip(axs.flat, labels, map_data.values()):\n        zonal_mean = np.nansum(value[:, :, lon_idx], axis=-1) / len(lon_idx)\n        if vmax is None and vmin is None:\n            vmax = np.nanpercentile(np.abs(zonal_mean), 99)\n            vmin = -vmax\n\n        any_isfinite = np.any(np.isfinite(value), axis=(1, 2))\n        any_isfinite = np.flatnonzero(any_isfinite)\n        sl = slice(any_isfinite[0], any_isfinite[-1])\n\n        im = ax.pcolormesh(datetime[sl],\n                           latitude,\n                           zonal_mean[sl, :].T,\n                           shading='nearest',\n                           cmap=cmap,\n                           norm=norm,\n                           vmin=vmin,\n                           vmax=vmax)\n\n        ax.set_title('{} ({}\\u2013{})'.format(label, *[lon_fmt._format_value(lon, None) for lon in lon_lim]))\n        ax.grid(which='major', axis='both')\n        ax.grid(which='minor', axis='x', linestyle=':')\n        fig.colorbar(im, ax=ax, pad=0.01, fraction=0.05, shrink=0.9 / min(nrows, 3))\n\n    ax.xaxis.set_major_locator(dates.YearLocator(5))\n    ax.xaxis.set_minor_locator(dates.YearLocator(1))\n    ax.xaxis.set_major_formatter(dates.DateFormatter('%Y'))\n    ax.yaxis.set_major_locator(cticker.LatitudeLocator())\n    ax.yaxis.set_major_formatter(cticker.LatitudeFormatter())\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.plot/#VAE.utils.plot.map_meridional","title":"VAE.utils.plot.map_meridional","text":"<pre><code>map_meridional(datetime, latitude, longitude, map_data, lat_lim=(-90, 90), labels=None, cmap='seismic', norm=None, vmin=None, vmax=None, figsize=None)\n</code></pre> <p>Plot a sequence of meridional averages.</p> <p>The function plots the meridional average for each entry in <code>map_data</code>.</p> <p>Parameters:</p> <ul> <li> <code>datetime</code>         \u2013          <p>datetime Datetime corresponding to the leading dimension in the entries of <code>map_data</code>.</p> </li> <li> <code>latitude</code>         \u2013          <p>Numpy array Latitude coordinate corresponding to the second dimension in the entries of <code>map_data</code>.</p> </li> <li> <code>longitude</code>         \u2013          <p>Numpy array Longitude coordinate corresponding to the third dimension in the entries of <code>map_data</code>.</p> </li> <li> <code>map_data</code>         \u2013          <p>dict or sequence of ndarray Dictionary or sequence of 2D map data. Can also be a 3D array.</p> </li> <li> <code>lat_lim</code>         \u2013          <p>tuple of two float Latitude limits in which the meridional average is obtained.</p> </li> <li> <code>labels</code>         \u2013          <p>List of str List of labels . Must match the length of map_data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>fig: :class:<code>matplotlib.figure.Figure</code>     The figure instance. axs: Array of :class:<code>matplotlib.axes.Axes</code>     Array of axes objects.</p> </li> </ul> Source code in <code>VAE/utils/plot.py</code> <pre><code>def map_meridional(datetime,\n                   latitude,\n                   longitude,\n                   map_data,\n                   lat_lim=(-90, 90),\n                   labels=None,\n                   cmap='seismic',\n                   norm=None,\n                   vmin=None,\n                   vmax=None,\n                   figsize=None):\n    \"\"\"Plot a sequence of meridional averages.\n\n    The function plots the meridional average for each entry in `map_data`.\n\n    Parameters:\n        datetime: datetime\n            Datetime corresponding to the leading dimension in the entries of `map_data`.\n        latitude : Numpy array\n            Latitude coordinate corresponding to the second dimension in the entries of `map_data`.\n        longitude : Numpy array\n            Longitude coordinate corresponding to the third dimension in the entries of `map_data`.\n        map_data : dict or sequence of ndarray\n            Dictionary or sequence of 2D map data. Can also be a 3D array.\n        lat_lim : tuple of two float\n            Latitude limits in which the meridional average is obtained.\n        labels : List of str\n            List of labels . Must match the length of map_data.\n\n    Returns:\n        tuple:\n            fig: :class:`matplotlib.figure.Figure`\n                The figure instance.\n            axs: Array of :class:`matplotlib.axes.Axes`\n                Array of axes objects.\n\n    \"\"\"\n    map_data, labels = _map_to_dict(map_data, labels)\n\n    minimum, maximum = lat_lim\n    lat_idx = np.flatnonzero(np.logical_and(minimum &lt;= latitude, latitude &lt;= maximum))\n\n    longitude_wrap = longitude.copy()\n    longitude_wrap[longitude_wrap &gt; 180] -= 360\n    lon_idx = np.argsort(longitude_wrap)\n\n    nrows = len(map_data)\n    fig, axs = plt.subplots(nrows, 1, squeeze=True, sharex=True, sharey=True, figsize=figsize)\n    lat_fmt = cticker.LatitudeFormatter()\n\n    for ax, label, value in zip(axs.flat, labels, map_data.values()):\n        meridional_mean = np.nansum(value[:, lat_idx, :], axis=1) / len(lat_idx)\n        if vmax is None and vmin is None:\n            vmax = np.nanpercentile(np.abs(meridional_mean), 99)\n            vmin = -vmax\n\n        any_isfinite = np.any(np.isfinite(value), axis=(1, 2))\n        any_isfinite = np.flatnonzero(any_isfinite)\n        sl = slice(any_isfinite[0], any_isfinite[-1])\n\n        im = ax.pcolormesh(datetime[sl],\n                           longitude_wrap[lon_idx],\n                           meridional_mean[sl, lon_idx].T,\n                           shading='nearest',\n                           cmap=cmap,\n                           norm=norm,\n                           vmin=vmin,\n                           vmax=vmax)\n\n        ax.set_title('{} ({}\\u2013{})'.format(label, *[lat_fmt._format_value(lat, None) for lat in lat_lim]))\n        ax.grid(which='major', axis='both')\n        ax.grid(which='minor', axis='x', linestyle=':')\n        fig.colorbar(im, ax=ax, pad=0.01, fraction=0.05, shrink=0.9 / min(nrows, 3))\n\n    ax.xaxis.set_major_locator(dates.YearLocator(5))\n    ax.xaxis.set_minor_locator(dates.YearLocator(1))\n    ax.xaxis.set_major_formatter(dates.DateFormatter('%Y'))\n    ax.yaxis.set_major_locator(cticker.LongitudeLocator())\n    ax.yaxis.set_major_formatter(cticker.LongitudeFormatter())\n\n    return fig, axs\n</code></pre>"},{"location":"VAE.utils.yaml_to_xlsx/","title":"VAE.utils.yaml to xlsx","text":""},{"location":"VAE.utils.yaml_to_xlsx/#VAE.utils.yaml_to_xlsx","title":"VAE.utils.yaml_to_xlsx","text":"<p>Collect configurations in Excel file.</p>"},{"location":"example_VAE/","title":"Example of a VAE model","text":"<p>:paperclip: You can find the full code for this example in a Jupyter notebook.</p> <p>This example demonstrates how to build a VAE model using the method <code>VAE.models.VAE</code>.</p> <pre><code>from tensorflow.keras.utils import plot_model\n\nfrom VAE.models import Encoder, LatentSampling, Decoder, VAE\nfrom VAE.utils import collection\n</code></pre> <p>We first define the parameters of the model:</p> <pre><code>params = {\n    'encoder_blocks': 1,\n    'cond_size': 12,\n    'fc_units': 48,\n    'filters': 16,\n    'input_shape': [16, 7],\n    'latent_dim': 10,\n    'trainable': ['*bn*'],\n}\n</code></pre> <p>Then we build the different parts of the model. We start with the encoder:</p> <pre><code>encoder = Encoder(**params, name='encoder')\n</code></pre> <p>and the latent sampling layer:</p> <pre><code>latent_sampling = LatentSampling(**params, name='latent')\n</code></pre> <p>and finally the decoder:</p> <pre><code>decoder = Decoder(output_shape=params['input_shape'],\n                  decoder_blocks=params['encoder_blocks'],\n                  output_reverse=True,\n                  **params,\n                  name='decoder')\n</code></pre> <p>Once we have the different parts of the model, we can build the full model:</p> <pre><code>model = VAE(encoder, decoder, latent_sampling, **params, name='VAE')\n</code></pre> <p>Let's have a look at the model:</p> <pre><code>model.summary()\n</code></pre> <pre><code>Model: \"VAE\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to\n==================================================================================================\nencoder_input (InputLayer)      [(None, 1, 16, 7)]   0\n__________________________________________________________________________________________________\nencoder_cond (InputLayer)       [(None, 1, 12)]      0\n__________________________________________________________________________________________________\nencoder (Functional)            [(None, 10), (None,  16496       encoder_input[0][0]\n                                                                 encoder_cond[0][0]\n__________________________________________________________________________________________________\nlatent (Functional)             (None, 1, 10)        0           encoder[0][0]\n                                                                 encoder[0][1]\n__________________________________________________________________________________________________\ndecoder_cond (InputLayer)       [(None, 1, 12)]      0\n__________________________________________________________________________________________________\ndecoder (Functional)            (None, 1, 16, 7)     16243       latent[0][0]\n                                                                 decoder_cond[0][0]\n==================================================================================================\nTotal params: 32,739\nTrainable params: 156\nNon-trainable params: 32,583\n__________________________________________________________________________________________________\n</code></pre> <p>We can also have a look at the trainable parameters:</p> <pre><code>collection.summary_trainable(model)\n</code></pre> <pre><code>________________________________________________________________________________\nLayer                                    Type                           # params\n================================================================================\nVAE                                      Functional                          156\n________________________________________________________________________________\n  encoder                                Functional                           78\n    encoder_input_bn                     BatchNormalization                   14\n    encoder_block_1                      Functional                           64\n      encoder_block_1_R1_bn1             BatchNormalization                   32\n      encoder_block_1_R1_bn2             BatchNormalization                   32\n________________________________________________________________________________\n  decoder                                Functional                           78\n    decoder_block_1                      Functional                           64\n      decoder_block_1_R1_bn1             BatchNormalization                   32\n      decoder_block_1_R1_bn2             BatchNormalization                   32\n    decoder_output_bn                    BatchNormalization                   14\n________________________________________________________________________________\n</code></pre> <p>and plot the model:</p> <pre><code>plot_model(model, show_shapes=True, dpi=75, rankdir='LR')\n</code></pre> <p></p>"},{"location":"example_VAEp/","title":"Example of a VAEp model with prediction","text":"<p>:paperclip: You can find the full code for this example in a Jupyter notebook.</p> <p>This example demonstrates how to build a VAEp model with prediction using the method <code>VAE.models.VAEp</code>.</p> <pre><code>from tensorflow.keras.utils import plot_model\n\nfrom VAE.models import Encoder, LatentSampling, Decoder, VAEp\nfrom VAE.utils import collection\n</code></pre> <p>We first define the parameters of the model:</p> <pre><code>params = {\n    'encoder_blocks': 1,\n    'cond_size': 12,\n    'fc_units': 48,\n    'filters': 16,\n    'input_shape': [16, 7],\n    'latent_dim': 10,\n    'trainable': ['*bn*'],\n    'prediction_shape': [16, 1],\n}\n</code></pre> <p>Then we build the different parts of the model. We start with the encoder:</p> <pre><code>encoder = Encoder(**params, name='encoder')\n</code></pre> <p>and the latent sampling layer:</p> <pre><code>latent_sampling = LatentSampling(**params, name='latent')\n</code></pre> <p>Then we build the decoder:</p> <pre><code>decoder = Decoder(output_shape=params['input_shape'],\n                  decoder_blocks=params['encoder_blocks'],\n                  output_reverse=True,\n                  **params,\n                  name='decoder')\n</code></pre> <p>and a second decoder for the prediction:</p> <pre><code>prediction = Decoder(output_shape=params['prediction_shape'],\n                     decoder_blocks=params['encoder_blocks'],\n                     output_reverse=False,\n                     **params,\n                     name='prediction')\n</code></pre> <p>Once we have the different parts of the model, we can build the full model:</p> <pre><code>model = VAEp(encoder, decoder, latent_sampling, prediction, **params, name='VAEp')\n</code></pre> <p>Let's have a look at the model:</p> <pre><code>model.summary()\n</code></pre> <pre><code>Model: \"VAEp\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to\n==================================================================================================\nencoder_input (InputLayer)      [(None, 1, 16, 7)]   0\n__________________________________________________________________________________________________\nencoder_cond (InputLayer)       [(None, 1, 12)]      0\n__________________________________________________________________________________________________\nencoder (Functional)            [(None, 10), (None,  16496       encoder_input[0][0]\n                                                                 encoder_cond[0][0]\n__________________________________________________________________________________________________\nlatent (Functional)             (None, 1, 10)        0           encoder[0][0]\n                                                                 encoder[0][1]\n__________________________________________________________________________________________________\ndecoder_cond (InputLayer)       [(None, 1, 12)]      0\n__________________________________________________________________________________________________\nprediction_cond (InputLayer)    [(None, 1, 12)]      0\n__________________________________________________________________________________________________\ndecoder (Functional)            (None, 1, 16, 7)     16243       latent[0][0]\n                                                                 decoder_cond[0][0]\n__________________________________________________________________________________________________\nprediction (Functional)         (None, 1, 16, 1)     16117       latent[0][0]\n                                                                 prediction_cond[0][0]\n==================================================================================================\nTotal params: 48,856\nTrainable params: 222\nNon-trainable params: 48,634\n__________________________________________________________________________________________________\n</code></pre> <p>We can also have a look at the trainable parameters:</p> <pre><code>collection.summary_trainable(model)\n</code></pre> <pre><code>________________________________________________________________________________\nLayer                                    Type                           # params\n================================================================================\nVAEp                                     Functional                          222\n________________________________________________________________________________\n  encoder                                Functional                           78\n    encoder_input_bn                     BatchNormalization                   14\n    encoder_block_1                      Functional                           64\n      encoder_block_1_R1_bn1             BatchNormalization                   32\n      encoder_block_1_R1_bn2             BatchNormalization                   32\n________________________________________________________________________________\n  decoder                                Functional                           78\n    decoder_block_1                      Functional                           64\n      decoder_block_1_R1_bn1             BatchNormalization                   32\n      decoder_block_1_R1_bn2             BatchNormalization                   32\n    decoder_output_bn                    BatchNormalization                   14\n________________________________________________________________________________\n  prediction                             Functional                           66\n    prediction_block_1                   Functional                           64\n      prediction_block_1_R1_bn1          BatchNormalization                   32\n      prediction_block_1_R1_bn2          BatchNormalization                   32\n    prediction_output_bn                 BatchNormalization                    2\n________________________________________________________________________________\n</code></pre> <p>and plot the model:</p> <pre><code>plot_model(model, show_shapes=True, dpi=75, rankdir='LR')\n</code></pre> <p></p>"},{"location":"examples/","title":"Examples","text":"<p>This page collects examples included in the different modules of the VAE project.</p>"},{"location":"examples/#models","title":"Models","text":""},{"location":"examples/#VAE.models.example_VAE","title":"VAE.models.example_VAE","text":"<pre><code>example_VAE()\n</code></pre> <p>Example of a VAE model.</p> <p>This function demonstrates how to build a VAE model using the method :func:<code>VAE.models.VAE</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def example_VAE():\n    \"\"\"Example of a VAE model.\n\n    This function demonstrates how to build a VAE model using the method :func:`VAE.models.VAE`.\n    \"\"\"\n\n    # We first define the parameters of the model:\n    params = {\n        'encoder_blocks': 1,\n        'cond_size': 12,\n        'fc_units': 48,\n        'filters': 16,\n        'input_shape': [16, 7],\n        'latent_dim': 10,\n        'trainable': ['*bn*'],\n    }\n\n    # Then we build the different parts of the model. We start with the encoder:\n    encoder = Encoder(**params, name='encoder')\n\n    # and the latent sampling layer:\n    latent_sampling = LatentSampling(**params, name='latent')\n\n    # and finally the decoder:\n    decoder = Decoder(output_shape=params['input_shape'],\n                      decoder_blocks=params['encoder_blocks'],\n                      output_reverse=True,\n                      **params,\n                      name='decoder')\n\n    # Once we have the different parts of the model, we can build the full model:\n    model = VAE(encoder, decoder, latent_sampling, **params, name='VAE')\n\n    # Let's have a look at the model:\n    model.summary()\n\n    # We can also have a look at the trainable parameters:\n    collection.summary_trainable(model)\n\n    # and plot the model:\n    ks.utils.plot_model(model, show_shapes=True, dpi=75, rankdir='LR', to_file='example_VAE.png')\n\n    return model\n</code></pre>"},{"location":"examples/#VAE.models.example_VAEp","title":"VAE.models.example_VAEp","text":"<pre><code>example_VAEp()\n</code></pre> <p>Example of a VAEp model.</p> <p>This function demonstrates how to build a VAEp model using the method :func:<code>VAE.models.VAEp</code>.</p> Source code in <code>VAE/models.py</code> <pre><code>def example_VAEp():\n    \"\"\"Example of a VAEp model.\n\n    This function demonstrates how to build a VAEp model using the method :func:`VAE.models.VAEp`.\n    \"\"\"\n\n    # We first define the parameters of the model:\n    params = {\n        'encoder_blocks': 1,\n        'cond_size': 12,\n        'fc_units': 48,\n        'filters': 16,\n        'input_shape': [16, 7],\n        'latent_dim': 10,\n        'trainable': ['*bn*'],\n        'prediction_shape': [16, 1],\n    }\n\n    # Then we build the different parts of the model. We start with the encoder:\n    encoder = Encoder(**params, name='encoder')\n\n    # and the latent sampling layer:\n    latent_sampling = LatentSampling(**params, name='latent')\n\n    # Then we build the decoder:\n    decoder = Decoder(output_shape=params['input_shape'],\n                      decoder_blocks=params['encoder_blocks'],\n                      output_reverse=True,\n                      **params,\n                      name='decoder')\n\n    # and a second decoder for the prediction:\n    prediction = Decoder(output_shape=params['prediction_shape'],\n                         decoder_blocks=params['encoder_blocks'],\n                         output_reverse=False,\n                         **params,\n                         name='prediction')\n\n    # Once we have the different parts of the model, we can build the full model:\n    model = VAEp(encoder, decoder, latent_sampling, prediction, **params, name='VAEp')\n\n    # Let's have a look at the model:\n    model.summary()\n\n    # We can also have a look at the trainable parameters:\n    collection.summary_trainable(model)\n\n    # and plot the model:\n    ks.utils.plot_model(model, show_shapes=True, dpi=75, rankdir='LR', to_file='example_VAEp.png')\n\n    return model\n</code></pre>"},{"location":"examples/#layers","title":"Layers","text":""},{"location":"examples/#VAE.layers.example_Film","title":"VAE.layers.example_Film","text":"<pre><code>example_Film()\n</code></pre> <p>Example of Film layer.</p> Source code in <code>VAE/layers.py</code> <pre><code>def example_Film():\n    \"\"\"Example of Film layer.\"\"\"\n    input_shape = (1, 16, 12)\n    cond_shape = (10, )\n    x = tf.constant(1., shape=(32, ) + input_shape)\n    c = tf.constant(1., shape=(32, ) + cond_shape)\n    x_in = ks.layers.Input(shape=input_shape)\n    cond_in = ks.layers.Input(shape=cond_shape)\n    out = Film(\n        use_scale=True,\n        use_offset=True,\n        use_bias=True,\n        shape=(1, None, None),\n    )([x_in, cond_in])\n    model = ks.Model(inputs=[x_in, cond_in], outputs=out)\n    model.summary()\n    _ = model.predict([x, c])\n    for w in model.weights:\n        print(w.name, ':', w.shape)\n</code></pre>"},{"location":"examples/#VAE.layers.example_GumbelSoftmax","title":"VAE.layers.example_GumbelSoftmax","text":"<pre><code>example_GumbelSoftmax()\n</code></pre> <p>Example of GumbelSoftmax layer.</p> Source code in <code>VAE/layers.py</code> <pre><code>def example_GumbelSoftmax():\n    \"\"\"Example of GumbelSoftmax layer.\"\"\"\n    input_shape = (5, 4)\n    x = tf.zeros((2, ) + input_shape)\n    x_in = ks.layers.Input(shape=input_shape)\n    out = GumbelSoftmax(axis=-1, hard=True, noise_shape=(None, 1, None))(x_in)\n    model = ks.Model(inputs=x_in, outputs=out)\n    y = model.predict(x)\n    print(y)\n</code></pre>"},{"location":"examples/#VAE.layers.example_RandomSampling","title":"VAE.layers.example_RandomSampling","text":"<pre><code>example_RandomSampling()\n</code></pre> <p>Example of RandomSampling layer.</p> Source code in <code>VAE/layers.py</code> <pre><code>def example_RandomSampling():\n    \"\"\"Example of RandomSampling layer.\"\"\"\n    input_shape = (5, 4)\n    z_mean = tf.zeros((2, ) + input_shape)\n    z_log_var = tf.zeros((2, ) + input_shape)\n    z_mean_in = ks.layers.Input(shape=input_shape)\n    z_log_var_in = ks.layers.Input(shape=input_shape)\n    out = RandomSampling(noise_shape=(None, 1, None))([z_mean_in, z_log_var_in])\n    model = ks.Model(inputs=[z_mean_in, z_log_var_in], outputs=out)\n    z = model.predict([z_mean, z_log_var])\n    print(z)\n</code></pre>"},{"location":"examples/#losses","title":"Losses","text":""},{"location":"examples/#VAE.losses.example_total_correlation_losses","title":"VAE.losses.example_total_correlation_losses","text":"<pre><code>example_total_correlation_losses()\n</code></pre> <p>Example of total correlation loss functions.</p> Source code in <code>VAE/losses.py</code> <pre><code>def example_total_correlation_losses():\n    \"\"\"Example of total correlation loss functions.\"\"\"\n    batch_size = 32\n    repeat_samples = 20\n    shape = (batch_size * repeat_samples, 8)\n    set_size = 7\n\n    z_mean = tf.random.normal(shape)\n    z_log_var = tf.random.normal(shape) * 0.1 - 1.\n    z = z_mean + tf.exp(z_log_var * 0.5) * tf.random.normal(shape)\n    z = tf.expand_dims(z, axis=1)\n    z = tf.repeat(z, repeats=set_size, axis=1)\n\n    fcns = {\n        'TC loss': TotalCorrelation(z, z_mean, z_log_var),\n        'TC loss between': TotalCorrelationBetween(z, z_mean, z_log_var, repeat_samples=repeat_samples),\n        'TC loss within': TotalCorrelationWithin(z, z_mean, z_log_var, repeat_samples=repeat_samples),\n    }\n\n    print(f'{\"Batch size\":&lt;20} {batch_size} * {repeat_samples} = {batch_size * repeat_samples}')\n\n    for name, fcn in fcns.items():\n        tc_loss = fcn(None, None)\n        tc_mean = tf.reduce_mean(tc_loss)\n        tc_std = tf.math.reduce_std(tc_loss)\n        print(f'{name:&lt;20} mean={tc_mean:.2f}  std={tc_std:.2f}  shape={tc_loss.shape}')\n</code></pre>"},{"location":"examples/#VAE.losses.example_similarity_losses","title":"VAE.losses.example_similarity_losses","text":"<pre><code>example_similarity_losses()\n</code></pre> <p>Example of similarity loss functions.</p> Source code in <code>VAE/losses.py</code> <pre><code>def example_similarity_losses():\n    \"\"\"Example of similarity loss functions.\"\"\"\n    batch_size = 32\n    repeat_samples = 5\n    shape = (batch_size * repeat_samples, 1, 160, 3)\n\n    inputs = tf.random.normal(shape)\n\n    fcns = {\n        'Sim loss': Similarity(),\n        'Sim loss between': _SimilarityBetween(repeat_samples=repeat_samples),\n        'Sim loss between (fast)': SimilarityBetween(repeat_samples=repeat_samples),\n    }\n\n    print(f'{\"Batch size\":&lt;25} {batch_size} * {repeat_samples} = {batch_size * repeat_samples}')\n\n    losses = []\n    for name, fcn in fcns.items():\n        loss = fcn(None, inputs)\n        losses.append(loss)\n        mean_loss = tf.reduce_mean(loss)\n        std_loss = tf.math.reduce_std(loss)\n        print(f'{name:&lt;25} mean={mean_loss:.2f}  std={std_loss:.2f}  shape={loss.shape}')\n\n    return losses\n</code></pre>"},{"location":"examples/#generators","title":"Generators","text":""},{"location":"examples/#VAE.generators.example_FitGenerator","title":"VAE.generators.example_FitGenerator","text":"<pre><code>example_FitGenerator()\n</code></pre> <p>Example of :class:<code>FitGenerator</code>.</p> <p>This example shows how to use the :class:<code>FitGenerator</code> class.</p> Source code in <code>VAE/generators.py</code> <pre><code>def example_FitGenerator():\n    \"\"\"Example of :class:`FitGenerator`.\n\n    This example shows how to use the :class:`FitGenerator` class.\n\n    \"\"\"\n\n    # first we create some dummy data\n    shape = (1, 32, 3)  # (set_size, data_length, channels)\n    dataset = np.reshape(np.arange(np.prod(shape)), shape)\n    datasets = [dataset] * 3\n\n    # the corresponding time values\n    time = range(shape[1])\n\n    # and the corresponding conditions\n    # the encoder and decoder conditions are different\n    encoder_cond = np.linspace(-1, 1, 32)\n    decoder_cond = np.linspace(1, -1, 32)\n\n    # then we create the generator\n    fit_gen = FitGenerator(datasets,\n                           condition={\n                               'encoder': encoder_cond,\n                               'decoder': decoder_cond\n                           },\n                           input_length=1,\n                           prediction_length=4,\n                           batch_size=128,\n                           ensemble_size=len(datasets),\n                           ensemble_type='index',\n                           tp_period=12,\n                           time=time,\n                           shuffle=False)\n\n    # we can see the summary of the generator\n    fit_gen.summary()\n\n    # we can now use the generator to get the inputs for the model\n    inputs, *_ = fit_gen[0]\n\n    # we can plot the inputs, to see what the model will get\n    # we show the encoder and decoder conditions\n    fig, (lax, rax) = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(16, 5))\n    lax.pcolormesh(inputs['encoder_cond'][:, 0, :])\n    lax.set_title(\"inputs['encoder_cond']\")\n    mp = rax.pcolormesh(inputs['decoder_cond'][:, 0, :])\n    rax.set_title(\"inputs['decoder_cond']\")\n\n    fig.colorbar(mp, ax=(lax, rax))\n</code></pre>"},{"location":"examples/#fileio","title":"FileIO","text":""},{"location":"examples/#VAE.utils.fileio.example_read_climexp_raw_data_multi","title":"VAE.utils.fileio.example_read_climexp_raw_data_multi","text":"<pre><code>example_read_climexp_raw_data_multi()\n</code></pre> <p>Example of how to use the function <code>read_climexp_raw_data_multi</code>.</p> <p>The function reads multiple files of raw data from the <code>example_data/</code> folder.</p> <pre><code>example_data/icmip5_tos_Omon_one_rcp45_pc01.txt\nexample_data/icmip5_tos_Omon_one_rcp45_pc02.txt\n</code></pre> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example_read_climexp_raw_data_multi():\n    \"\"\"Example of how to use the function `read_climexp_raw_data_multi`.\n\n    The function reads multiple files of raw data from the `example_data/` folder.\n\n    ```\n    example_data/icmip5_tos_Omon_one_rcp45_pc01.txt\n    example_data/icmip5_tos_Omon_one_rcp45_pc02.txt\n    ```\n\n    \"\"\"\n\n    filename = [\n        'example_data/icmip5_tos_Omon_one_rcp45_pc01.txt',\n        'example_data/icmip5_tos_Omon_one_rcp45_pc02.txt',\n    ]\n\n    # read data\n    df, metadata = read_climexp_raw_data_multi(filename, ensemble_members=[0, 1, 2, 3, 4, 5], join='outer')\n\n    with pd.option_context('display.precision', 3):\n        print(df)\n\n    _, ax = plt.subplots(1, 1, figsize=(10, 5))\n    time = df.index.to_numpy()\n\n    # access data by level-zero index\n    for idx in df.columns.levels[0]:\n        x = df[idx]\n        x = x.to_numpy()\n        x_mean = x.mean(axis=1)\n        x_std = x.std(axis=1) * 3\n\n        ax.plot(time, x_mean, label=metadata[idx].get('description'), zorder=2.2)\n        ax.fill_between(time, x_mean - x_std, x_mean + x_std, alpha=0.5, zorder=2.1)\n\n    ax.legend(loc='upper left')\n    ax.grid(linestyle=':')\n</code></pre>"},{"location":"examples/#VAE.utils.fileio.example1_read_netcdf","title":"VAE.utils.fileio.example1_read_netcdf","text":"<pre><code>example1_read_netcdf()\n</code></pre> <p>Example of how to use the function <code>read_netcdf</code>.</p> <p>This function reads EOFs in a netCDF file from the Climate explorer from the <code>example_data/</code> folder:</p> <pre><code>example_data/eofs_icmip5_tos_Omon_one_rcp45.nc\n</code></pre> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example1_read_netcdf():\n    \"\"\"Example of how to use the function `read_netcdf`.\n\n    This function reads EOFs in a netCDF file from the Climate explorer from the `example_data/` folder:\n\n    ```\n    example_data/eofs_icmip5_tos_Omon_one_rcp45.nc\n    ```\n\n    \"\"\"\n\n    filename = 'example_data/eofs_icmip5_tos_Omon_one_rcp45.nc'\n\n    # read data\n    variables, dimensions, attributes = read_netcdf(filename)\n\n    print('variables')\n    for key, value in variables.items():\n        print('  ', key, value.shape)\n\n    print('dimensions')\n    for key, value in dimensions.items():\n        print('  ', key, value.shape)\n\n    print('attributes')\n    pprint(attributes)\n\n    # remove singleton dimensions\n    squeeze_variables = {key: np.squeeze(value) for key, value in variables.items()}\n    # plot variables\n    vplt.map_plot(dimensions['lat'], dimensions['lon'], squeeze_variables, ncols=5, figwidth=20, cmap='seismic')\n</code></pre>"},{"location":"examples/#VAE.utils.fileio.example2_read_netcdf","title":"VAE.utils.fileio.example2_read_netcdf","text":"<pre><code>example2_read_netcdf()\n</code></pre> <p>Example of how to use the function <code>read_netcdf</code>.</p> <p>This function reads EOFs in a netCDF file from the output of the climate data operators (CDO). The file is from the <code>example_data/</code> folder:</p> <pre><code>example_data/eofs_anom_gpcc_v2020_1dgr.nc\n</code></pre> <p>:material-github: For the calculation of the EOFs and PCs with CDO see the CDO     scripts.</p> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example2_read_netcdf():\n    \"\"\"Example of how to use the function `read_netcdf`.\n\n    This function reads EOFs in a netCDF file from the output of the climate data operators (CDO). The file is from the\n    `example_data/` folder:\n\n    ```\n    example_data/eofs_anom_gpcc_v2020_1dgr.nc\n    ```\n\n    :material-github: For the calculation of the EOFs and PCs with CDO see the [CDO\n        scripts](https://github.com/andr-groth/cdo-scripts).\n\n    \"\"\"\n\n    filename = 'example_data/eofs_anom_gpcc_v2020_1dgr.nc'\n\n    # read data\n    variables, dimensions, attributes = read_netcdf(filename)\n\n    print('variables')\n    for key, value in variables.items():\n        print('  ', key, value.shape)\n\n    print('dimensions')\n    for key, value in dimensions.items():\n        print('  ', key, value.shape)\n\n    print('attributes')\n    pprint(attributes)\n\n    # plot first variable\n    key, *_ = list(variables)\n    variable = variables[key]\n    vplt.map_plot(dimensions['lat'], dimensions['lon'], variable, ncols=10, figwidth=20, cmap='seismic')\n</code></pre>"},{"location":"examples/#VAE.utils.fileio.example3_read_netcdf","title":"VAE.utils.fileio.example3_read_netcdf","text":"<pre><code>example3_read_netcdf()\n</code></pre> <p>Example of how to use the function <code>read_netcdf</code>.</p> <p>This function reads PCs in a netCDF file from the output of the climate data operators (CDO). The file is from the <code>example_data/</code> folder:</p> <pre><code>example_data/pcs_anom_gpcc_v2020_1dgr.nc\n</code></pre> <p>:material-github: For the calculation of the EOFs and PCs with CDO see the CDO     scripts.</p> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example3_read_netcdf():\n    \"\"\"Example of how to use the function `read_netcdf`.\n\n    This function reads PCs in a netCDF file from the output of the climate data operators (CDO). The file is from the\n    `example_data/` folder:\n\n    ```\n    example_data/pcs_anom_gpcc_v2020_1dgr.nc\n    ```\n\n    :material-github: For the calculation of the EOFs and PCs with CDO see the [CDO\n        scripts](https://github.com/andr-groth/cdo-scripts).\n\n    \"\"\"\n\n    filename = 'example_data/pcs_anom_gpcc_v2020_1dgr.nc'\n\n    # read data\n    variables, dimensions, attributes = read_netcdf(filename, num2date=True)\n\n    print('variables')\n    for key, value in variables.items():\n        print('  ', key, value.shape)\n\n    print('dimensions')\n    for key, value in dimensions.items():\n        print('  ', key, value.shape)\n\n    print('attribtutes')\n    pprint(attributes)\n\n    # plot first variable\n    key, *_ = list(variables)\n    variable = np.squeeze(variables[key])  # remove singleton spatial dimensions\n    variable = variable.T\n    variable = np.atleast_2d(variable)\n    cols = min(len(variable), 5)\n    rows = -(-len(variable) // cols)\n    _, axs = plt.subplots(rows, cols, figsize=(4 * cols, 2 * rows), sharex=True, sharey=True, squeeze=False)\n    for n, (ax, value) in enumerate(zip(axs.flatten(), variable)):\n        ax.plot(dimensions['time'], value)\n        ax.set_title(n)\n</code></pre>"},{"location":"examples/#VAE.utils.fileio.example_read_netcdf_multi","title":"VAE.utils.fileio.example_read_netcdf_multi","text":"<pre><code>example_read_netcdf_multi(filename)\n</code></pre> <p>Example of how to use the function <code>read_netcdf_multi</code>.</p> <p>This function reads PCs in multiple netCDF files from the output of the climate data operators (CDO). The files are from the <code>example_data/</code> folder:</p> <pre><code>example_data/pcs_anom_pr_*.nc\n</code></pre> <p>:material-github: For the calculation of the EOFs and PCs with CDO see the CDO     scripts.</p> Source code in <code>VAE/utils/fileio.py</code> <pre><code>def example_read_netcdf_multi(filename: str):\n    \"\"\"Example of how to use the function `read_netcdf_multi`.\n\n    This function reads PCs in multiple netCDF files from the output of the climate data operators (CDO). The files are\n    from the `example_data/` folder:\n\n    ```\n    example_data/pcs_anom_pr_*.nc\n    ```\n\n    :material-github: For the calculation of the EOFs and PCs with CDO see the [CDO\n        scripts](https://github.com/andr-groth/cdo-scripts).\n\n    \"\"\"\n\n    filename = 'example_data/pcs_anom_pr_*.nc'\n\n    # read data\n    variables, dimensions, attributes = read_netcdf_multi(filename, num2date=True)\n\n    print('variables')\n    for key, value in variables.items():\n        print('  ', key)\n        for k, v in value.items():\n            print('    ', k, v.shape)\n\n    print('dimensions')\n    for key, value in dimensions.items():\n        print('  ', key)\n        for k, v in value.items():\n            print('    ', k, v.shape)\n\n    rows = 5\n    cols = 2\n    _, axs = plt.subplots(rows, cols, figsize=(8 * cols, 3 * rows), sharex=True, sharey=True, squeeze=False)\n    # cycle through different files\n    for key, variable in variables.items():\n        var_name, *_ = list(variable)  # extract first variable\n        values = np.squeeze(variable[var_name])  # remove singleton spatial dimensions\n        values = values.T\n        values = np.atleast_2d(values)\n        for n, (ax, value) in enumerate(zip(axs.flatten(), values)):\n            ax.plot(dimensions[key]['time'], value, label=key)\n            ax.set_title(n)\n\n    axs.flat[0].legend()\n</code></pre>"}]}